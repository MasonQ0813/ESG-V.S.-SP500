{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFk-lTYwBgRW",
    "outputId": "fddc512e-e95e-4767-c74b-d693da65308d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient data for FISV, trying another ticker.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "ERROR:yfinance:\n",
      "1 Failed download:\n",
      "ERROR:yfinance:['FBHS']: Exception('%ticker%: No timezone found, symbol may be delisted')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient data for FBHS, trying another ticker.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "ERROR:yfinance:\n",
      "1 Failed download:\n",
      "ERROR:yfinance:['KSU']: Exception('%ticker%: No timezone found, symbol may be delisted')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient data for KSU, trying another ticker.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock data downloaded successfully for tickers: ['DPZ', 'AVGO', 'TSLA', 'NOW', 'DTE', 'ADBE', 'COO', 'DHI', 'ADSK', 'TRV', 'AES', 'RF', 'WMT', 'LNT', 'COF', 'EXR', 'PCAR', 'EIX', 'TMO', 'FE', 'RSG', 'DOV', 'AMT', 'VZ', 'NUE', 'OKE', 'WAB', 'BIIB', 'NTRS', 'MGM']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import timedelta\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "# Function to get daily stock data for a given ticker\n",
    "def get_stock_data(ticker, start_date, end_date):\n",
    "    try:\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        return stock_data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download data for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Read the ticker symbols from the CSV file\n",
    "SP500_df = pd.read_csv(\"tickers.csv\")\n",
    "sp500_tickers = list(SP500_df[\"Symbol\"].iloc[:504])\n",
    "\n",
    "# Define the start and end date for the past ten years\n",
    "end_date = pd.Timestamp.now()\n",
    "start_date = end_date - pd.DateOffset(years=10)\n",
    "\n",
    "# Initialize a dictionary to store the stock data\n",
    "SP500_stock_data = {}\n",
    "\n",
    "# Keep trying until we get data for 30 tickers\n",
    "while len(SP500_stock_data) < 30:\n",
    "    # Randomly sample 1 ticker from the list\n",
    "    random_ticker = np.random.choice(sp500_tickers, size=1, replace=False)[0]\n",
    "\n",
    "    # If we already have this ticker, skip to the next iteration\n",
    "    if random_ticker in SP500_stock_data:\n",
    "        continue\n",
    "\n",
    "    data = get_stock_data(random_ticker, start_date=start_date, end_date=end_date)\n",
    "\n",
    "    # Validate that the data contains at least 10 years of data\n",
    "    # Assuming at least 250 trading days in a year\n",
    "    if data is not None and len(data) >= 250 * 10:\n",
    "        SP500_stock_data[random_ticker] = data\n",
    "    else:\n",
    "        print(f\"Insufficient data for {random_ticker}, trying another ticker.\")\n",
    "\n",
    "print(\"Stock data downloaded successfully for tickers:\", list(SP500_stock_data.keys()))\n",
    "stock_names = [key for key in SP500_stock_data]\n",
    "SP500_result_dict = {}\n",
    "for dataset_name, dataset in SP500_stock_data.items():\n",
    "    # Assuming your data is sorted by date, you can calculate the logarithmic return\n",
    "    dataset['rt'] = np.log(dataset['Close']) - np.log(dataset['Close'].shift(1))\n",
    "    # Calculate the one-day lagged logarithmic return\n",
    "    dataset['rt-1'] = dataset['rt'].shift(1)\n",
    "    # Calculate the two-day lagged logarithmic return\n",
    "    dataset['rt-2'] = np.log(dataset['Open'].shift(2)) - np.log(dataset['Close'].shift(1))\n",
    "    # Calculate the three-day lagged logarithmic return\n",
    "    dataset['rt-3'] = np.log(dataset['Open'].shift(3)) - np.log(dataset['Close'].shift(1))\n",
    "    dataset['ct'] = np.log(dataset['Close']) - np.log(dataset['Open'])\n",
    "    dataset['ct-1'] = np.log(dataset['Close']) - np.log(dataset['Open'].shift(1))\n",
    "    dataset['ot'] = np.log(dataset['Open']) - np.log(dataset['Close'].shift(1))\n",
    "    dataset['ht'] = np.log(dataset['High']) - np.log(dataset['Open'])\n",
    "    dataset['ht-1'] = np.log(dataset['High'].shift(1)) - np.log(dataset['Open'].shift(1))\n",
    "    dataset['ht-2'] = np.log(dataset['High'].shift(2)) - np.log(dataset['Open'].shift(2))\n",
    "    dataset['ht-2'] = np.log(dataset['High'].shift(3)) - np.log(dataset['Open'].shift(3))\n",
    "    dataset['lt'] = np.log(dataset['Low']) - np.log(dataset['Open'])\n",
    "    dataset['lt-1'] = np.log(dataset['Low'].shift(1)) - np.log(dataset['Open'].shift(1))\n",
    "    dataset['lt-2'] = np.log(dataset['Low'].shift(2)) - np.log(dataset['Open'].shift(2))\n",
    "    dataset['lt-3'] = np.log(dataset['Low'].shift(3)) - np.log(dataset['Open'].shift(3))\n",
    "\n",
    "    close_prices = dataset['Close']\n",
    "    high_prices = dataset['High']\n",
    "    low_prices = dataset['Low']\n",
    "    prev_close = np.roll(close_prices, 1)\n",
    "    true_range = np.maximum(\n",
    "        np.abs(high_prices - low_prices),\n",
    "        np.abs(prev_close - high_prices),\n",
    "        np.abs(prev_close - low_prices)\n",
    "    )\n",
    "    dataset=dataset.reset_index()\n",
    "    dataset[\"Date\"]=pd.to_datetime(dataset[\"Date\"])\n",
    "    result = dataset.dropna()\n",
    "    SP500_result_dict[dataset_name] = result\n",
    "\n",
    "def create_rolling_windows(stock_df, num_windows=7, train_years=3, test_years=1):\n",
    "    rolling_windows = []\n",
    "    start_date = stock_df['Date'].min()\n",
    "\n",
    "    for _ in range(num_windows):\n",
    "        train_end_date = start_date + pd.DateOffset(years=train_years)\n",
    "        test_end_date = train_end_date + pd.DateOffset(years=test_years)\n",
    "\n",
    "        if test_end_date > stock_df['Date'].max():\n",
    "            break  # Stop if we don't have enough data for the next window\n",
    "\n",
    "        # Extract training and testing sets\n",
    "        training_set = stock_df[(stock_df['Date'] >= start_date) & (stock_df['Date'] < train_end_date)]\n",
    "        testing_set = stock_df[(stock_df['Date'] >= train_end_date) & (stock_df['Date'] < test_end_date)]\n",
    "\n",
    "        # Store the pairs\n",
    "        rolling_windows.append((training_set, testing_set))\n",
    "\n",
    "        # Move the start date by one year for the next window\n",
    "        start_date += pd.DateOffset(years=1)\n",
    "\n",
    "    return rolling_windows\n",
    "\n",
    "# Create a new dictionary with rolling window pairs for each stock\n",
    "SP500_Train_Test_Dict = {stock_name: create_rolling_windows(stock_df) for stock_name, stock_df in SP500_result_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjUZ57zeB6px"
   },
   "source": [
    "<h2>SP500</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plST-a9mB-fS"
   },
   "source": [
    "<b>random forest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Zd7ag50B4Vz",
    "outputId": "49fcdbb3-5b76-4809-e7bc-f02e4e129c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Prediction of year 2017 of DPZ is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.497793467586848e-05, 'rmse': 0.00806088919883337, 'mae': 0.003231702808106048, 'hit_rate': 0.927710843373494}]\n",
      "the Prediction of year 2018 of DPZ is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.497793467586848e-05, 'rmse': 0.00806088919883337, 'mae': 0.003231702808106048, 'hit_rate': 0.927710843373494}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.7213695468806956e-05, 'rmse': 0.007563973523803938, 'mae': 0.003533390494737521, 'hit_rate': 0.9362549800796812}]\n",
      "the Prediction of year 2019 of DPZ is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.497793467586848e-05, 'rmse': 0.00806088919883337, 'mae': 0.003231702808106048, 'hit_rate': 0.927710843373494}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.7213695468806956e-05, 'rmse': 0.007563973523803938, 'mae': 0.003533390494737521, 'hit_rate': 0.9362549800796812}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00029491681674394097, 'rmse': 0.017173142308382034, 'mae': 0.0052534927791307645, 'hit_rate': 0.9404761904761905}]\n",
      "the Prediction of year 2020 of DPZ is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.497793467586848e-05, 'rmse': 0.00806088919883337, 'mae': 0.003231702808106048, 'hit_rate': 0.927710843373494}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.7213695468806956e-05, 'rmse': 0.007563973523803938, 'mae': 0.003533390494737521, 'hit_rate': 0.9362549800796812}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00029491681674394097, 'rmse': 0.017173142308382034, 'mae': 0.0052534927791307645, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.6786238299215046e-05, 'rmse': 0.006840046659140202, 'mae': 0.002520990895929568, 'hit_rate': 0.9721115537848606}]\n",
      "the Prediction of year 2021 of DPZ is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.497793467586848e-05, 'rmse': 0.00806088919883337, 'mae': 0.003231702808106048, 'hit_rate': 0.927710843373494}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.7213695468806956e-05, 'rmse': 0.007563973523803938, 'mae': 0.003533390494737521, 'hit_rate': 0.9362549800796812}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00029491681674394097, 'rmse': 0.017173142308382034, 'mae': 0.0052534927791307645, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.6786238299215046e-05, 'rmse': 0.006840046659140202, 'mae': 0.002520990895929568, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.73142532295241e-05, 'rmse': 0.00687853568934, 'mae': 0.0020899339228806586, 'hit_rate': 0.9444444444444444}]\n",
      "the Prediction of year 2022 of DPZ is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.497793467586848e-05, 'rmse': 0.00806088919883337, 'mae': 0.003231702808106048, 'hit_rate': 0.927710843373494}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.7213695468806956e-05, 'rmse': 0.007563973523803938, 'mae': 0.003533390494737521, 'hit_rate': 0.9362549800796812}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00029491681674394097, 'rmse': 0.017173142308382034, 'mae': 0.0052534927791307645, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.6786238299215046e-05, 'rmse': 0.006840046659140202, 'mae': 0.002520990895929568, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.73142532295241e-05, 'rmse': 0.00687853568934, 'mae': 0.0020899339228806586, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.999409514439754e-05, 'rmse': 0.008366247375281079, 'mae': 0.0032565498193775203, 'hit_rate': 0.9598393574297188}]\n",
      "the Prediction of year 2017 of AVGO is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2374846035374292e-05, 'rmse': 0.004730205707511492, 'mae': 0.0025948798678037486, 'hit_rate': 0.9477911646586346}]\n",
      "the Prediction of year 2018 of AVGO is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2374846035374292e-05, 'rmse': 0.004730205707511492, 'mae': 0.0025948798678037486, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00014414185684029067, 'rmse': 0.012005909246712248, 'mae': 0.004426083869548508, 'hit_rate': 0.9282868525896414}]\n",
      "the Prediction of year 2019 of AVGO is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2374846035374292e-05, 'rmse': 0.004730205707511492, 'mae': 0.0025948798678037486, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00014414185684029067, 'rmse': 0.012005909246712248, 'mae': 0.004426083869548508, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003936125784459093, 'rmse': 0.019839671833120357, 'mae': 0.006659465808586715, 'hit_rate': 0.9603174603174603}]\n",
      "the Prediction of year 2020 of AVGO is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2374846035374292e-05, 'rmse': 0.004730205707511492, 'mae': 0.0025948798678037486, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00014414185684029067, 'rmse': 0.012005909246712248, 'mae': 0.004426083869548508, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003936125784459093, 'rmse': 0.019839671833120357, 'mae': 0.006659465808586715, 'hit_rate': 0.9603174603174603}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.438354565961269e-05, 'rmse': 0.006662097692139668, 'mae': 0.003928207939971753, 'hit_rate': 0.9442231075697212}]\n",
      "the Prediction of year 2021 of AVGO is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2374846035374292e-05, 'rmse': 0.004730205707511492, 'mae': 0.0025948798678037486, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00014414185684029067, 'rmse': 0.012005909246712248, 'mae': 0.004426083869548508, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003936125784459093, 'rmse': 0.019839671833120357, 'mae': 0.006659465808586715, 'hit_rate': 0.9603174603174603}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.438354565961269e-05, 'rmse': 0.006662097692139668, 'mae': 0.003928207939971753, 'hit_rate': 0.9442231075697212}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.795492960088637e-05, 'rmse': 0.004237325760534157, 'mae': 0.0018869039625289546, 'hit_rate': 0.9801587301587301}]\n",
      "the Prediction of year 2022 of AVGO is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2374846035374292e-05, 'rmse': 0.004730205707511492, 'mae': 0.0025948798678037486, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00014414185684029067, 'rmse': 0.012005909246712248, 'mae': 0.004426083869548508, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003936125784459093, 'rmse': 0.019839671833120357, 'mae': 0.006659465808586715, 'hit_rate': 0.9603174603174603}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.438354565961269e-05, 'rmse': 0.006662097692139668, 'mae': 0.003928207939971753, 'hit_rate': 0.9442231075697212}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.795492960088637e-05, 'rmse': 0.004237325760534157, 'mae': 0.0018869039625289546, 'hit_rate': 0.9801587301587301}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.297725173863943e-05, 'rmse': 0.005742582323192191, 'mae': 0.003292737887329664, 'hit_rate': 0.9477911646586346}]\n",
      "the Prediction of year 2017 of TSLA is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.091606660500578e-05, 'rmse': 0.007135549495659446, 'mae': 0.00309305151782363, 'hit_rate': 0.9598393574297188}]\n",
      "the Prediction of year 2018 of TSLA is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.091606660500578e-05, 'rmse': 0.007135549495659446, 'mae': 0.00309305151782363, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003771451597935404, 'rmse': 0.01942022553405445, 'mae': 0.0088738166230334, 'hit_rate': 0.9163346613545816}]\n",
      "the Prediction of year 2019 of TSLA is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.091606660500578e-05, 'rmse': 0.007135549495659446, 'mae': 0.00309305151782363, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003771451597935404, 'rmse': 0.01942022553405445, 'mae': 0.0088738166230334, 'hit_rate': 0.9163346613545816}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0007508330463203768, 'rmse': 0.027401332929629114, 'mae': 0.011756694511168848, 'hit_rate': 0.9484126984126984}]\n",
      "the Prediction of year 2020 of TSLA is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.091606660500578e-05, 'rmse': 0.007135549495659446, 'mae': 0.00309305151782363, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003771451597935404, 'rmse': 0.01942022553405445, 'mae': 0.0088738166230334, 'hit_rate': 0.9163346613545816}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0007508330463203768, 'rmse': 0.027401332929629114, 'mae': 0.011756694511168848, 'hit_rate': 0.9484126984126984}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0004032946987384979, 'rmse': 0.020082198553407888, 'mae': 0.011822562774649851, 'hit_rate': 0.9282868525896414}]\n",
      "the Prediction of year 2021 of TSLA is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.091606660500578e-05, 'rmse': 0.007135549495659446, 'mae': 0.00309305151782363, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003771451597935404, 'rmse': 0.01942022553405445, 'mae': 0.0088738166230334, 'hit_rate': 0.9163346613545816}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0007508330463203768, 'rmse': 0.027401332929629114, 'mae': 0.011756694511168848, 'hit_rate': 0.9484126984126984}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0004032946987384979, 'rmse': 0.020082198553407888, 'mae': 0.011822562774649851, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.09300225795287e-05, 'rmse': 0.009535723495337347, 'mae': 0.0049728472249800275, 'hit_rate': 0.9365079365079365}]\n",
      "the Prediction of year 2022 of TSLA is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.091606660500578e-05, 'rmse': 0.007135549495659446, 'mae': 0.00309305151782363, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003771451597935404, 'rmse': 0.01942022553405445, 'mae': 0.0088738166230334, 'hit_rate': 0.9163346613545816}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0007508330463203768, 'rmse': 0.027401332929629114, 'mae': 0.011756694511168848, 'hit_rate': 0.9484126984126984}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0004032946987384979, 'rmse': 0.020082198553407888, 'mae': 0.011822562774649851, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.09300225795287e-05, 'rmse': 0.009535723495337347, 'mae': 0.0049728472249800275, 'hit_rate': 0.9365079365079365}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001323330364877182, 'rmse': 0.01150360971555095, 'mae': 0.0067806894105031145, 'hit_rate': 0.9518072289156626}]\n",
      "the Prediction of year 2017 of NOW is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.994715877358499e-05, 'rmse': 0.006320376474038947, 'mae': 0.002244069404684654, 'hit_rate': 0.9477911646586346}]\n",
      "the Prediction of year 2018 of NOW is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.994715877358499e-05, 'rmse': 0.006320376474038947, 'mae': 0.002244069404684654, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.105367795873965e-05, 'rmse': 0.009542205088905796, 'mae': 0.0046994367919319146, 'hit_rate': 0.9721115537848606}]\n",
      "the Prediction of year 2019 of NOW is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.994715877358499e-05, 'rmse': 0.006320376474038947, 'mae': 0.002244069404684654, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.105367795873965e-05, 'rmse': 0.009542205088905796, 'mae': 0.0046994367919319146, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00023668444312505398, 'rmse': 0.01538455209374176, 'mae': 0.006475308559581166, 'hit_rate': 0.9365079365079365}]\n",
      "the Prediction of year 2020 of NOW is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.994715877358499e-05, 'rmse': 0.006320376474038947, 'mae': 0.002244069404684654, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.105367795873965e-05, 'rmse': 0.009542205088905796, 'mae': 0.0046994367919319146, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00023668444312505398, 'rmse': 0.01538455209374176, 'mae': 0.006475308559581166, 'hit_rate': 0.9365079365079365}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.4702960336683384e-05, 'rmse': 0.007396144964553046, 'mae': 0.0039349462905032126, 'hit_rate': 0.9482071713147411}]\n",
      "the Prediction of year 2021 of NOW is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.994715877358499e-05, 'rmse': 0.006320376474038947, 'mae': 0.002244069404684654, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.105367795873965e-05, 'rmse': 0.009542205088905796, 'mae': 0.0046994367919319146, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00023668444312505398, 'rmse': 0.01538455209374176, 'mae': 0.006475308559581166, 'hit_rate': 0.9365079365079365}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.4702960336683384e-05, 'rmse': 0.007396144964553046, 'mae': 0.0039349462905032126, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001304904490332455, 'rmse': 0.01142324161668856, 'mae': 0.0038406933582301006, 'hit_rate': 0.9325396825396826}]\n",
      "the Prediction of year 2022 of NOW is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.994715877358499e-05, 'rmse': 0.006320376474038947, 'mae': 0.002244069404684654, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.105367795873965e-05, 'rmse': 0.009542205088905796, 'mae': 0.0046994367919319146, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00023668444312505398, 'rmse': 0.01538455209374176, 'mae': 0.006475308559581166, 'hit_rate': 0.9365079365079365}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.4702960336683384e-05, 'rmse': 0.007396144964553046, 'mae': 0.0039349462905032126, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001304904490332455, 'rmse': 0.01142324161668856, 'mae': 0.0038406933582301006, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00022804274910950164, 'rmse': 0.015101084368663783, 'mae': 0.006759427768936012, 'hit_rate': 0.9437751004016064}]\n",
      "the Prediction of year 2017 of DTE is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9344963597962587e-06, 'rmse': 0.0013908617328103677, 'mae': 0.0007967341843855111, 'hit_rate': 0.963855421686747}]\n",
      "the Prediction of year 2018 of DTE is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9344963597962587e-06, 'rmse': 0.0013908617328103677, 'mae': 0.0007967341843855111, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.052861631890442e-05, 'rmse': 0.00324478293864234, 'mae': 0.0012932387369694572, 'hit_rate': 0.9641434262948207}]\n",
      "the Prediction of year 2019 of DTE is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9344963597962587e-06, 'rmse': 0.0013908617328103677, 'mae': 0.0007967341843855111, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.052861631890442e-05, 'rmse': 0.00324478293864234, 'mae': 0.0012932387369694572, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003944383143964802, 'rmse': 0.019860471152429397, 'mae': 0.005632627116492189, 'hit_rate': 0.9484126984126984}]\n",
      "the Prediction of year 2020 of DTE is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9344963597962587e-06, 'rmse': 0.0013908617328103677, 'mae': 0.0007967341843855111, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.052861631890442e-05, 'rmse': 0.00324478293864234, 'mae': 0.0012932387369694572, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003944383143964802, 'rmse': 0.019860471152429397, 'mae': 0.005632627116492189, 'hit_rate': 0.9484126984126984}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011839671199946126, 'rmse': 0.010881025319309815, 'mae': 0.006357921189562968, 'hit_rate': 0.9043824701195219}]\n",
      "the Prediction of year 2021 of DTE is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9344963597962587e-06, 'rmse': 0.0013908617328103677, 'mae': 0.0007967341843855111, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.052861631890442e-05, 'rmse': 0.00324478293864234, 'mae': 0.0012932387369694572, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003944383143964802, 'rmse': 0.019860471152429397, 'mae': 0.005632627116492189, 'hit_rate': 0.9484126984126984}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011839671199946126, 'rmse': 0.010881025319309815, 'mae': 0.006357921189562968, 'hit_rate': 0.9043824701195219}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.022700527240216e-06, 'rmse': 0.0022411382213599, 'mae': 0.0010927565601660193, 'hit_rate': 0.9722222222222222}]\n",
      "the Prediction of year 2022 of DTE is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9344963597962587e-06, 'rmse': 0.0013908617328103677, 'mae': 0.0007967341843855111, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.052861631890442e-05, 'rmse': 0.00324478293864234, 'mae': 0.0012932387369694572, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003944383143964802, 'rmse': 0.019860471152429397, 'mae': 0.005632627116492189, 'hit_rate': 0.9484126984126984}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011839671199946126, 'rmse': 0.010881025319309815, 'mae': 0.006357921189562968, 'hit_rate': 0.9043824701195219}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.022700527240216e-06, 'rmse': 0.0022411382213599, 'mae': 0.0010927565601660193, 'hit_rate': 0.9722222222222222}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.0804084090832993e-05, 'rmse': 0.004561149426496899, 'mae': 0.002166125789909867, 'hit_rate': 0.9598393574297188}]\n",
      "the Prediction of year 2017 of ADBE is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.098225433998106e-05, 'rmse': 0.007809113543801311, 'mae': 0.002420626094711836, 'hit_rate': 0.9718875502008032}]\n",
      "the Prediction of year 2018 of ADBE is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.098225433998106e-05, 'rmse': 0.007809113543801311, 'mae': 0.002420626094711836, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.424037388862425e-05, 'rmse': 0.009707748136855645, 'mae': 0.004675088172185407, 'hit_rate': 0.9561752988047809}]\n",
      "the Prediction of year 2019 of ADBE is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.098225433998106e-05, 'rmse': 0.007809113543801311, 'mae': 0.002420626094711836, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.424037388862425e-05, 'rmse': 0.009707748136855645, 'mae': 0.004675088172185407, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002593658109885233, 'rmse': 0.01610483812363612, 'mae': 0.0055184529545492704, 'hit_rate': 0.9404761904761905}]\n",
      "the Prediction of year 2020 of ADBE is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.098225433998106e-05, 'rmse': 0.007809113543801311, 'mae': 0.002420626094711836, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.424037388862425e-05, 'rmse': 0.009707748136855645, 'mae': 0.004675088172185407, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002593658109885233, 'rmse': 0.01610483812363612, 'mae': 0.0055184529545492704, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.612273220119942e-05, 'rmse': 0.006791371893895917, 'mae': 0.0033849526425499005, 'hit_rate': 0.9681274900398407}]\n",
      "the Prediction of year 2021 of ADBE is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.098225433998106e-05, 'rmse': 0.007809113543801311, 'mae': 0.002420626094711836, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.424037388862425e-05, 'rmse': 0.009707748136855645, 'mae': 0.004675088172185407, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002593658109885233, 'rmse': 0.01610483812363612, 'mae': 0.0055184529545492704, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.612273220119942e-05, 'rmse': 0.006791371893895917, 'mae': 0.0033849526425499005, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.311002795305901e-05, 'rmse': 0.007287662722235367, 'mae': 0.0030424791734850374, 'hit_rate': 0.9563492063492064}]\n",
      "the Prediction of year 2022 of ADBE is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.098225433998106e-05, 'rmse': 0.007809113543801311, 'mae': 0.002420626094711836, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.424037388862425e-05, 'rmse': 0.009707748136855645, 'mae': 0.004675088172185407, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002593658109885233, 'rmse': 0.01610483812363612, 'mae': 0.0055184529545492704, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.612273220119942e-05, 'rmse': 0.006791371893895917, 'mae': 0.0033849526425499005, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.311002795305901e-05, 'rmse': 0.007287662722235367, 'mae': 0.0030424791734850374, 'hit_rate': 0.9563492063492064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001369044044419674, 'rmse': 0.011700615558250232, 'mae': 0.005204018047421126, 'hit_rate': 0.927710843373494}]\n",
      "the Prediction of year 2017 of COO is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1671621258767645e-05, 'rmse': 0.00562775454855377, 'mae': 0.0020294124593607074, 'hit_rate': 0.9718875502008032}]\n",
      "the Prediction of year 2018 of COO is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1671621258767645e-05, 'rmse': 0.00562775454855377, 'mae': 0.0020294124593607074, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.352468304851756e-05, 'rmse': 0.007970237326988297, 'mae': 0.002710779876786917, 'hit_rate': 0.9681274900398407}]\n",
      "the Prediction of year 2019 of COO is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1671621258767645e-05, 'rmse': 0.00562775454855377, 'mae': 0.0020294124593607074, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.352468304851756e-05, 'rmse': 0.007970237326988297, 'mae': 0.002710779876786917, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00021422868183733668, 'rmse': 0.01463655293562445, 'mae': 0.004789565149997233, 'hit_rate': 0.9404761904761905}]\n",
      "the Prediction of year 2020 of COO is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1671621258767645e-05, 'rmse': 0.00562775454855377, 'mae': 0.0020294124593607074, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.352468304851756e-05, 'rmse': 0.007970237326988297, 'mae': 0.002710779876786917, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00021422868183733668, 'rmse': 0.01463655293562445, 'mae': 0.004789565149997233, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.633285427492882e-05, 'rmse': 0.007505521585801271, 'mae': 0.003789888908828865, 'hit_rate': 0.9322709163346613}]\n",
      "the Prediction of year 2021 of COO is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1671621258767645e-05, 'rmse': 0.00562775454855377, 'mae': 0.0020294124593607074, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.352468304851756e-05, 'rmse': 0.007970237326988297, 'mae': 0.002710779876786917, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00021422868183733668, 'rmse': 0.01463655293562445, 'mae': 0.004789565149997233, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.633285427492882e-05, 'rmse': 0.007505521585801271, 'mae': 0.003789888908828865, 'hit_rate': 0.9322709163346613}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.790165759313192e-05, 'rmse': 0.004231035049858594, 'mae': 0.0016869410490064848, 'hit_rate': 0.9642857142857143}]\n",
      "the Prediction of year 2022 of COO is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1671621258767645e-05, 'rmse': 0.00562775454855377, 'mae': 0.0020294124593607074, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.352468304851756e-05, 'rmse': 0.007970237326988297, 'mae': 0.002710779876786917, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00021422868183733668, 'rmse': 0.01463655293562445, 'mae': 0.004789565149997233, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.633285427492882e-05, 'rmse': 0.007505521585801271, 'mae': 0.003789888908828865, 'hit_rate': 0.9322709163346613}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.790165759313192e-05, 'rmse': 0.004231035049858594, 'mae': 0.0016869410490064848, 'hit_rate': 0.9642857142857143}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.564480164471207e-05, 'rmse': 0.0074595443322438984, 'mae': 0.0036717453219374694, 'hit_rate': 0.9558232931726908}]\n",
      "the Prediction of year 2017 of DHI is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4924077024676493e-05, 'rmse': 0.0038631692979568593, 'mae': 0.001368658325831008, 'hit_rate': 0.9678714859437751}]\n",
      "the Prediction of year 2018 of DHI is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4924077024676493e-05, 'rmse': 0.0038631692979568593, 'mae': 0.001368658325831008, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.467789025034994e-05, 'rmse': 0.008042256539700157, 'mae': 0.003135920313007132, 'hit_rate': 0.952191235059761}]\n",
      "the Prediction of year 2019 of DHI is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4924077024676493e-05, 'rmse': 0.0038631692979568593, 'mae': 0.001368658325831008, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.467789025034994e-05, 'rmse': 0.008042256539700157, 'mae': 0.003135920313007132, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003605033313886318, 'rmse': 0.018986925274741873, 'mae': 0.005643109824119895, 'hit_rate': 0.9444444444444444}]\n",
      "the Prediction of year 2020 of DHI is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4924077024676493e-05, 'rmse': 0.0038631692979568593, 'mae': 0.001368658325831008, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.467789025034994e-05, 'rmse': 0.008042256539700157, 'mae': 0.003135920313007132, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003605033313886318, 'rmse': 0.018986925274741873, 'mae': 0.005643109824119895, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001822964598849815, 'rmse': 0.01350172062683055, 'mae': 0.007246035275241438, 'hit_rate': 0.9362549800796812}]\n",
      "the Prediction of year 2021 of DHI is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4924077024676493e-05, 'rmse': 0.0038631692979568593, 'mae': 0.001368658325831008, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.467789025034994e-05, 'rmse': 0.008042256539700157, 'mae': 0.003135920313007132, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003605033313886318, 'rmse': 0.018986925274741873, 'mae': 0.005643109824119895, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001822964598849815, 'rmse': 0.01350172062683055, 'mae': 0.007246035275241438, 'hit_rate': 0.9362549800796812}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.7449737687816266e-05, 'rmse': 0.005239249725658843, 'mae': 0.002706650020086964, 'hit_rate': 0.9523809523809523}]\n",
      "the Prediction of year 2022 of DHI is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4924077024676493e-05, 'rmse': 0.0038631692979568593, 'mae': 0.001368658325831008, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.467789025034994e-05, 'rmse': 0.008042256539700157, 'mae': 0.003135920313007132, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003605033313886318, 'rmse': 0.018986925274741873, 'mae': 0.005643109824119895, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001822964598849815, 'rmse': 0.01350172062683055, 'mae': 0.007246035275241438, 'hit_rate': 0.9362549800796812}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.7449737687816266e-05, 'rmse': 0.005239249725658843, 'mae': 0.002706650020086964, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.274756687908319e-05, 'rmse': 0.007262752018283647, 'mae': 0.003781272937687276, 'hit_rate': 0.9437751004016064}]\n",
      "the Prediction of year 2017 of ADSK is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015120677503521832, 'rmse': 0.012296616405955677, 'mae': 0.003019166419835372, 'hit_rate': 0.9598393574297188}]\n",
      "the Prediction of year 2018 of ADSK is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015120677503521832, 'rmse': 0.012296616405955677, 'mae': 0.003019166419835372, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011681929029694941, 'rmse': 0.010808297289441543, 'mae': 0.004240529312687189, 'hit_rate': 0.9561752988047809}]\n",
      "the Prediction of year 2019 of ADSK is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015120677503521832, 'rmse': 0.012296616405955677, 'mae': 0.003019166419835372, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011681929029694941, 'rmse': 0.010808297289441543, 'mae': 0.004240529312687189, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00027462849371375213, 'rmse': 0.016571918830170274, 'mae': 0.006443120157938188, 'hit_rate': 0.9444444444444444}]\n",
      "the Prediction of year 2020 of ADSK is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015120677503521832, 'rmse': 0.012296616405955677, 'mae': 0.003019166419835372, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011681929029694941, 'rmse': 0.010808297289441543, 'mae': 0.004240529312687189, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00027462849371375213, 'rmse': 0.016571918830170274, 'mae': 0.006443120157938188, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.7198963345704325e-05, 'rmse': 0.0075629996261869755, 'mae': 0.004060621205486328, 'hit_rate': 0.9721115537848606}]\n",
      "the Prediction of year 2021 of ADSK is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015120677503521832, 'rmse': 0.012296616405955677, 'mae': 0.003019166419835372, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011681929029694941, 'rmse': 0.010808297289441543, 'mae': 0.004240529312687189, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00027462849371375213, 'rmse': 0.016571918830170274, 'mae': 0.006443120157938188, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.7198963345704325e-05, 'rmse': 0.0075629996261869755, 'mae': 0.004060621205486328, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.270228351356177e-05, 'rmse': 0.009094079585838348, 'mae': 0.0027774042666651104, 'hit_rate': 0.9722222222222222}]\n",
      "the Prediction of year 2022 of ADSK is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015120677503521832, 'rmse': 0.012296616405955677, 'mae': 0.003019166419835372, 'hit_rate': 0.9598393574297188}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011681929029694941, 'rmse': 0.010808297289441543, 'mae': 0.004240529312687189, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00027462849371375213, 'rmse': 0.016571918830170274, 'mae': 0.006443120157938188, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.7198963345704325e-05, 'rmse': 0.0075629996261869755, 'mae': 0.004060621205486328, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.270228351356177e-05, 'rmse': 0.009094079585838348, 'mae': 0.0027774042666651104, 'hit_rate': 0.9722222222222222}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001321837336845341, 'rmse': 0.01149711849484618, 'mae': 0.00500094945214609, 'hit_rate': 0.9558232931726908}]\n",
      "the Prediction of year 2017 of TRV is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.041898481182445e-05, 'rmse': 0.00451873708151121, 'mae': 0.001755043752380727, 'hit_rate': 0.9477911646586346}]\n",
      "the Prediction of year 2018 of TRV is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.041898481182445e-05, 'rmse': 0.00451873708151121, 'mae': 0.001755043752380727, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.337622148862361e-05, 'rmse': 0.00365735170425591, 'mae': 0.001718529284994688, 'hit_rate': 0.9601593625498008}]\n",
      "the Prediction of year 2019 of TRV is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.041898481182445e-05, 'rmse': 0.00451873708151121, 'mae': 0.001755043752380727, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.337622148862361e-05, 'rmse': 0.00365735170425591, 'mae': 0.001718529284994688, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003982189930141149, 'rmse': 0.01995542515242697, 'mae': 0.00544378809510889, 'hit_rate': 0.9523809523809523}]\n",
      "the Prediction of year 2020 of TRV is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.041898481182445e-05, 'rmse': 0.00451873708151121, 'mae': 0.001755043752380727, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.337622148862361e-05, 'rmse': 0.00365735170425591, 'mae': 0.001718529284994688, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003982189930141149, 'rmse': 0.01995542515242697, 'mae': 0.00544378809510889, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001252741673603429, 'rmse': 0.011192594308753575, 'mae': 0.006314081784376939, 'hit_rate': 0.896414342629482}]\n",
      "the Prediction of year 2021 of TRV is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.041898481182445e-05, 'rmse': 0.00451873708151121, 'mae': 0.001755043752380727, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.337622148862361e-05, 'rmse': 0.00365735170425591, 'mae': 0.001718529284994688, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003982189930141149, 'rmse': 0.01995542515242697, 'mae': 0.00544378809510889, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001252741673603429, 'rmse': 0.011192594308753575, 'mae': 0.006314081784376939, 'hit_rate': 0.896414342629482}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.6795045818151957e-05, 'rmse': 0.00409817591351957, 'mae': 0.0017297758486429988, 'hit_rate': 0.9682539682539683}]\n",
      "the Prediction of year 2022 of TRV is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.041898481182445e-05, 'rmse': 0.00451873708151121, 'mae': 0.001755043752380727, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.337622148862361e-05, 'rmse': 0.00365735170425591, 'mae': 0.001718529284994688, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003982189930141149, 'rmse': 0.01995542515242697, 'mae': 0.00544378809510889, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001252741673603429, 'rmse': 0.011192594308753575, 'mae': 0.006314081784376939, 'hit_rate': 0.896414342629482}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.6795045818151957e-05, 'rmse': 0.00409817591351957, 'mae': 0.0017297758486429988, 'hit_rate': 0.9682539682539683}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.690611380534021e-06, 'rmse': 0.002773195157311151, 'mae': 0.0013862743871853112, 'hit_rate': 0.9558232931726908}]\n",
      "the Prediction of year 2017 of AES is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.083213510373697e-05, 'rmse': 0.007129665847971907, 'mae': 0.0015631084472818714, 'hit_rate': 0.9799196787148594}]\n",
      "the Prediction of year 2018 of AES is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.083213510373697e-05, 'rmse': 0.007129665847971907, 'mae': 0.0015631084472818714, 'hit_rate': 0.9799196787148594}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1400531888395603e-05, 'rmse': 0.004626070890982498, 'mae': 0.0016608331660061613, 'hit_rate': 0.9561752988047809}]\n",
      "the Prediction of year 2019 of AES is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.083213510373697e-05, 'rmse': 0.007129665847971907, 'mae': 0.0015631084472818714, 'hit_rate': 0.9799196787148594}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1400531888395603e-05, 'rmse': 0.004626070890982498, 'mae': 0.0016608331660061613, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0004459850534154339, 'rmse': 0.021118358208332244, 'mae': 0.0059316049443478664, 'hit_rate': 0.9285714285714286}]\n",
      "the Prediction of year 2020 of AES is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.083213510373697e-05, 'rmse': 0.007129665847971907, 'mae': 0.0015631084472818714, 'hit_rate': 0.9799196787148594}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1400531888395603e-05, 'rmse': 0.004626070890982498, 'mae': 0.0016608331660061613, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0004459850534154339, 'rmse': 0.021118358208332244, 'mae': 0.0059316049443478664, 'hit_rate': 0.9285714285714286}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001703958973970791, 'rmse': 0.013053577953843884, 'mae': 0.007033869516784393, 'hit_rate': 0.9203187250996016}]\n",
      "the Prediction of year 2021 of AES is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.083213510373697e-05, 'rmse': 0.007129665847971907, 'mae': 0.0015631084472818714, 'hit_rate': 0.9799196787148594}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1400531888395603e-05, 'rmse': 0.004626070890982498, 'mae': 0.0016608331660061613, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0004459850534154339, 'rmse': 0.021118358208332244, 'mae': 0.0059316049443478664, 'hit_rate': 0.9285714285714286}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001703958973970791, 'rmse': 0.013053577953843884, 'mae': 0.007033869516784393, 'hit_rate': 0.9203187250996016}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4353074818857749e-05, 'rmse': 0.0037885452114047352, 'mae': 0.0020697022045502917, 'hit_rate': 0.9523809523809523}]\n",
      "the Prediction of year 2022 of AES is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.083213510373697e-05, 'rmse': 0.007129665847971907, 'mae': 0.0015631084472818714, 'hit_rate': 0.9799196787148594}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1400531888395603e-05, 'rmse': 0.004626070890982498, 'mae': 0.0016608331660061613, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0004459850534154339, 'rmse': 0.021118358208332244, 'mae': 0.0059316049443478664, 'hit_rate': 0.9285714285714286}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001703958973970791, 'rmse': 0.013053577953843884, 'mae': 0.007033869516784393, 'hit_rate': 0.9203187250996016}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4353074818857749e-05, 'rmse': 0.0037885452114047352, 'mae': 0.0020697022045502917, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.80232721958497e-05, 'rmse': 0.007617300847140652, 'mae': 0.003431658659242667, 'hit_rate': 0.963855421686747}]\n",
      "the Prediction of year 2017 of RF is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4536116523786435e-05, 'rmse': 0.003812625935465796, 'mae': 0.0017166287891883178, 'hit_rate': 0.9518072289156626}]\n",
      "the Prediction of year 2018 of RF is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4536116523786435e-05, 'rmse': 0.003812625935465796, 'mae': 0.0017166287891883178, 'hit_rate': 0.9518072289156626}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.958007572463927e-05, 'rmse': 0.005438756817935444, 'mae': 0.0025038246762871135, 'hit_rate': 0.9402390438247012}]\n",
      "the Prediction of year 2019 of RF is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4536116523786435e-05, 'rmse': 0.003812625935465796, 'mae': 0.0017166287891883178, 'hit_rate': 0.9518072289156626}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.958007572463927e-05, 'rmse': 0.005438756817935444, 'mae': 0.0025038246762871135, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.000536780373650481, 'rmse': 0.02316852117961958, 'mae': 0.007436082401253418, 'hit_rate': 0.9484126984126984}]\n",
      "the Prediction of year 2020 of RF is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4536116523786435e-05, 'rmse': 0.003812625935465796, 'mae': 0.0017166287891883178, 'hit_rate': 0.9518072289156626}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.958007572463927e-05, 'rmse': 0.005438756817935444, 'mae': 0.0025038246762871135, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.000536780373650481, 'rmse': 0.02316852117961958, 'mae': 0.007436082401253418, 'hit_rate': 0.9484126984126984}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002500993036449941, 'rmse': 0.015814528246046233, 'mae': 0.008332605700043356, 'hit_rate': 0.9163346613545816}]\n",
      "the Prediction of year 2021 of RF is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4536116523786435e-05, 'rmse': 0.003812625935465796, 'mae': 0.0017166287891883178, 'hit_rate': 0.9518072289156626}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.958007572463927e-05, 'rmse': 0.005438756817935444, 'mae': 0.0025038246762871135, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.000536780373650481, 'rmse': 0.02316852117961958, 'mae': 0.007436082401253418, 'hit_rate': 0.9484126984126984}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002500993036449941, 'rmse': 0.015814528246046233, 'mae': 0.008332605700043356, 'hit_rate': 0.9163346613545816}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.736500063623158e-05, 'rmse': 0.006112691766826754, 'mae': 0.0030446500501946487, 'hit_rate': 0.9563492063492064}]\n",
      "the Prediction of year 2022 of RF is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4536116523786435e-05, 'rmse': 0.003812625935465796, 'mae': 0.0017166287891883178, 'hit_rate': 0.9518072289156626}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.958007572463927e-05, 'rmse': 0.005438756817935444, 'mae': 0.0025038246762871135, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.000536780373650481, 'rmse': 0.02316852117961958, 'mae': 0.007436082401253418, 'hit_rate': 0.9484126984126984}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002500993036449941, 'rmse': 0.015814528246046233, 'mae': 0.008332605700043356, 'hit_rate': 0.9163346613545816}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.736500063623158e-05, 'rmse': 0.006112691766826754, 'mae': 0.0030446500501946487, 'hit_rate': 0.9563492063492064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.150505026290386e-05, 'rmse': 0.009028014746493488, 'mae': 0.0038752695970655834, 'hit_rate': 0.9477911646586346}]\n",
      "the Prediction of year 2017 of WMT is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.606580331725343e-05, 'rmse': 0.008721571149583853, 'mae': 0.002495751109144099, 'hit_rate': 0.9116465863453815}]\n",
      "the Prediction of year 2018 of WMT is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.606580331725343e-05, 'rmse': 0.008721571149583853, 'mae': 0.002495751109144099, 'hit_rate': 0.9116465863453815}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.270550763849557e-05, 'rmse': 0.007259855896537862, 'mae': 0.001869948442230734, 'hit_rate': 0.9721115537848606}]\n",
      "the Prediction of year 2019 of WMT is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.606580331725343e-05, 'rmse': 0.008721571149583853, 'mae': 0.002495751109144099, 'hit_rate': 0.9116465863453815}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.270550763849557e-05, 'rmse': 0.007259855896537862, 'mae': 0.001869948442230734, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011988237604114235, 'rmse': 0.010949081059209597, 'mae': 0.003464051904253451, 'hit_rate': 0.9444444444444444}]\n",
      "the Prediction of year 2020 of WMT is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.606580331725343e-05, 'rmse': 0.008721571149583853, 'mae': 0.002495751109144099, 'hit_rate': 0.9116465863453815}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.270550763849557e-05, 'rmse': 0.007259855896537862, 'mae': 0.001869948442230734, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011988237604114235, 'rmse': 0.010949081059209597, 'mae': 0.003464051904253451, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.441847671993521e-05, 'rmse': 0.005866726235298116, 'mae': 0.002603651324292475, 'hit_rate': 0.9601593625498008}]\n",
      "the Prediction of year 2021 of WMT is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.606580331725343e-05, 'rmse': 0.008721571149583853, 'mae': 0.002495751109144099, 'hit_rate': 0.9116465863453815}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.270550763849557e-05, 'rmse': 0.007259855896537862, 'mae': 0.001869948442230734, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011988237604114235, 'rmse': 0.010949081059209597, 'mae': 0.003464051904253451, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.441847671993521e-05, 'rmse': 0.005866726235298116, 'mae': 0.002603651324292475, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.618314901679564e-06, 'rmse': 0.0029356966637715766, 'mae': 0.0012665830721802006, 'hit_rate': 0.9642857142857143}]\n",
      "the Prediction of year 2022 of WMT is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.606580331725343e-05, 'rmse': 0.008721571149583853, 'mae': 0.002495751109144099, 'hit_rate': 0.9116465863453815}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.270550763849557e-05, 'rmse': 0.007259855896537862, 'mae': 0.001869948442230734, 'hit_rate': 0.9721115537848606}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011988237604114235, 'rmse': 0.010949081059209597, 'mae': 0.003464051904253451, 'hit_rate': 0.9444444444444444}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.441847671993521e-05, 'rmse': 0.005866726235298116, 'mae': 0.002603651324292475, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.618314901679564e-06, 'rmse': 0.0029356966637715766, 'mae': 0.0012665830721802006, 'hit_rate': 0.9642857142857143}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.403610695616863e-05, 'rmse': 0.009167120974230057, 'mae': 0.0029440902447240374, 'hit_rate': 0.9236947791164659}]\n",
      "the Prediction of year 2017 of LNT is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1514768688058622e-06, 'rmse': 0.0017752399468257418, 'mae': 0.0009175476613583582, 'hit_rate': 0.9678714859437751}]\n",
      "the Prediction of year 2018 of LNT is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1514768688058622e-06, 'rmse': 0.0017752399468257418, 'mae': 0.0009175476613583582, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.1023562420896506e-05, 'rmse': 0.003320175058772731, 'mae': 0.001403019387208115, 'hit_rate': 0.952191235059761}]\n",
      "the Prediction of year 2019 of LNT is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1514768688058622e-06, 'rmse': 0.0017752399468257418, 'mae': 0.0009175476613583582, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.1023562420896506e-05, 'rmse': 0.003320175058772731, 'mae': 0.001403019387208115, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00017860271304030834, 'rmse': 0.013364232601998078, 'mae': 0.004511953462377182, 'hit_rate': 0.9761904761904762}]\n",
      "the Prediction of year 2020 of LNT is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1514768688058622e-06, 'rmse': 0.0017752399468257418, 'mae': 0.0009175476613583582, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.1023562420896506e-05, 'rmse': 0.003320175058772731, 'mae': 0.001403019387208115, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00017860271304030834, 'rmse': 0.013364232601998078, 'mae': 0.004511953462377182, 'hit_rate': 0.9761904761904762}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.47492597622154e-05, 'rmse': 0.0073992742726713, 'mae': 0.004128924981786499, 'hit_rate': 0.9282868525896414}]\n",
      "the Prediction of year 2021 of LNT is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1514768688058622e-06, 'rmse': 0.0017752399468257418, 'mae': 0.0009175476613583582, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.1023562420896506e-05, 'rmse': 0.003320175058772731, 'mae': 0.001403019387208115, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00017860271304030834, 'rmse': 0.013364232601998078, 'mae': 0.004511953462377182, 'hit_rate': 0.9761904761904762}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.47492597622154e-05, 'rmse': 0.0073992742726713, 'mae': 0.004128924981786499, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.420016638809588e-06, 'rmse': 0.002328092918852164, 'mae': 0.0012344296566076044, 'hit_rate': 0.9801587301587301}]\n",
      "the Prediction of year 2022 of LNT is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.1514768688058622e-06, 'rmse': 0.0017752399468257418, 'mae': 0.0009175476613583582, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.1023562420896506e-05, 'rmse': 0.003320175058772731, 'mae': 0.001403019387208115, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00017860271304030834, 'rmse': 0.013364232601998078, 'mae': 0.004511953462377182, 'hit_rate': 0.9761904761904762}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.47492597622154e-05, 'rmse': 0.0073992742726713, 'mae': 0.004128924981786499, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.420016638809588e-06, 'rmse': 0.002328092918852164, 'mae': 0.0012344296566076044, 'hit_rate': 0.9801587301587301}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.944341425019929e-05, 'rmse': 0.004409468703846223, 'mae': 0.0023252070466303286, 'hit_rate': 0.9477911646586346}]\n",
      "the Prediction of year 2017 of COF is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.6340033254723152e-05, 'rmse': 0.005132254207921033, 'mae': 0.002042839488045769, 'hit_rate': 0.9558232931726908}]\n",
      "the Prediction of year 2018 of COF is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.6340033254723152e-05, 'rmse': 0.005132254207921033, 'mae': 0.002042839488045769, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1025140429092945e-05, 'rmse': 0.004585317920176631, 'mae': 0.002244408192491136, 'hit_rate': 0.9482071713147411}]\n",
      "the Prediction of year 2019 of COF is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.6340033254723152e-05, 'rmse': 0.005132254207921033, 'mae': 0.002042839488045769, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1025140429092945e-05, 'rmse': 0.004585317920176631, 'mae': 0.002244408192491136, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0006210930475936307, 'rmse': 0.024921738454482478, 'mae': 0.007432787367734263, 'hit_rate': 0.9682539682539683}]\n",
      "the Prediction of year 2020 of COF is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.6340033254723152e-05, 'rmse': 0.005132254207921033, 'mae': 0.002042839488045769, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1025140429092945e-05, 'rmse': 0.004585317920176631, 'mae': 0.002244408192491136, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0006210930475936307, 'rmse': 0.024921738454482478, 'mae': 0.007432787367734263, 'hit_rate': 0.9682539682539683}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00031567025528392696, 'rmse': 0.017767111619054095, 'mae': 0.009390770127952485, 'hit_rate': 0.9163346613545816}]\n",
      "the Prediction of year 2021 of COF is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.6340033254723152e-05, 'rmse': 0.005132254207921033, 'mae': 0.002042839488045769, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1025140429092945e-05, 'rmse': 0.004585317920176631, 'mae': 0.002244408192491136, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0006210930475936307, 'rmse': 0.024921738454482478, 'mae': 0.007432787367734263, 'hit_rate': 0.9682539682539683}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00031567025528392696, 'rmse': 0.017767111619054095, 'mae': 0.009390770127952485, 'hit_rate': 0.9163346613545816}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.576414339302775e-05, 'rmse': 0.005980312984537494, 'mae': 0.0030598543154690748, 'hit_rate': 0.9682539682539683}]\n",
      "the Prediction of year 2022 of COF is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.6340033254723152e-05, 'rmse': 0.005132254207921033, 'mae': 0.002042839488045769, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1025140429092945e-05, 'rmse': 0.004585317920176631, 'mae': 0.002244408192491136, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0006210930475936307, 'rmse': 0.024921738454482478, 'mae': 0.007432787367734263, 'hit_rate': 0.9682539682539683}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00031567025528392696, 'rmse': 0.017767111619054095, 'mae': 0.009390770127952485, 'hit_rate': 0.9163346613545816}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.576414339302775e-05, 'rmse': 0.005980312984537494, 'mae': 0.0030598543154690748, 'hit_rate': 0.9682539682539683}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.636039928356851e-05, 'rmse': 0.008146189249186917, 'mae': 0.004794478104683091, 'hit_rate': 0.9397590361445783}]\n",
      "the Prediction of year 2017 of EXR is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.882758632585704e-06, 'rmse': 0.002980395717448558, 'mae': 0.0012822454160724142, 'hit_rate': 0.9558232931726908}]\n",
      "the Prediction of year 2018 of EXR is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.882758632585704e-06, 'rmse': 0.002980395717448558, 'mae': 0.0012822454160724142, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.38842726391397e-06, 'rmse': 0.0023212986158428583, 'mae': 0.0010896736781895622, 'hit_rate': 0.9920318725099602}]\n",
      "the Prediction of year 2019 of EXR is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.882758632585704e-06, 'rmse': 0.002980395717448558, 'mae': 0.0012822454160724142, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.38842726391397e-06, 'rmse': 0.0023212986158428583, 'mae': 0.0010896736781895622, 'hit_rate': 0.9920318725099602}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015842031960092826, 'rmse': 0.012586513401293, 'mae': 0.003770456400197471, 'hit_rate': 0.9722222222222222}]\n",
      "the Prediction of year 2020 of EXR is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.882758632585704e-06, 'rmse': 0.002980395717448558, 'mae': 0.0012822454160724142, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.38842726391397e-06, 'rmse': 0.0023212986158428583, 'mae': 0.0010896736781895622, 'hit_rate': 0.9920318725099602}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015842031960092826, 'rmse': 0.012586513401293, 'mae': 0.003770456400197471, 'hit_rate': 0.9722222222222222}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.760509266844224e-05, 'rmse': 0.008809375271177988, 'mae': 0.004984285729991536, 'hit_rate': 0.9402390438247012}]\n",
      "the Prediction of year 2021 of EXR is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.882758632585704e-06, 'rmse': 0.002980395717448558, 'mae': 0.0012822454160724142, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.38842726391397e-06, 'rmse': 0.0023212986158428583, 'mae': 0.0010896736781895622, 'hit_rate': 0.9920318725099602}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015842031960092826, 'rmse': 0.012586513401293, 'mae': 0.003770456400197471, 'hit_rate': 0.9722222222222222}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.760509266844224e-05, 'rmse': 0.008809375271177988, 'mae': 0.004984285729991536, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.2230930488326197e-05, 'rmse': 0.0034972747230273744, 'mae': 0.001710473813798376, 'hit_rate': 0.9523809523809523}]\n",
      "the Prediction of year 2022 of EXR is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.882758632585704e-06, 'rmse': 0.002980395717448558, 'mae': 0.0012822454160724142, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.38842726391397e-06, 'rmse': 0.0023212986158428583, 'mae': 0.0010896736781895622, 'hit_rate': 0.9920318725099602}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00015842031960092826, 'rmse': 0.012586513401293, 'mae': 0.003770456400197471, 'hit_rate': 0.9722222222222222}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.760509266844224e-05, 'rmse': 0.008809375271177988, 'mae': 0.004984285729991536, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.2230930488326197e-05, 'rmse': 0.0034972747230273744, 'mae': 0.001710473813798376, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.405208303539262e-05, 'rmse': 0.008003254527715123, 'mae': 0.0039486521638104465, 'hit_rate': 0.9477911646586346}]\n",
      "the Prediction of year 2017 of PCAR is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.7273781200810904e-05, 'rmse': 0.004156173865565649, 'mae': 0.002053484231421776, 'hit_rate': 0.9718875502008032}]\n",
      "the Prediction of year 2018 of PCAR is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.7273781200810904e-05, 'rmse': 0.004156173865565649, 'mae': 0.002053484231421776, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.4465283645250273e-05, 'rmse': 0.004946239343708538, 'mae': 0.0025158624732279805, 'hit_rate': 0.9601593625498008}]\n",
      "the Prediction of year 2019 of PCAR is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.7273781200810904e-05, 'rmse': 0.004156173865565649, 'mae': 0.002053484231421776, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.4465283645250273e-05, 'rmse': 0.004946239343708538, 'mae': 0.0025158624732279805, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00016786602207441128, 'rmse': 0.012956312055303827, 'mae': 0.005079234942964089, 'hit_rate': 0.9404761904761905}]\n",
      "the Prediction of year 2020 of PCAR is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.7273781200810904e-05, 'rmse': 0.004156173865565649, 'mae': 0.002053484231421776, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.4465283645250273e-05, 'rmse': 0.004946239343708538, 'mae': 0.0025158624732279805, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00016786602207441128, 'rmse': 0.012956312055303827, 'mae': 0.005079234942964089, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.924312944368522e-05, 'rmse': 0.007017344899866702, 'mae': 0.0033898836433721474, 'hit_rate': 0.952191235059761}]\n",
      "the Prediction of year 2021 of PCAR is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.7273781200810904e-05, 'rmse': 0.004156173865565649, 'mae': 0.002053484231421776, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.4465283645250273e-05, 'rmse': 0.004946239343708538, 'mae': 0.0025158624732279805, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00016786602207441128, 'rmse': 0.012956312055303827, 'mae': 0.005079234942964089, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.924312944368522e-05, 'rmse': 0.007017344899866702, 'mae': 0.0033898836433721474, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4111882233817191e-05, 'rmse': 0.0037565785275722897, 'mae': 0.0019097681250853785, 'hit_rate': 0.9563492063492064}]\n",
      "the Prediction of year 2022 of PCAR is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.7273781200810904e-05, 'rmse': 0.004156173865565649, 'mae': 0.002053484231421776, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.4465283645250273e-05, 'rmse': 0.004946239343708538, 'mae': 0.0025158624732279805, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00016786602207441128, 'rmse': 0.012956312055303827, 'mae': 0.005079234942964089, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.924312944368522e-05, 'rmse': 0.007017344899866702, 'mae': 0.0033898836433721474, 'hit_rate': 0.952191235059761}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4111882233817191e-05, 'rmse': 0.0037565785275722897, 'mae': 0.0019097681250853785, 'hit_rate': 0.9563492063492064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.219273141387037e-05, 'rmse': 0.004710916196863448, 'mae': 0.0023471223910703203, 'hit_rate': 0.9718875502008032}]\n",
      "the Prediction of year 2017 of EIX is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.689853228728121e-05, 'rmse': 0.008769180821905842, 'mae': 0.0021027961249176154, 'hit_rate': 0.9558232931726908}]\n",
      "the Prediction of year 2018 of EIX is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.689853228728121e-05, 'rmse': 0.008769180821905842, 'mae': 0.0021027961249176154, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00020382003734985453, 'rmse': 0.0142765555141937, 'mae': 0.003694727445132464, 'hit_rate': 0.9203187250996016}]\n",
      "the Prediction of year 2019 of EIX is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.689853228728121e-05, 'rmse': 0.008769180821905842, 'mae': 0.0021027961249176154, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00020382003734985453, 'rmse': 0.0142765555141937, 'mae': 0.003694727445132464, 'hit_rate': 0.9203187250996016}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00021844550216577484, 'rmse': 0.014779901967393925, 'mae': 0.00542330606377475, 'hit_rate': 0.9523809523809523}]\n",
      "the Prediction of year 2020 of EIX is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.689853228728121e-05, 'rmse': 0.008769180821905842, 'mae': 0.0021027961249176154, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00020382003734985453, 'rmse': 0.0142765555141937, 'mae': 0.003694727445132464, 'hit_rate': 0.9203187250996016}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00021844550216577484, 'rmse': 0.014779901967393925, 'mae': 0.00542330606377475, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.985840744972772e-05, 'rmse': 0.008936353140388294, 'mae': 0.004694490110691593, 'hit_rate': 0.9123505976095617}]\n",
      "the Prediction of year 2021 of EIX is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.689853228728121e-05, 'rmse': 0.008769180821905842, 'mae': 0.0021027961249176154, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00020382003734985453, 'rmse': 0.0142765555141937, 'mae': 0.003694727445132464, 'hit_rate': 0.9203187250996016}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00021844550216577484, 'rmse': 0.014779901967393925, 'mae': 0.00542330606377475, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.985840744972772e-05, 'rmse': 0.008936353140388294, 'mae': 0.004694490110691593, 'hit_rate': 0.9123505976095617}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.410966470728643e-06, 'rmse': 0.0025319886395338827, 'mae': 0.0011660082946331205, 'hit_rate': 0.9642857142857143}]\n",
      "the Prediction of year 2022 of EIX is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.689853228728121e-05, 'rmse': 0.008769180821905842, 'mae': 0.0021027961249176154, 'hit_rate': 0.9558232931726908}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00020382003734985453, 'rmse': 0.0142765555141937, 'mae': 0.003694727445132464, 'hit_rate': 0.9203187250996016}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00021844550216577484, 'rmse': 0.014779901967393925, 'mae': 0.00542330606377475, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.985840744972772e-05, 'rmse': 0.008936353140388294, 'mae': 0.004694490110691593, 'hit_rate': 0.9123505976095617}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.410966470728643e-06, 'rmse': 0.0025319886395338827, 'mae': 0.0011660082946331205, 'hit_rate': 0.9642857142857143}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.5082416127935317e-05, 'rmse': 0.005008234831548468, 'mae': 0.002444846608974081, 'hit_rate': 0.9678714859437751}]\n",
      "the Prediction of year 2017 of TMO is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.117999687827432e-05, 'rmse': 0.004602173060443764, 'mae': 0.0017941030921260774, 'hit_rate': 0.9678714859437751}]\n",
      "the Prediction of year 2018 of TMO is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.117999687827432e-05, 'rmse': 0.004602173060443764, 'mae': 0.0017941030921260774, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4581114643700862e-05, 'rmse': 0.003818522573417743, 'mae': 0.002035828713154284, 'hit_rate': 0.9601593625498008}]\n",
      "the Prediction of year 2019 of TMO is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.117999687827432e-05, 'rmse': 0.004602173060443764, 'mae': 0.0017941030921260774, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4581114643700862e-05, 'rmse': 0.003818522573417743, 'mae': 0.002035828713154284, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001647276698141296, 'rmse': 0.012834627762975037, 'mae': 0.005577130847708355, 'hit_rate': 0.9206349206349206}]\n",
      "the Prediction of year 2020 of TMO is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.117999687827432e-05, 'rmse': 0.004602173060443764, 'mae': 0.0017941030921260774, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4581114643700862e-05, 'rmse': 0.003818522573417743, 'mae': 0.002035828713154284, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001647276698141296, 'rmse': 0.012834627762975037, 'mae': 0.005577130847708355, 'hit_rate': 0.9206349206349206}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.093707187407383e-05, 'rmse': 0.007137021218552865, 'mae': 0.003925160759173868, 'hit_rate': 0.9243027888446215}]\n",
      "the Prediction of year 2021 of TMO is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.117999687827432e-05, 'rmse': 0.004602173060443764, 'mae': 0.0017941030921260774, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4581114643700862e-05, 'rmse': 0.003818522573417743, 'mae': 0.002035828713154284, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001647276698141296, 'rmse': 0.012834627762975037, 'mae': 0.005577130847708355, 'hit_rate': 0.9206349206349206}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.093707187407383e-05, 'rmse': 0.007137021218552865, 'mae': 0.003925160759173868, 'hit_rate': 0.9243027888446215}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.6733765126777386e-05, 'rmse': 0.004090692499660343, 'mae': 0.0016785537628235473, 'hit_rate': 0.9563492063492064}]\n",
      "the Prediction of year 2022 of TMO is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.117999687827432e-05, 'rmse': 0.004602173060443764, 'mae': 0.0017941030921260774, 'hit_rate': 0.9678714859437751}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.4581114643700862e-05, 'rmse': 0.003818522573417743, 'mae': 0.002035828713154284, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001647276698141296, 'rmse': 0.012834627762975037, 'mae': 0.005577130847708355, 'hit_rate': 0.9206349206349206}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.093707187407383e-05, 'rmse': 0.007137021218552865, 'mae': 0.003925160759173868, 'hit_rate': 0.9243027888446215}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.6733765126777386e-05, 'rmse': 0.004090692499660343, 'mae': 0.0016785537628235473, 'hit_rate': 0.9563492063492064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.204705203984178e-05, 'rmse': 0.005661011573901063, 'mae': 0.0027527161833166814, 'hit_rate': 0.9759036144578314}]\n",
      "the Prediction of year 2017 of FE is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.502378537211096e-05, 'rmse': 0.005918089672530398, 'mae': 0.0016068511646915582, 'hit_rate': 0.9477911646586346}]\n",
      "the Prediction of year 2018 of FE is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.502378537211096e-05, 'rmse': 0.005918089672530398, 'mae': 0.0016068511646915582, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.1684652450502045e-06, 'rmse': 0.0020416819647168863, 'mae': 0.0009812276051956554, 'hit_rate': 0.9482071713147411}]\n",
      "the Prediction of year 2019 of FE is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.502378537211096e-05, 'rmse': 0.005918089672530398, 'mae': 0.0016068511646915582, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.1684652450502045e-06, 'rmse': 0.0020416819647168863, 'mae': 0.0009812276051956554, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002855231864950716, 'rmse': 0.01689743135790383, 'mae': 0.004791548625918571, 'hit_rate': 0.9404761904761905}]\n",
      "the Prediction of year 2020 of FE is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.502378537211096e-05, 'rmse': 0.005918089672530398, 'mae': 0.0016068511646915582, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.1684652450502045e-06, 'rmse': 0.0020416819647168863, 'mae': 0.0009812276051956554, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002855231864950716, 'rmse': 0.01689743135790383, 'mae': 0.004791548625918571, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00032661247484476, 'rmse': 0.018072423048522298, 'mae': 0.007097626733029912, 'hit_rate': 0.9243027888446215}]\n",
      "the Prediction of year 2021 of FE is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.502378537211096e-05, 'rmse': 0.005918089672530398, 'mae': 0.0016068511646915582, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.1684652450502045e-06, 'rmse': 0.0020416819647168863, 'mae': 0.0009812276051956554, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002855231864950716, 'rmse': 0.01689743135790383, 'mae': 0.004791548625918571, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00032661247484476, 'rmse': 0.018072423048522298, 'mae': 0.007097626733029912, 'hit_rate': 0.9243027888446215}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.322713254356014e-06, 'rmse': 0.0027060512290708787, 'mae': 0.0010962251663632627, 'hit_rate': 0.9642857142857143}]\n",
      "the Prediction of year 2022 of FE is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.502378537211096e-05, 'rmse': 0.005918089672530398, 'mae': 0.0016068511646915582, 'hit_rate': 0.9477911646586346}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.1684652450502045e-06, 'rmse': 0.0020416819647168863, 'mae': 0.0009812276051956554, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002855231864950716, 'rmse': 0.01689743135790383, 'mae': 0.004791548625918571, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00032661247484476, 'rmse': 0.018072423048522298, 'mae': 0.007097626733029912, 'hit_rate': 0.9243027888446215}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.322713254356014e-06, 'rmse': 0.0027060512290708787, 'mae': 0.0010962251663632627, 'hit_rate': 0.9642857142857143}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.3748237199617603e-05, 'rmse': 0.0037078615399738974, 'mae': 0.001945431808402123, 'hit_rate': 0.9759036144578314}]\n",
      "the Prediction of year 2017 of RSG is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.0827832353357742e-05, 'rmse': 0.003290567178064861, 'mae': 0.0011447799027829296, 'hit_rate': 0.963855421686747}]\n",
      "the Prediction of year 2018 of RSG is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.0827832353357742e-05, 'rmse': 0.003290567178064861, 'mae': 0.0011447799027829296, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.886557818241257e-06, 'rmse': 0.0031442897160155673, 'mae': 0.0013319949148409955, 'hit_rate': 0.9641434262948207}]\n",
      "the Prediction of year 2019 of RSG is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.0827832353357742e-05, 'rmse': 0.003290567178064861, 'mae': 0.0011447799027829296, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.886557818241257e-06, 'rmse': 0.0031442897160155673, 'mae': 0.0013319949148409955, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00019979625668299912, 'rmse': 0.014134930374182928, 'mae': 0.004564757920071396, 'hit_rate': 0.9325396825396826}]\n",
      "the Prediction of year 2020 of RSG is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.0827832353357742e-05, 'rmse': 0.003290567178064861, 'mae': 0.0011447799027829296, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.886557818241257e-06, 'rmse': 0.0031442897160155673, 'mae': 0.0013319949148409955, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00019979625668299912, 'rmse': 0.014134930374182928, 'mae': 0.004564757920071396, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.061180117791725e-05, 'rmse': 0.008403082837739806, 'mae': 0.004510176580373845, 'hit_rate': 0.900398406374502}]\n",
      "the Prediction of year 2021 of RSG is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.0827832353357742e-05, 'rmse': 0.003290567178064861, 'mae': 0.0011447799027829296, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.886557818241257e-06, 'rmse': 0.0031442897160155673, 'mae': 0.0013319949148409955, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00019979625668299912, 'rmse': 0.014134930374182928, 'mae': 0.004564757920071396, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.061180117791725e-05, 'rmse': 0.008403082837739806, 'mae': 0.004510176580373845, 'hit_rate': 0.900398406374502}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.3201051164133957e-05, 'rmse': 0.0036333250837399557, 'mae': 0.0015766879985857894, 'hit_rate': 0.9523809523809523}]\n",
      "the Prediction of year 2022 of RSG is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.0827832353357742e-05, 'rmse': 0.003290567178064861, 'mae': 0.0011447799027829296, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.886557818241257e-06, 'rmse': 0.0031442897160155673, 'mae': 0.0013319949148409955, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00019979625668299912, 'rmse': 0.014134930374182928, 'mae': 0.004564757920071396, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.061180117791725e-05, 'rmse': 0.008403082837739806, 'mae': 0.004510176580373845, 'hit_rate': 0.900398406374502}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.3201051164133957e-05, 'rmse': 0.0036333250837399557, 'mae': 0.0015766879985857894, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.1091602393138778e-05, 'rmse': 0.0033304057400170895, 'mae': 0.0018523997962895796, 'hit_rate': 0.9437751004016064}]\n",
      "the Prediction of year 2017 of DOV is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9924606333420915e-05, 'rmse': 0.0044636987278960615, 'mae': 0.0015450748268909925, 'hit_rate': 0.9718875502008032}]\n",
      "the Prediction of year 2018 of DOV is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9924606333420915e-05, 'rmse': 0.0044636987278960615, 'mae': 0.0015450748268909925, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0176567522222363e-05, 'rmse': 0.005493320263940777, 'mae': 0.0021056427281686482, 'hit_rate': 0.9402390438247012}]\n",
      "the Prediction of year 2019 of DOV is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9924606333420915e-05, 'rmse': 0.0044636987278960615, 'mae': 0.0015450748268909925, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0176567522222363e-05, 'rmse': 0.005493320263940777, 'mae': 0.0021056427281686482, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00031926164273605225, 'rmse': 0.017867894188629288, 'mae': 0.006086866898051208, 'hit_rate': 0.9325396825396826}]\n",
      "the Prediction of year 2020 of DOV is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9924606333420915e-05, 'rmse': 0.0044636987278960615, 'mae': 0.0015450748268909925, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0176567522222363e-05, 'rmse': 0.005493320263940777, 'mae': 0.0021056427281686482, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00031926164273605225, 'rmse': 0.017867894188629288, 'mae': 0.006086866898051208, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.813789251155601e-05, 'rmse': 0.007624820818324586, 'mae': 0.0033941533892001717, 'hit_rate': 0.9282868525896414}]\n",
      "the Prediction of year 2021 of DOV is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9924606333420915e-05, 'rmse': 0.0044636987278960615, 'mae': 0.0015450748268909925, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0176567522222363e-05, 'rmse': 0.005493320263940777, 'mae': 0.0021056427281686482, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00031926164273605225, 'rmse': 0.017867894188629288, 'mae': 0.006086866898051208, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.813789251155601e-05, 'rmse': 0.007624820818324586, 'mae': 0.0033941533892001717, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.386370919996242e-05, 'rmse': 0.00372340022022377, 'mae': 0.0017524055839472205, 'hit_rate': 0.9603174603174603}]\n",
      "the Prediction of year 2022 of DOV is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.9924606333420915e-05, 'rmse': 0.0044636987278960615, 'mae': 0.0015450748268909925, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0176567522222363e-05, 'rmse': 0.005493320263940777, 'mae': 0.0021056427281686482, 'hit_rate': 0.9402390438247012}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00031926164273605225, 'rmse': 0.017867894188629288, 'mae': 0.006086866898051208, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.813789251155601e-05, 'rmse': 0.007624820818324586, 'mae': 0.0033941533892001717, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.386370919996242e-05, 'rmse': 0.00372340022022377, 'mae': 0.0017524055839472205, 'hit_rate': 0.9603174603174603}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.611312832138109e-05, 'rmse': 0.004014116132024719, 'mae': 0.0022883846652244242, 'hit_rate': 0.9718875502008032}]\n",
      "the Prediction of year 2017 of AMT is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.14636120511388e-06, 'rmse': 0.00302429515839871, 'mae': 0.001257243130077066, 'hit_rate': 0.9718875502008032}]\n",
      "the Prediction of year 2018 of AMT is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.14636120511388e-06, 'rmse': 0.00302429515839871, 'mae': 0.001257243130077066, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.043143826932146e-06, 'rmse': 0.0028360436927050586, 'mae': 0.0012273636739180396, 'hit_rate': 0.9840637450199203}]\n",
      "the Prediction of year 2019 of AMT is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.14636120511388e-06, 'rmse': 0.00302429515839871, 'mae': 0.001257243130077066, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.043143826932146e-06, 'rmse': 0.0028360436927050586, 'mae': 0.0012273636739180396, 'hit_rate': 0.9840637450199203}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002773837268080937, 'rmse': 0.01665484094214333, 'mae': 0.005428511200703536, 'hit_rate': 0.9325396825396826}]\n",
      "the Prediction of year 2020 of AMT is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.14636120511388e-06, 'rmse': 0.00302429515839871, 'mae': 0.001257243130077066, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.043143826932146e-06, 'rmse': 0.0028360436927050586, 'mae': 0.0012273636739180396, 'hit_rate': 0.9840637450199203}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002773837268080937, 'rmse': 0.01665484094214333, 'mae': 0.005428511200703536, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.6037426446185865e-05, 'rmse': 0.007485815015493361, 'mae': 0.003944398346316217, 'hit_rate': 0.9442231075697212}]\n",
      "the Prediction of year 2021 of AMT is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.14636120511388e-06, 'rmse': 0.00302429515839871, 'mae': 0.001257243130077066, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.043143826932146e-06, 'rmse': 0.0028360436927050586, 'mae': 0.0012273636739180396, 'hit_rate': 0.9840637450199203}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002773837268080937, 'rmse': 0.01665484094214333, 'mae': 0.005428511200703536, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.6037426446185865e-05, 'rmse': 0.007485815015493361, 'mae': 0.003944398346316217, 'hit_rate': 0.9442231075697212}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.195020130260582e-05, 'rmse': 0.0034569063196166917, 'mae': 0.0018403528368533125, 'hit_rate': 0.9603174603174603}]\n",
      "the Prediction of year 2022 of AMT is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.14636120511388e-06, 'rmse': 0.00302429515839871, 'mae': 0.001257243130077066, 'hit_rate': 0.9718875502008032}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.043143826932146e-06, 'rmse': 0.0028360436927050586, 'mae': 0.0012273636739180396, 'hit_rate': 0.9840637450199203}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002773837268080937, 'rmse': 0.01665484094214333, 'mae': 0.005428511200703536, 'hit_rate': 0.9325396825396826}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.6037426446185865e-05, 'rmse': 0.007485815015493361, 'mae': 0.003944398346316217, 'hit_rate': 0.9442231075697212}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.195020130260582e-05, 'rmse': 0.0034569063196166917, 'mae': 0.0018403528368533125, 'hit_rate': 0.9603174603174603}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.110495905144646e-05, 'rmse': 0.005577181999132399, 'mae': 0.0029745301420602025, 'hit_rate': 0.9397590361445783}]\n",
      "the Prediction of year 2017 of VZ is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.765833675857249e-05, 'rmse': 0.005259119390028381, 'mae': 0.0019524342872681137, 'hit_rate': 0.9236947791164659}]\n",
      "the Prediction of year 2018 of VZ is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.765833675857249e-05, 'rmse': 0.005259119390028381, 'mae': 0.0019524342872681137, 'hit_rate': 0.9236947791164659}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.606117667026052e-05, 'rmse': 0.004007639787987504, 'mae': 0.0020139187021980423, 'hit_rate': 0.9561752988047809}]\n",
      "the Prediction of year 2019 of VZ is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.765833675857249e-05, 'rmse': 0.005259119390028381, 'mae': 0.0019524342872681137, 'hit_rate': 0.9236947791164659}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.606117667026052e-05, 'rmse': 0.004007639787987504, 'mae': 0.0020139187021980423, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.821835873513214e-05, 'rmse': 0.008259440582456668, 'mae': 0.0030975192363178086, 'hit_rate': 0.9404761904761905}]\n",
      "the Prediction of year 2020 of VZ is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.765833675857249e-05, 'rmse': 0.005259119390028381, 'mae': 0.0019524342872681137, 'hit_rate': 0.9236947791164659}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.606117667026052e-05, 'rmse': 0.004007639787987504, 'mae': 0.0020139187021980423, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.821835873513214e-05, 'rmse': 0.008259440582456668, 'mae': 0.0030975192363178086, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.435641466063234e-06, 'rmse': 0.0030717489262736355, 'mae': 0.001476843509955414, 'hit_rate': 0.9561752988047809}]\n",
      "the Prediction of year 2021 of VZ is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.765833675857249e-05, 'rmse': 0.005259119390028381, 'mae': 0.0019524342872681137, 'hit_rate': 0.9236947791164659}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.606117667026052e-05, 'rmse': 0.004007639787987504, 'mae': 0.0020139187021980423, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.821835873513214e-05, 'rmse': 0.008259440582456668, 'mae': 0.0030975192363178086, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.435641466063234e-06, 'rmse': 0.0030717489262736355, 'mae': 0.001476843509955414, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.675444860153914e-06, 'rmse': 0.0021622777019046175, 'mae': 0.0010422241390898386, 'hit_rate': 0.9603174603174603}]\n",
      "the Prediction of year 2022 of VZ is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.765833675857249e-05, 'rmse': 0.005259119390028381, 'mae': 0.0019524342872681137, 'hit_rate': 0.9236947791164659}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.606117667026052e-05, 'rmse': 0.004007639787987504, 'mae': 0.0020139187021980423, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.821835873513214e-05, 'rmse': 0.008259440582456668, 'mae': 0.0030975192363178086, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.435641466063234e-06, 'rmse': 0.0030717489262736355, 'mae': 0.001476843509955414, 'hit_rate': 0.9561752988047809}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 4.675444860153914e-06, 'rmse': 0.0021622777019046175, 'mae': 0.0010422241390898386, 'hit_rate': 0.9603174603174603}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.308526071270113e-05, 'rmse': 0.005751978851899677, 'mae': 0.002938451464946501, 'hit_rate': 0.9397590361445783}]\n",
      "the Prediction of year 2017 of NUE is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2896587040763638e-05, 'rmse': 0.004785037830651252, 'mae': 0.002149690369927593, 'hit_rate': 0.963855421686747}]\n",
      "the Prediction of year 2018 of NUE is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2896587040763638e-05, 'rmse': 0.004785037830651252, 'mae': 0.002149690369927593, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.567247161003841e-05, 'rmse': 0.003958847257730261, 'mae': 0.002228789750703896, 'hit_rate': 0.9641434262948207}]\n",
      "the Prediction of year 2019 of NUE is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2896587040763638e-05, 'rmse': 0.004785037830651252, 'mae': 0.002149690369927593, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.567247161003841e-05, 'rmse': 0.003958847257730261, 'mae': 0.002228789750703896, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00023570222521053405, 'rmse': 0.015352596692759634, 'mae': 0.005794196389972474, 'hit_rate': 0.9206349206349206}]\n",
      "the Prediction of year 2020 of NUE is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2896587040763638e-05, 'rmse': 0.004785037830651252, 'mae': 0.002149690369927593, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.567247161003841e-05, 'rmse': 0.003958847257730261, 'mae': 0.002228789750703896, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00023570222521053405, 'rmse': 0.015352596692759634, 'mae': 0.005794196389972474, 'hit_rate': 0.9206349206349206}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001035263646840722, 'rmse': 0.010174790645712186, 'mae': 0.0049635863106976055, 'hit_rate': 0.9322709163346613}]\n",
      "the Prediction of year 2021 of NUE is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2896587040763638e-05, 'rmse': 0.004785037830651252, 'mae': 0.002149690369927593, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.567247161003841e-05, 'rmse': 0.003958847257730261, 'mae': 0.002228789750703896, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00023570222521053405, 'rmse': 0.015352596692759634, 'mae': 0.005794196389972474, 'hit_rate': 0.9206349206349206}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001035263646840722, 'rmse': 0.010174790645712186, 'mae': 0.0049635863106976055, 'hit_rate': 0.9322709163346613}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.348936770087543e-05, 'rmse': 0.009137251649203683, 'mae': 0.00532944801533849, 'hit_rate': 0.9206349206349206}]\n",
      "the Prediction of year 2022 of NUE is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.2896587040763638e-05, 'rmse': 0.004785037830651252, 'mae': 0.002149690369927593, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.567247161003841e-05, 'rmse': 0.003958847257730261, 'mae': 0.002228789750703896, 'hit_rate': 0.9641434262948207}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00023570222521053405, 'rmse': 0.015352596692759634, 'mae': 0.005794196389972474, 'hit_rate': 0.9206349206349206}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0001035263646840722, 'rmse': 0.010174790645712186, 'mae': 0.0049635863106976055, 'hit_rate': 0.9322709163346613}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 8.348936770087543e-05, 'rmse': 0.009137251649203683, 'mae': 0.00532944801533849, 'hit_rate': 0.9206349206349206}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.14208104306037e-05, 'rmse': 0.008451083387980722, 'mae': 0.00408681587070431, 'hit_rate': 0.9518072289156626}]\n",
      "the Prediction of year 2017 of OKE is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.947293298307269e-06, 'rmse': 0.00198677963003129, 'mae': 0.0010731546340576519, 'hit_rate': 0.9759036144578314}]\n",
      "the Prediction of year 2018 of OKE is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.947293298307269e-06, 'rmse': 0.00198677963003129, 'mae': 0.0010731546340576519, 'hit_rate': 0.9759036144578314}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.784285234061452e-06, 'rmse': 0.002405054102106947, 'mae': 0.0014762053507938056, 'hit_rate': 0.9601593625498008}]\n",
      "the Prediction of year 2019 of OKE is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.947293298307269e-06, 'rmse': 0.00198677963003129, 'mae': 0.0010731546340576519, 'hit_rate': 0.9759036144578314}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.784285234061452e-06, 'rmse': 0.002405054102106947, 'mae': 0.0014762053507938056, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0019404238352778813, 'rmse': 0.0440502421704794, 'mae': 0.01019411983461547, 'hit_rate': 0.9722222222222222}]\n",
      "the Prediction of year 2020 of OKE is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.947293298307269e-06, 'rmse': 0.00198677963003129, 'mae': 0.0010731546340576519, 'hit_rate': 0.9759036144578314}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.784285234061452e-06, 'rmse': 0.002405054102106947, 'mae': 0.0014762053507938056, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0019404238352778813, 'rmse': 0.0440502421704794, 'mae': 0.01019411983461547, 'hit_rate': 0.9722222222222222}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00046957840374404174, 'rmse': 0.021669757814614398, 'mae': 0.012508353152153474, 'hit_rate': 0.9123505976095617}]\n",
      "the Prediction of year 2021 of OKE is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.947293298307269e-06, 'rmse': 0.00198677963003129, 'mae': 0.0010731546340576519, 'hit_rate': 0.9759036144578314}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.784285234061452e-06, 'rmse': 0.002405054102106947, 'mae': 0.0014762053507938056, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0019404238352778813, 'rmse': 0.0440502421704794, 'mae': 0.01019411983461547, 'hit_rate': 0.9722222222222222}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00046957840374404174, 'rmse': 0.021669757814614398, 'mae': 0.012508353152153474, 'hit_rate': 0.9123505976095617}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.7452492600943794e-05, 'rmse': 0.005239512630096792, 'mae': 0.0020643305325374526, 'hit_rate': 0.9722222222222222}]\n",
      "the Prediction of year 2022 of OKE is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.947293298307269e-06, 'rmse': 0.00198677963003129, 'mae': 0.0010731546340576519, 'hit_rate': 0.9759036144578314}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.784285234061452e-06, 'rmse': 0.002405054102106947, 'mae': 0.0014762053507938056, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0019404238352778813, 'rmse': 0.0440502421704794, 'mae': 0.01019411983461547, 'hit_rate': 0.9722222222222222}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00046957840374404174, 'rmse': 0.021669757814614398, 'mae': 0.012508353152153474, 'hit_rate': 0.9123505976095617}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.7452492600943794e-05, 'rmse': 0.005239512630096792, 'mae': 0.0020643305325374526, 'hit_rate': 0.9722222222222222}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 5.472211664019656e-05, 'rmse': 0.007397439870671242, 'mae': 0.003151679189153265, 'hit_rate': 0.9437751004016064}]\n",
      "the Prediction of year 2017 of WAB is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.458536967863112e-05, 'rmse': 0.008636282167613047, 'mae': 0.002223303008071066, 'hit_rate': 0.963855421686747}]\n",
      "the Prediction of year 2018 of WAB is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.458536967863112e-05, 'rmse': 0.008636282167613047, 'mae': 0.002223303008071066, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.18664412152191e-05, 'rmse': 0.009584698285038456, 'mae': 0.004013106198507935, 'hit_rate': 0.9482071713147411}]\n",
      "the Prediction of year 2019 of WAB is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.458536967863112e-05, 'rmse': 0.008636282167613047, 'mae': 0.002223303008071066, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.18664412152191e-05, 'rmse': 0.009584698285038456, 'mae': 0.004013106198507935, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003044175741744733, 'rmse': 0.017447566425564148, 'mae': 0.00629327510046138, 'hit_rate': 0.9166666666666666}]\n",
      "the Prediction of year 2020 of WAB is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.458536967863112e-05, 'rmse': 0.008636282167613047, 'mae': 0.002223303008071066, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.18664412152191e-05, 'rmse': 0.009584698285038456, 'mae': 0.004013106198507935, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003044175741744733, 'rmse': 0.017447566425564148, 'mae': 0.00629327510046138, 'hit_rate': 0.9166666666666666}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00016176599063212312, 'rmse': 0.012718725983058331, 'mae': 0.0060972848436150065, 'hit_rate': 0.9282868525896414}]\n",
      "the Prediction of year 2021 of WAB is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.458536967863112e-05, 'rmse': 0.008636282167613047, 'mae': 0.002223303008071066, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.18664412152191e-05, 'rmse': 0.009584698285038456, 'mae': 0.004013106198507935, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003044175741744733, 'rmse': 0.017447566425564148, 'mae': 0.00629327510046138, 'hit_rate': 0.9166666666666666}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00016176599063212312, 'rmse': 0.012718725983058331, 'mae': 0.0060972848436150065, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.2903994661919381e-05, 'rmse': 0.003592213059093152, 'mae': 0.0017400623613062444, 'hit_rate': 0.9682539682539683}]\n",
      "the Prediction of year 2022 of WAB is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 7.458536967863112e-05, 'rmse': 0.008636282167613047, 'mae': 0.002223303008071066, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 9.18664412152191e-05, 'rmse': 0.009584698285038456, 'mae': 0.004013106198507935, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003044175741744733, 'rmse': 0.017447566425564148, 'mae': 0.00629327510046138, 'hit_rate': 0.9166666666666666}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00016176599063212312, 'rmse': 0.012718725983058331, 'mae': 0.0060972848436150065, 'hit_rate': 0.9282868525896414}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.2903994661919381e-05, 'rmse': 0.003592213059093152, 'mae': 0.0017400623613062444, 'hit_rate': 0.9682539682539683}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.0066875815187222e-05, 'rmse': 0.0031728340352415573, 'mae': 0.001995490002513087, 'hit_rate': 0.9678714859437751}]\n",
      "the Prediction of year 2017 of BIIB is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.582554671896591e-05, 'rmse': 0.003978133572288129, 'mae': 0.0017540944306855338, 'hit_rate': 0.963855421686747}]\n",
      "the Prediction of year 2018 of BIIB is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.582554671896591e-05, 'rmse': 0.003978133572288129, 'mae': 0.0017540944306855338, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0005120811282304223, 'rmse': 0.02262920962451898, 'mae': 0.004603653088931783, 'hit_rate': 0.9681274900398407}]\n",
      "the Prediction of year 2019 of BIIB is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.582554671896591e-05, 'rmse': 0.003978133572288129, 'mae': 0.0017540944306855338, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0005120811282304223, 'rmse': 0.02262920962451898, 'mae': 0.004603653088931783, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00041700839377212565, 'rmse': 0.02042078337802264, 'mae': 0.0058704543030566655, 'hit_rate': 0.9563492063492064}]\n",
      "the Prediction of year 2020 of BIIB is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.582554671896591e-05, 'rmse': 0.003978133572288129, 'mae': 0.0017540944306855338, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0005120811282304223, 'rmse': 0.02262920962451898, 'mae': 0.004603653088931783, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00041700839377212565, 'rmse': 0.02042078337802264, 'mae': 0.0058704543030566655, 'hit_rate': 0.9563492063492064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.000901460369389682, 'rmse': 0.03002432962431771, 'mae': 0.0063783563195221465, 'hit_rate': 0.9601593625498008}]\n",
      "the Prediction of year 2021 of BIIB is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.582554671896591e-05, 'rmse': 0.003978133572288129, 'mae': 0.0017540944306855338, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0005120811282304223, 'rmse': 0.02262920962451898, 'mae': 0.004603653088931783, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00041700839377212565, 'rmse': 0.02042078337802264, 'mae': 0.0058704543030566655, 'hit_rate': 0.9563492063492064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.000901460369389682, 'rmse': 0.03002432962431771, 'mae': 0.0063783563195221465, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002969869451849534, 'rmse': 0.01723330917685148, 'mae': 0.0040269581116617915, 'hit_rate': 0.9523809523809523}]\n",
      "the Prediction of year 2022 of BIIB is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 1.582554671896591e-05, 'rmse': 0.003978133572288129, 'mae': 0.0017540944306855338, 'hit_rate': 0.963855421686747}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0005120811282304223, 'rmse': 0.02262920962451898, 'mae': 0.004603653088931783, 'hit_rate': 0.9681274900398407}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00041700839377212565, 'rmse': 0.02042078337802264, 'mae': 0.0058704543030566655, 'hit_rate': 0.9563492063492064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.000901460369389682, 'rmse': 0.03002432962431771, 'mae': 0.0063783563195221465, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0002969869451849534, 'rmse': 0.01723330917685148, 'mae': 0.0040269581116617915, 'hit_rate': 0.9523809523809523}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003797495476487715, 'rmse': 0.019487163663518905, 'mae': 0.0035669221743471918, 'hit_rate': 0.9839357429718876}]\n",
      "the Prediction of year 2017 of NTRS is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.11726138940344e-05, 'rmse': 0.005583244029597346, 'mae': 0.0023081400116187244, 'hit_rate': 0.9437751004016064}]\n",
      "the Prediction of year 2018 of NTRS is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.11726138940344e-05, 'rmse': 0.005583244029597346, 'mae': 0.0023081400116187244, 'hit_rate': 0.9437751004016064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0015037885228344e-05, 'rmse': 0.005478598167891887, 'mae': 0.0023011971886892895, 'hit_rate': 0.9482071713147411}]\n",
      "the Prediction of year 2019 of NTRS is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.11726138940344e-05, 'rmse': 0.005583244029597346, 'mae': 0.0023081400116187244, 'hit_rate': 0.9437751004016064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0015037885228344e-05, 'rmse': 0.005478598167891887, 'mae': 0.0023011971886892895, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003568014719957631, 'rmse': 0.018889189289002403, 'mae': 0.006013284759777948, 'hit_rate': 0.9404761904761905}]\n",
      "the Prediction of year 2020 of NTRS is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.11726138940344e-05, 'rmse': 0.005583244029597346, 'mae': 0.0023081400116187244, 'hit_rate': 0.9437751004016064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0015037885228344e-05, 'rmse': 0.005478598167891887, 'mae': 0.0023011971886892895, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003568014719957631, 'rmse': 0.018889189289002403, 'mae': 0.006013284759777948, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011102465275319365, 'rmse': 0.010536823655788952, 'mae': 0.006234175319955923, 'hit_rate': 0.9243027888446215}]\n",
      "the Prediction of year 2021 of NTRS is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.11726138940344e-05, 'rmse': 0.005583244029597346, 'mae': 0.0023081400116187244, 'hit_rate': 0.9437751004016064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0015037885228344e-05, 'rmse': 0.005478598167891887, 'mae': 0.0023011971886892895, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003568014719957631, 'rmse': 0.018889189289002403, 'mae': 0.006013284759777948, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011102465275319365, 'rmse': 0.010536823655788952, 'mae': 0.006234175319955923, 'hit_rate': 0.9243027888446215}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1647036794094116e-05, 'rmse': 0.004652637616889383, 'mae': 0.0022869740459122226, 'hit_rate': 0.9682539682539683}]\n",
      "the Prediction of year 2022 of NTRS is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.11726138940344e-05, 'rmse': 0.005583244029597346, 'mae': 0.0023081400116187244, 'hit_rate': 0.9437751004016064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.0015037885228344e-05, 'rmse': 0.005478598167891887, 'mae': 0.0023011971886892895, 'hit_rate': 0.9482071713147411}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0003568014719957631, 'rmse': 0.018889189289002403, 'mae': 0.006013284759777948, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.00011102465275319365, 'rmse': 0.010536823655788952, 'mae': 0.006234175319955923, 'hit_rate': 0.9243027888446215}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 2.1647036794094116e-05, 'rmse': 0.004652637616889383, 'mae': 0.0022869740459122226, 'hit_rate': 0.9682539682539683}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.802918410139633e-05, 'rmse': 0.008247980607481829, 'mae': 0.0033092746691511426, 'hit_rate': 0.963855421686747}]\n",
      "the Prediction of year 2017 of MGM is done\n",
      "2017:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.362311305820923e-06, 'rmse': 0.0025223622471447125, 'mae': 0.0014396025050043817, 'hit_rate': 0.9879518072289156}]\n",
      "the Prediction of year 2018 of MGM is done\n",
      "2018:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.362311305820923e-06, 'rmse': 0.0025223622471447125, 'mae': 0.0014396025050043817, 'hit_rate': 0.9879518072289156}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.082536590659884e-05, 'rmse': 0.007799061860672657, 'mae': 0.00392928095015544, 'hit_rate': 0.9601593625498008}]\n",
      "the Prediction of year 2019 of MGM is done\n",
      "2019:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.362311305820923e-06, 'rmse': 0.0025223622471447125, 'mae': 0.0014396025050043817, 'hit_rate': 0.9879518072289156}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.082536590659884e-05, 'rmse': 0.007799061860672657, 'mae': 0.00392928095015544, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0014082692461068972, 'rmse': 0.037526913623516886, 'mae': 0.010472452591650224, 'hit_rate': 0.9404761904761905}]\n",
      "the Prediction of year 2020 of MGM is done\n",
      "2020:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.362311305820923e-06, 'rmse': 0.0025223622471447125, 'mae': 0.0014396025050043817, 'hit_rate': 0.9879518072289156}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.082536590659884e-05, 'rmse': 0.007799061860672657, 'mae': 0.00392928095015544, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0014082692461068972, 'rmse': 0.037526913623516886, 'mae': 0.010472452591650224, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0006451492107731948, 'rmse': 0.02539978761275761, 'mae': 0.012055130439294114, 'hit_rate': 0.900398406374502}]\n",
      "the Prediction of year 2021 of MGM is done\n",
      "2021:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.362311305820923e-06, 'rmse': 0.0025223622471447125, 'mae': 0.0014396025050043817, 'hit_rate': 0.9879518072289156}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.082536590659884e-05, 'rmse': 0.007799061860672657, 'mae': 0.00392928095015544, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0014082692461068972, 'rmse': 0.037526913623516886, 'mae': 0.010472452591650224, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0006451492107731948, 'rmse': 0.02539978761275761, 'mae': 0.012055130439294114, 'hit_rate': 0.900398406374502}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.822248274616932e-05, 'rmse': 0.006182433400059343, 'mae': 0.0030738276180797075, 'hit_rate': 0.9563492063492064}]\n",
      "the Prediction of year 2022 of MGM is done\n",
      "2022:\n",
      "[{'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.362311305820923e-06, 'rmse': 0.0025223622471447125, 'mae': 0.0014396025050043817, 'hit_rate': 0.9879518072289156}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 6.082536590659884e-05, 'rmse': 0.007799061860672657, 'mae': 0.00392928095015544, 'hit_rate': 0.9601593625498008}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0014082692461068972, 'rmse': 0.037526913623516886, 'mae': 0.010472452591650224, 'hit_rate': 0.9404761904761905}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 0.0006451492107731948, 'rmse': 0.02539978761275761, 'mae': 0.012055130439294114, 'hit_rate': 0.900398406374502}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.822248274616932e-05, 'rmse': 0.006182433400059343, 'mae': 0.0030738276180797075, 'hit_rate': 0.9563492063492064}, {'model': RandomForestRegressor(max_depth=15, min_samples_leaf=15, min_samples_split=15,\n",
      "                      n_estimators=500, random_state=0), 'mse': 3.6053262776337055e-05, 'rmse': 0.00600443692417008, 'mae': 0.0034935695733403155, 'hit_rate': 0.9518072289156626}]\n",
      "Execution time: 617.6031329631805 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "target_column = 'rt'\n",
    "rf_return={}\n",
    "# Initialize a dictionary to store the best models and their performance for each stock\n",
    "RF_performance = {}\n",
    "\n",
    "for stock_name, windows in SP500_Train_Test_Dict.items():\n",
    "    error_year=[]\n",
    "    ret=[]\n",
    "    # Initialize a list to store the best models and their metrics for the current stock\n",
    "    stock_best_models = []\n",
    "    param_grid = {\n",
    "    'max_depth': [15],\n",
    "    'min_samples_split': [15],\n",
    "    'min_samples_leaf': [15],\n",
    "    'n_estimators': [500]}\n",
    "    # Loop over each pair of training/testing set\n",
    "    years=[2017,2018,2019,2020,2021,2022]\n",
    "    count=0\n",
    "    for  i in windows:\n",
    "        train_df, test_df= i\n",
    "        # Prepare the training data\n",
    "        X_train = train_df.iloc[:,7:].drop(columns=[target_column])\n",
    "        y_train = train_df.iloc[:,7:][target_column]\n",
    "\n",
    "        # Prepare the testing data\n",
    "        X_test = test_df.iloc[:,7:].drop(columns=[target_column])\n",
    "        y_test = test_df.iloc[:,7:][target_column]\n",
    "\n",
    "        # Initialize the GridSearchCV object\n",
    "        rf = RandomForestRegressor(random_state=0)\n",
    "        grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "        # Fit the grid search to the data\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best estimator\n",
    "        best_rf = grid_search.best_estimator_\n",
    "\n",
    "        # Predict on the testing set with the best estimator\n",
    "        y_pred = best_rf.predict(X_test)\n",
    "\n",
    "\n",
    "        ret.append(y_pred)\n",
    "\n",
    "\n",
    "        # Calculate the performance metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Calculate Hit Rate\n",
    "        # Assuming the target column is the price and we are interested in the direction of the change\n",
    "        direction_pred = np.sign(np.diff(y_pred))\n",
    "        direction_true = np.sign(np.diff(y_test.values))\n",
    "        hit_rate = np.mean(direction_pred == direction_true)\n",
    "\n",
    "        # Store the best model and its performance metrics\n",
    "        stock_best_models.append({\n",
    "            'model': best_rf,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'hit_rate': hit_rate\n",
    "        })\n",
    "        error_year.append({years[count]:stock_best_models})\n",
    "        print(\"the Prediction of year \"+str(years[count])+\" of \" +stock_name+\" is done\")\n",
    "        print(str(years[count])+\":\")\n",
    "        print(stock_best_models)\n",
    "        count+=1\n",
    "    # Add the best models and their performance to the dictionary\n",
    "    RF_performance[stock_name] = error_year\n",
    "    rf_return[stock_name]=ret\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LwJJ-ArqCFDj"
   },
   "outputs": [],
   "source": [
    "def calculate_averages(data):\n",
    "    grouped_data = {}\n",
    "    for stock in data:\n",
    "        for year_data in data[stock]:\n",
    "            for year, records in year_data.items():\n",
    "                totals = {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0}\n",
    "                count = len(records)\n",
    "                for record in records:\n",
    "                    for key in totals:\n",
    "                        totals[key] += record[key]\n",
    "                if year not in grouped_data:\n",
    "                    grouped_data[year] = {key: 0 for key in totals}\n",
    "                for key in totals:\n",
    "                    grouped_data[year][key] += totals[key] / count\n",
    "    for year in grouped_data:\n",
    "        for key in grouped_data[year]:\n",
    "            grouped_data[year][key] /= len(data)\n",
    "\n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urbdT2CsCYcn"
   },
   "source": [
    "<B>LSTM</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEuUstjECVf3",
    "outputId": "ead2abec-3de1-462d-d172-ecada27ca823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2793\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3413\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2724\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2822\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1940\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2438\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2258\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2758\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2473\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2020 of VZ is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3d04b90fa0>, 'mse': 8.506894937704163e-06, 'rmse': 0.0029166581797845565, 'mae': 0.0021444797270086216, 'hit_rate': 0.9442231075697212}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.6958\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.3005\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2546\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2522\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2858\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2689\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2825\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2870\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2743\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2429\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2884\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2387\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2676\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2322\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2469\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2631\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2626\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2361\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3026\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2262\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2560\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2972\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2724\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2952\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2988\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2803\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2413\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2863\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3227\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2369\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2385\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2565\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2416\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2898\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2606\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2392\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2881\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2100\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3006\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2275\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2310\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2307\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3293\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1926\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2273\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2059\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2448\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2406\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2246\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2458\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2743\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2599\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2421\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2493\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2625\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2615\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2467\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2533\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2588\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2575\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2577\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2251\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2548\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3108\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2021 of VZ is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cfef37ca0>, 'mse': 6.098594698255867e-06, 'rmse': 0.0024695332956362155, 'mae': 0.0017104084139266571, 'hit_rate': 0.9285714285714286}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8073\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3625\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2845\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2386\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3258\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2515\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2989\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2737\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2859\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2961\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3630\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2907\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2574\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2444\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2618\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2628\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2759\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2542\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2692\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2489\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2480\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2679\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2585\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2404\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2463\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2617\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2510\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2351\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2372\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2900\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3087\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2728\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2679\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3052\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3594\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2895\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2525\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2590\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2754\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2941\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2449\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2188\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2214\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2576\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3204\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2570\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2225\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2818\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2453\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2788\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2393\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2761\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2385\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2617\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2598\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2323\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2279\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2496\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2166\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2405\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2380\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2574\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2342\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2640\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2022 of VZ is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cfd589600>, 'mse': 2.0563071985433896e-05, 'rmse': 0.0045346523555211925, 'mae': 0.0030130645624730744, 'hit_rate': 0.9558232931726908}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7049\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3034\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2706\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2844\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2934\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2523\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2760\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2480\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2651\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2788\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2761\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2308\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2429\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2688\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2489\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2499\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2968\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2631\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2592\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2742\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2587\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2726\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2544\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2773\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2618\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2420\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2306\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2898\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2563\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2294\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2594\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2339\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2493\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2618\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2345\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2160\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2343\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2045\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2451\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2702\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2676\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2252\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2605\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2104\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2265\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2772\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2343\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1985\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2393\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2406\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2142\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2279\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2344\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2505\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2283\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2630\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2441\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2512\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2418\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2335\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2728\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2487\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2523\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2383\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2017 of NUE is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cf7023d30>, 'mse': 3.194826221874556e-05, 'rmse': 0.005652279382580585, 'mae': 0.0037581089493267613, 'hit_rate': 0.9477911646586346}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7837\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3288\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2919\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2466\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2638\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2876\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2641\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2810\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2726\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2566\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2499\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2479\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2518\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2237\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2638\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2511\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2706\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2655\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2581\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2657\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2743\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2682\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2135\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2671\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2772\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2646\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2718\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2253\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2487\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2890\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2933\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2334\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2744\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2630\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2196\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2421\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2538\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2469\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2384\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2869\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2636\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2183\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2605\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2639\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2881\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2335\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2673\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2083\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2596\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2311\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2426\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2415\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2549\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2334\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3139\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2537\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2110\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2102\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2765\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2312\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2202\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2556\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2567\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2331\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2018 of NUE is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cf2321150>, 'mse': 1.7524696856618854e-05, 'rmse': 0.00418625093091884, 'mae': 0.003107308850728141, 'hit_rate': 0.9561752988047809}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7162\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2948\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2812\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2743\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2990\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2209\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2945\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2906\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2760\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2984\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3133\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2620\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2389\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2613\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2708\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2895\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2653\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2991\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2546\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2488\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2728\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2907\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2224\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2648\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2447\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2630\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2265\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2612\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2683\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2786\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2510\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2412\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2185\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2282\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2624\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2545\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2494\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2335\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2145\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2282\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2521\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2163\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2250\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2172\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2427\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2363\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2459\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2400\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2343\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2076\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2389\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2163\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2010\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1997\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2379\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2401\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2181\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2288\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2214\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2659\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2122\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2279\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2485\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2432\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2019 of NUE is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cf77ea290>, 'mse': 0.00011969200915476675, 'rmse': 0.010940384323905936, 'mae': 0.005625907397795443, 'hit_rate': 0.9047619047619048}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8099\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3869\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3037\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2626\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2575\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2956\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3171\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2415\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2879\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3607\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2808\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3623\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3169\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2790\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2303\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2404\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2714\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2476\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2387\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2481\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2748\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2478\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2224\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2945\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2586\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2410\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2529\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2279\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2514\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2348\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3036\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3194\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2363\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2479\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2220\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2604\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2572\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2884\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2270\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2391\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2535\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2454\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2540\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2703\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2442\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2662\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2142\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2195\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2100\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2371\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2200\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2306\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2771\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2699\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2673\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2758\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2846\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1962\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2585\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2115\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2854\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1932\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2244\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2416\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2020 of NUE is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ce46c1300>, 'mse': 3.2478852499059575e-05, 'rmse': 0.0056990220651493865, 'mae': 0.004187622940270338, 'hit_rate': 0.9601593625498008}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7719\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3375\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2281\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2610\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2739\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2735\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2954\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2754\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3114\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2639\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2560\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2932\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2953\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2183\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2903\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3026\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2699\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3281\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2846\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3066\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2156\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2860\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2521\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2401\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2543\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2273\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2995\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2721\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2644\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3257\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2498\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2869\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2420\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2952\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2943\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2530\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2699\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2109\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2373\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2633\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3377\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2304\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2780\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2869\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2452\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2867\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2386\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2997\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2682\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2481\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2837\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3512\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2911\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2058\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3065\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3162\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2568\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2846\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3287\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2249\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2340\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3125\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3608\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2291\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2021 of NUE is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ce9a6cdf0>, 'mse': 7.545175381593645e-05, 'rmse': 0.008686296898905566, 'mae': 0.006353641835908904, 'hit_rate': 0.9047619047619048}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.8022\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3118\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2596\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2612\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2520\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2508\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2722\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3238\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2728\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2759\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2850\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2666\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2954\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2858\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2820\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2297\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2995\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2748\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2482\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2682\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3082\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2625\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2458\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2898\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2641\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2865\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2604\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2604\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2708\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2431\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2478\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2358\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2543\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2827\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2417\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2745\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2472\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3161\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3038\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2348\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2453\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2591\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2403\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2564\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2474\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2804\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2214\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2678\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2363\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2351\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2316\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2851\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2542\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2296\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2479\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2662\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2567\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2537\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2631\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2885\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2809\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2416\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2309\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2259\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2022 of NUE is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ce82c6560>, 'mse': 7.119662539929569e-05, 'rmse': 0.008437809277252935, 'mae': 0.005987659705658132, 'hit_rate': 0.9196787148594378}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.7736\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2885\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2903\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2531\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2944\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2588\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3205\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2389\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3130\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2542\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2347\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2354\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2529\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2556\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2492\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2722\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2701\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2588\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2219\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2578\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2553\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2761\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2700\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2326\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2549\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2749\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2783\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2028\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2455\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2739\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2856\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2389\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2351\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2336\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2449\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2524\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2713\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2331\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2454\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2051\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2623\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2465\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2635\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2620\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2575\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1911\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2132\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2200\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2519\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2091\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2396\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2356\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2326\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2089\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1926\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2607\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2295\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2451\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2507\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1841\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2497\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2025\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2149\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2055\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2017 of OKE is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ce5a1b160>, 'mse': 1.232330300203406e-05, 'rmse': 0.003510456238444522, 'mae': 0.002628608665657925, 'hit_rate': 0.9196787148594378}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.8306\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3724\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2997\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2422\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2952\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2324\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2719\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2492\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3000\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2704\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2904\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2826\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2758\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2599\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2274\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2381\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2780\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2590\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2539\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2538\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2510\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2012\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2446\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2775\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2676\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2359\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2415\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2555\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2417\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3187\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2251\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2477\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2078\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2268\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2478\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2307\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2587\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2492\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2544\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2518\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2747\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2197\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2283\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1901\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2364\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2285\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2793\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2290\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2668\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2519\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2469\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2147\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2500\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2043\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2059\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2303\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1907\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2247\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2328\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2066\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2290\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2496\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1982\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2266\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2018 of OKE is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ce440bd90>, 'mse': 1.5376196015195567e-05, 'rmse': 0.00392124929266115, 'mae': 0.0028464938574270125, 'hit_rate': 0.9203187250996016}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.7882\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2868\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2978\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2505\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2784\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2771\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2443\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2335\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2838\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2616\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2619\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2665\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2387\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2873\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2522\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2525\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2363\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2302\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2569\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2666\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2761\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2991\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2683\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2299\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2355\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2736\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2531\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2839\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2359\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2518\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2378\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2545\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3128\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2350\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2558\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2390\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2488\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2445\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2301\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2592\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2787\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2494\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2517\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2412\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2379\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2705\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2830\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2727\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2359\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2808\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2448\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2412\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2347\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2142\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2540\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2250\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2548\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2719\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2539\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2371\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2642\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2327\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2276\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2660\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2019 of OKE is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ce3ede200>, 'mse': 0.0015541359995895117, 'rmse': 0.039422531623292685, 'mae': 0.00967109752930468, 'hit_rate': 0.9285714285714286}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.9372\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.7497\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4857\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3066\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2852\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1670\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3124\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3239\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3298\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3196\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2515\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2541\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1865\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2749\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1905\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2202\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1482\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2767\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1648\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1823\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2664\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2585\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2263\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2050\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3749\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2388\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2820\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2958\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2588\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2431\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1745\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1462\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2151\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1489\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2058\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1624\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2960\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2048\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1888\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1435\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2612\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1965\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1455\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1899\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2129\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2279\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4764\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1636\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1943\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1903\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2121\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2128\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1869\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1901\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2138\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1393\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2449\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2696\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2298\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1879\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1212\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2785\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1922\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2319\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2020 of OKE is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ce1e1c0d0>, 'mse': 0.00016579748688090774, 'rmse': 0.01287623729514596, 'mae': 0.009077950595800112, 'hit_rate': 0.9601593625498008}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8840\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5281\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2932\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3020\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2269\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3331\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2753\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2053\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3297\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3839\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2800\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3512\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4474\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3067\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3238\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2960\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3498\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2851\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2779\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2991\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2018\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2573\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3864\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2888\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2177\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1776\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2036\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2656\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2018\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1770\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2154\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2323\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2664\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2889\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2933\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2763\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2158\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1858\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2121\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2635\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1796\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1865\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3853\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3455\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1935\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3258\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2646\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1704\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2920\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3183\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2004\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2214\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1664\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3596\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2019\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2802\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1891\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1919\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1913\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2061\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3645\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1714\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2728\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3000\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2021 of OKE is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cdc434610>, 'mse': 3.314171943609911e-05, 'rmse': 0.005756884525166291, 'mae': 0.0045782428204378025, 'hit_rate': 0.9365079365079365}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.9020\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4793\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3982\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3150\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2987\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2934\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3642\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3091\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2281\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2760\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3195\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1964\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2750\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3176\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2082\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4131\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2228\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3152\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2283\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2018\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2560\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2406\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2256\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2758\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2248\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1690\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.5890\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2231\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2455\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2433\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2084\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3741\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2319\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4478\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2026\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2383\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2687\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2229\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2628\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2384\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2570\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2058\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2772\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2955\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2892\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1923\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1949\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1986\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2524\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2306\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2519\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1608\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3040\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2195\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1684\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1682\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1733\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3474\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2367\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2734\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1767\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2758\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2055\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1811\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2022 of OKE is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cdd85eaa0>, 'mse': 3.4033795987233935e-05, 'rmse': 0.005833849157051795, 'mae': 0.004654608607012545, 'hit_rate': 0.9236947791164659}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.7903\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3338\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3076\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2877\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2767\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2995\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2723\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2861\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2707\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3187\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2445\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2862\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2641\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2852\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2553\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2762\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2768\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2646\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2756\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2685\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2455\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2418\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3002\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2218\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2884\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2690\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2904\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2500\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2724\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2987\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2417\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2530\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2572\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2682\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2842\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2844\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2530\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2994\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2691\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2500\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2644\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2569\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2460\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2487\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3030\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2400\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2805\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2983\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2725\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2678\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2614\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2468\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2648\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2542\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2997\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2389\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3151\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2508\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2071\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2988\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2463\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2955\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3107\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2384\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2017 of WAB is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cdc10cfa0>, 'mse': 3.464449430036137e-05, 'rmse': 0.005885957381799614, 'mae': 0.00289059220672927, 'hit_rate': 0.9437751004016064}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 9s 5ms/step - loss: 0.8307\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3665\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3102\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3241\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2718\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2797\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3074\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2502\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2214\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2763\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3253\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2704\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2790\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2823\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2875\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2802\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2696\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3328\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2732\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3350\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2920\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2872\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2616\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2704\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3517\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2725\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3118\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3011\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2358\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2348\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3056\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3639\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3378\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2265\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2239\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2665\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2348\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2866\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2820\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2856\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2707\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2774\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2515\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3826\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2446\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2336\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3240\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3664\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2578\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2666\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2723\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2705\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2209\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2248\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3089\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2544\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2473\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2490\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3044\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2319\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2180\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2986\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2557\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2359\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2018 of WAB is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cd72f1bd0>, 'mse': 5.00186828347341e-05, 'rmse': 0.007072388764394538, 'mae': 0.003758876091251022, 'hit_rate': 0.9322709163346613}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.7612\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2806\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2578\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2886\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2625\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2407\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3015\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3210\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2443\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2755\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2099\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2249\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2387\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2504\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2202\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2313\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2114\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2488\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2562\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3252\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2809\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2951\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2340\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2539\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2406\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2516\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2347\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2441\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2480\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2693\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2515\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2319\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2317\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2439\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2901\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2077\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3071\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2454\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2309\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2686\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2593\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2009\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2326\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2533\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2697\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2389\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2344\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1892\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2468\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1860\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2192\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3209\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2433\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2643\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2235\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2317\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2508\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2384\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2108\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2894\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2787\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1953\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1944\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2361\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2019 of WAB is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cd48fe590>, 'mse': 0.00014852332655827246, 'rmse': 0.012187014669650335, 'mae': 0.006116640329904875, 'hit_rate': 0.9325396825396826}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8513\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4194\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2519\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3052\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2891\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2600\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3171\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3036\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2046\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2237\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2386\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3034\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2946\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2703\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2998\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2140\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3229\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2770\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3401\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2098\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2810\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1777\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3019\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2486\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2393\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2293\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2649\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2729\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2467\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2881\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3260\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2345\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1925\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2893\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2234\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2283\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2274\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2227\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2421\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2703\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2059\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2371\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1957\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2663\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1857\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2462\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2311\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2114\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2097\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2155\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1745\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1726\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2146\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1940\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1957\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2438\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2068\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1987\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2258\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1815\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2031\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2134\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2375\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2642\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2020 of WAB is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cdc758760>, 'mse': 8.388195194921701e-05, 'rmse': 0.009158709076568433, 'mae': 0.0066253594719662265, 'hit_rate': 0.9123505976095617}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7979\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3207\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2709\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2622\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2549\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2726\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3362\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3353\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2488\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2486\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3021\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1927\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2300\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2856\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2682\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2429\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2571\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2263\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2527\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2557\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2415\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2837\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2718\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2124\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2586\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2991\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2123\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2078\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3032\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1749\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2251\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1873\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2189\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2407\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2204\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2469\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2483\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2095\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2488\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2332\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2301\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1984\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2512\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2147\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2148\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2342\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2612\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2355\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2447\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2298\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2397\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1863\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2398\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1934\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2411\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2466\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2250\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2574\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2175\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1906\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2382\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2147\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2335\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2362\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2021 of WAB is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3d04f29c90>, 'mse': 2.5014302670813906e-05, 'rmse': 0.005001430062573494, 'mae': 0.0038386575197934484, 'hit_rate': 0.9325396825396826}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7282\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3292\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2626\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2916\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2415\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2241\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2983\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3152\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2131\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2300\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2532\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2933\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2228\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2649\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2642\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2364\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2492\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1947\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2530\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2518\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2025\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2691\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2411\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2277\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2048\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2527\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2391\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2575\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2255\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2316\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2278\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2171\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2467\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2262\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2619\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2428\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2208\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2843\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2661\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2780\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2305\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2038\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2417\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1960\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2164\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2769\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2422\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2480\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2433\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2354\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2851\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2824\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2435\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2634\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2428\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1943\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2057\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2429\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3503\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1900\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1734\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2209\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1836\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1982\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2022 of WAB is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cf184bb80>, 'mse': 1.9015876039912467e-05, 'rmse': 0.0043607196699527095, 'mae': 0.00346058842330331, 'hit_rate': 0.9156626506024096}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7699\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3757\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3134\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3513\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3161\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2646\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3170\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3118\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2510\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3171\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2252\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2379\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2391\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2440\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2374\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3084\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2795\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3829\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2905\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2281\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3058\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2511\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2813\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2247\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2126\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2558\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2369\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3058\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2591\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3345\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2666\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3265\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2637\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2285\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3085\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4065\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1820\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2429\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3338\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2464\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2769\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3898\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2215\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3652\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2212\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2020\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3484\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2003\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2288\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2283\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2595\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2430\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2937\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2273\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2864\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2420\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3604\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2196\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2275\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2137\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2509\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2158\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2541\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2810\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2017 of BIIB is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3d0b843be0>, 'mse': 2.293238214574704e-05, 'rmse': 0.004788776685725389, 'mae': 0.0033512825276555383, 'hit_rate': 0.9437751004016064}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7177\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3344\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3600\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2577\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2334\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2220\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2939\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2270\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4133\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2175\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2517\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2636\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2129\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3361\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2922\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2517\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2416\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2697\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2705\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2422\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1892\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3651\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2867\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2104\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2166\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3668\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2354\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3001\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2670\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2094\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2232\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2321\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2277\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2335\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2231\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3433\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2057\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3400\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2676\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2537\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2046\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2480\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2248\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1835\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1902\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3099\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2519\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2584\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2965\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3338\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1911\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2551\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2219\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2176\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2210\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2182\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2162\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2266\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3266\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3465\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2125\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2064\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2616\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2205\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2018 of BIIB is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cd34ebdc0>, 'mse': 0.00010633690167191638, 'rmse': 0.010311978552727715, 'mae': 0.003855092479432565, 'hit_rate': 0.9402390438247012}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.7701\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4876\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3860\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4166\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3450\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3146\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3243\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3004\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2799\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4852\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2596\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4450\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5569\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2116\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2024\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2506\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2069\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2813\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3026\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2026\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2594\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2232\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1712\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2004\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2067\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1703\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3047\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2121\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4650\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2382\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2700\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1810\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1513\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4828\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1843\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2126\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2124\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2201\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2015\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2036\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1678\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2837\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2049\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4957\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1836\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2072\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1737\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1481\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1827\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2295\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1897\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4777\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1696\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1751\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2213\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1756\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1655\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1975\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1594\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1490\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1986\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1875\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2079\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1738\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2019 of BIIB is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cd1b7cf10>, 'mse': 0.00013035602933545495, 'rmse': 0.011417356495067277, 'mae': 0.005824084731069469, 'hit_rate': 0.9206349206349206}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8302\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5350\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4922\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4817\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3404\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4401\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3006\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3556\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3588\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4098\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3225\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2886\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2293\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2117\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4033\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3304\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2628\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3093\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2563\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1859\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2647\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4261\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2809\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4433\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3884\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2286\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1664\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1527\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1948\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1906\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1802\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1646\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2407\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3460\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2027\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2717\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2965\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1802\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1979\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3825\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1647\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3332\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3222\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2013\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1694\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3590\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2217\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1863\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1944\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1871\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1535\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2009\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2558\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3244\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2219\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1828\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1478\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1695\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2129\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1778\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1439\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2992\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1974\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2047\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2020 of BIIB is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cd00f5480>, 'mse': 0.0004700049818171742, 'rmse': 0.021679598285419734, 'mae': 0.006795527215207034, 'hit_rate': 0.9482071713147411}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8437\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5591\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4372\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5095\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3710\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2952\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4833\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4122\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2816\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3162\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3417\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3103\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2390\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1904\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4467\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2795\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1961\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2470\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3737\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2940\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2344\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2090\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2799\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3704\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3321\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4120\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2278\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3545\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4157\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1634\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1634\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3795\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2382\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5005\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1839\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5128\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2378\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2568\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1998\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2304\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2437\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2984\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2125\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3418\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2824\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2007\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3322\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1732\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1572\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1891\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2291\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1570\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1492\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1928\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2905\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1643\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1494\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2551\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2525\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1752\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2269\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1778\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2055\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3509\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2021 of BIIB is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cbe371870>, 'mse': 0.00014085545879441872, 'rmse': 0.011868254243755427, 'mae': 0.0053715579262815765, 'hit_rate': 0.9365079365079365}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.9079\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6053\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4607\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3889\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2891\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2631\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2534\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4211\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2547\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2907\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4426\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3259\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3512\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3078\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3397\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2261\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4012\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3956\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4424\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2648\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4381\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2455\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1852\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2622\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2272\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3858\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2499\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1938\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4162\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2763\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3699\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2824\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2422\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1630\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2178\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2211\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2662\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1575\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3403\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3576\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1538\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2318\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3102\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2442\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2333\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2729\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2781\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2427\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3713\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2085\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1557\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1671\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2484\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4298\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2265\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1998\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4385\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2369\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3701\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1684\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1833\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2133\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1466\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1556\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2022 of BIIB is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cbcfe9390>, 'mse': 7.735290377215117e-05, 'rmse': 0.008795049958479552, 'mae': 0.004128723439542725, 'hit_rate': 0.9116465863453815}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7674\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3147\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2713\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2514\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2911\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3520\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3237\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2936\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2434\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2898\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2784\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2697\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2486\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2468\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2819\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3076\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3425\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2692\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2941\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2695\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2931\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2867\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2660\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2341\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2751\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2642\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2656\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3068\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2276\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2584\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2796\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2993\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2394\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2582\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2723\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2772\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2454\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3155\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2456\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2100\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2383\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2964\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2885\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2484\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2717\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2296\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2422\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2456\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2635\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2877\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2576\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2311\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2551\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2619\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2613\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2898\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2772\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2696\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2121\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2283\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2458\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2504\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3119\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2532\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2017 of NTRS is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cbc4c6800>, 'mse': 1.4429202796372297e-05, 'rmse': 0.003798579049641102, 'mae': 0.002469255758706833, 'hit_rate': 0.9437751004016064}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7883\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3632\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2949\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2524\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2761\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2812\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2876\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2685\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2653\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2727\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2409\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2579\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2722\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2486\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2300\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2032\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2276\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2499\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2812\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2627\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2270\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2666\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2777\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2169\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2521\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2931\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2773\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2590\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2725\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3033\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2457\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2529\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2283\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3197\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2588\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2375\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2753\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2617\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2672\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2059\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2649\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2787\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2325\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2473\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2465\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2184\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2419\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2045\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2417\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2304\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2972\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2239\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2403\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1922\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2632\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2533\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2340\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2507\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2622\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2583\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2381\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2463\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2519\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2114\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2018 of NTRS is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cb6ff5ab0>, 'mse': 2.090289261399996e-05, 'rmse': 0.004571968133528488, 'mae': 0.0032459751567757685, 'hit_rate': 0.9322709163346613}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8232\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3880\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3038\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3343\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2817\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2755\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3034\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3145\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2555\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2671\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2781\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2848\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3455\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3237\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2736\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3641\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3052\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3318\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2889\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2411\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2997\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3168\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2787\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3025\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2615\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2975\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2633\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3170\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3050\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2450\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2498\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2393\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2290\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2579\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2398\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2759\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2342\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2525\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2655\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2513\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2721\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2538\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2487\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2570\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2576\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2383\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2389\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2846\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2756\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2303\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2638\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3155\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2205\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3476\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2857\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2278\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2665\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2354\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2597\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2445\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2449\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2784\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2706\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2541\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2019 of NTRS is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cb68edd20>, 'mse': 0.00026717430865623475, 'rmse': 0.01634546752638892, 'mae': 0.006667251993137914, 'hit_rate': 0.9722222222222222}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.8788\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.5036\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3732\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3665\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2899\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3493\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2618\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3726\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2396\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3409\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3151\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2927\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2702\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2056\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2347\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3605\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2421\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2229\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3108\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2352\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1766\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2550\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2685\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2484\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2690\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2594\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3207\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3141\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2748\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3210\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3518\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2638\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2813\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2238\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2366\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2992\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3557\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3471\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5182\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2191\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2630\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2629\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2858\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2627\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3175\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2473\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2485\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2953\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3552\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2479\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3371\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1963\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2344\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2066\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2423\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2858\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2327\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2772\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2875\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2137\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2265\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2545\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1849\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2603\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2020 of NTRS is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3caf723820>, 'mse': 5.72842762396434e-05, 'rmse': 0.007568637673957143, 'mae': 0.005601810891728603, 'hit_rate': 0.9482071713147411}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8121\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4446\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3461\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3118\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3567\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3870\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3512\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3518\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2813\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2959\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2997\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2548\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2746\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3315\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3111\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2970\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2492\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3033\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2586\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2539\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2074\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2867\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2598\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3037\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2333\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2825\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3322\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3085\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2981\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2618\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3155\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2395\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2083\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2843\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3292\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1926\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2472\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2480\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4144\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2345\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3169\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2481\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2974\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2586\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2563\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3088\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2165\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1951\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2848\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2737\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2393\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2760\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2107\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2618\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2301\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2258\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2603\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2414\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2509\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1894\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2088\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2655\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1981\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1905\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2021 of NTRS is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cad8acfd0>, 'mse': 2.4358140537832344e-05, 'rmse': 0.004935396695082609, 'mae': 0.0036941857093167195, 'hit_rate': 0.9365079365079365}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.8064\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3400\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2897\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3303\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2459\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3560\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3077\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3317\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2939\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3168\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2612\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3021\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2961\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2823\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2784\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3352\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2739\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2373\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3218\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2844\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2457\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2454\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2635\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2647\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2421\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2227\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2386\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2287\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3077\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3227\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2113\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1941\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2350\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2676\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3054\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2960\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3131\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2177\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2664\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1935\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2567\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2183\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3090\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2661\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2458\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3201\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2131\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2526\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2650\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2437\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2067\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2688\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1962\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2263\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2353\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2504\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2075\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2105\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2784\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2616\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1965\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2123\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2454\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2198\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2022 of NTRS is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cad8ad060>, 'mse': 4.377548728226103e-05, 'rmse': 0.006616304654583329, 'mae': 0.004847243466831159, 'hit_rate': 0.9357429718875502}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.7507\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2907\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3043\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2539\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2911\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3090\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2930\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2755\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2890\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2700\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2811\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2340\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2578\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2400\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2732\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2678\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2743\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2096\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2513\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2660\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2350\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2669\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2718\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2472\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2716\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2831\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2487\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2705\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2642\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2515\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2897\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2870\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2468\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2402\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2523\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2746\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2973\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2085\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2536\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2478\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2295\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2349\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2693\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2184\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2467\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2358\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2726\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2891\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2539\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2300\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2316\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2424\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2429\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2559\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2249\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2423\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2418\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2202\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2471\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2676\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2366\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2487\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2755\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2744\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2017 of MGM is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca0568bb0>, 'mse': 1.7508552768006327e-05, 'rmse': 0.0041843222591007884, 'mae': 0.0031724744453284826, 'hit_rate': 0.9156626506024096}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 6ms/step - loss: 0.7614\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3352\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2676\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2760\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2961\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2513\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2816\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2602\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2544\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3002\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2820\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2606\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3092\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2794\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3240\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2667\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3034\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2898\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2885\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2636\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2779\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2747\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2436\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2676\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2511\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2398\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2665\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2761\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2588\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1953\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2310\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2538\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3035\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2918\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2865\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2568\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2319\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3333\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2396\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2244\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2846\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2259\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2529\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2397\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2825\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2205\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2286\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2417\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2685\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2691\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2761\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2275\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2789\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2811\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2341\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2730\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2845\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2699\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2324\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3187\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2876\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2536\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2861\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2018 of MGM is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca56ff970>, 'mse': 4.7376200244268536e-05, 'rmse': 0.006883037138085813, 'mae': 0.004904188551577186, 'hit_rate': 0.9043824701195219}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.7434\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3192\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2906\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3028\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2381\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2485\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2332\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2707\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2855\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2258\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2623\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2719\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2392\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2629\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2841\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2678\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2759\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2579\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2696\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2623\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2117\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2681\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2777\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2362\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2338\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2355\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2287\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2879\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2586\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2744\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2720\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2222\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2593\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2336\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2212\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2418\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2176\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2831\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2747\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2428\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2159\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2187\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2871\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2205\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2284\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2842\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2211\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2199\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2128\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2339\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2361\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2328\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2530\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2854\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2982\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2293\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2293\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2533\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2392\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2779\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2093\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2165\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2235\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2726\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2019 of MGM is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca3bc64a0>, 'mse': 0.0010155779829955787, 'rmse': 0.031868134287961994, 'mae': 0.009948835230336768, 'hit_rate': 0.9246031746031746}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8622\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4805\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4460\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3475\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2939\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2820\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3924\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4432\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2584\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2726\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5451\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3082\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2661\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2857\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3264\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1935\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3708\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4387\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2258\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5200\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2230\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2372\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4113\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3584\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2696\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1913\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1456\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1981\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1918\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2126\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2730\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2078\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1624\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2262\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3667\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2302\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1946\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3323\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2021\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1715\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1629\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1999\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3134\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2238\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3632\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1793\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2490\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2788\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2040\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1961\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3143\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2886\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2200\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1793\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1597\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4613\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4172\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2044\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2490\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1396\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2672\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2326\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2754\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1442\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2020 of MGM is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca27a1bd0>, 'mse': 0.0001702123204210599, 'rmse': 0.013046544386198972, 'mae': 0.009448304799929612, 'hit_rate': 0.896414342629482}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8905\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5949\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3433\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2976\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3271\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3248\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3513\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3601\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3343\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1886\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2827\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3252\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3175\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2652\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2125\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2733\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3904\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2627\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3347\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2779\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2235\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2767\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3667\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2584\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3170\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2158\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2558\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2821\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1977\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2553\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2936\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2946\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2258\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2480\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2429\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2471\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2743\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2755\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2910\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2507\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2176\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2704\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3372\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2272\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2464\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2842\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2714\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2033\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2398\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2526\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2821\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2744\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1798\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2236\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2641\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2601\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2205\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2727\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2443\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2971\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3018\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2559\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2149\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2102\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2021 of MGM is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca08a0d90>, 'mse': 4.862333282252932e-05, 'rmse': 0.0069730432970496695, 'mae': 0.0052308459851730955, 'hit_rate': 0.9642857142857143}\n",
      "Epoch 1/64\n",
      "24/24 [==============================] - 4s 5ms/step - loss: 0.8385\n",
      "Epoch 2/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4198\n",
      "Epoch 3/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3778\n",
      "Epoch 4/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4013\n",
      "Epoch 5/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3082\n",
      "Epoch 6/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2892\n",
      "Epoch 7/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2982\n",
      "Epoch 8/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3186\n",
      "Epoch 9/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3123\n",
      "Epoch 10/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3804\n",
      "Epoch 11/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2413\n",
      "Epoch 12/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2405\n",
      "Epoch 13/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3132\n",
      "Epoch 14/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2519\n",
      "Epoch 15/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2317\n",
      "Epoch 16/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3228\n",
      "Epoch 17/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3414\n",
      "Epoch 18/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2719\n",
      "Epoch 19/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2529\n",
      "Epoch 20/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2177\n",
      "Epoch 21/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2941\n",
      "Epoch 22/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2238\n",
      "Epoch 23/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2616\n",
      "Epoch 24/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2207\n",
      "Epoch 25/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3708\n",
      "Epoch 26/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2486\n",
      "Epoch 27/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2324\n",
      "Epoch 28/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2638\n",
      "Epoch 29/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2099\n",
      "Epoch 30/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3032\n",
      "Epoch 31/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2860\n",
      "Epoch 32/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2451\n",
      "Epoch 33/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3166\n",
      "Epoch 34/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2144\n",
      "Epoch 35/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2522\n",
      "Epoch 36/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2888\n",
      "Epoch 37/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3028\n",
      "Epoch 38/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2287\n",
      "Epoch 39/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2610\n",
      "Epoch 40/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2382\n",
      "Epoch 41/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2040\n",
      "Epoch 42/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2721\n",
      "Epoch 43/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3030\n",
      "Epoch 44/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1869\n",
      "Epoch 45/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3235\n",
      "Epoch 46/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3972\n",
      "Epoch 47/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3046\n",
      "Epoch 48/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2088\n",
      "Epoch 49/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2772\n",
      "Epoch 50/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2144\n",
      "Epoch 51/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2094\n",
      "Epoch 52/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3453\n",
      "Epoch 53/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2990\n",
      "Epoch 54/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2872\n",
      "Epoch 55/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1835\n",
      "Epoch 56/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2675\n",
      "Epoch 57/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3380\n",
      "Epoch 58/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2452\n",
      "Epoch 59/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3186\n",
      "Epoch 60/64\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2191\n",
      "Epoch 61/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2897\n",
      "Epoch 62/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2841\n",
      "Epoch 63/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2147\n",
      "Epoch 64/64\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1974\n",
      "8/8 [==============================] - 1s 3ms/step\n",
      "Prediction for year 2022 of MGM is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c99dfe0b0>, 'mse': 7.159805059769865e-05, 'rmse': 0.008461563129688193, 'mae': 0.006293343297601463, 'hit_rate': 0.9477911646586346}\n",
      "Execution time: 2459.9701256752014 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "target_column = 'rt'\n",
    "\n",
    "# Initialize a dictionary to store the best models and their performance for each stock\n",
    "LSTM_performance = {}\n",
    "LSTM_stock_return = {}\n",
    "\n",
    "# Define LSTM model architecture with new parameters\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=input_shape, dropout=0.4))\n",
    "    model.add(LSTM(128, return_sequences=False, dropout=0.4))\n",
    "    model.add(Dense(25))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=\"Adam\", loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Loop over each stock\n",
    "for stock_name, windows in SP500_Train_Test_Dict.items():\n",
    "    stock_best_models = []\n",
    "    ret = []\n",
    "    years = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "    for year, (train_df, test_df) in zip(years, windows):\n",
    "        # Standardize the data\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        X_train_scaled = scaler_X.fit_transform(train_df.iloc[:, 7:].drop(columns=[target_column]))\n",
    "        y_train_scaled = scaler_y.fit_transform(train_df[[target_column]])\n",
    "        X_test_scaled = scaler_X.transform(test_df.iloc[:, 7:].drop(columns=[target_column]))\n",
    "        y_test_scaled = scaler_y.transform(test_df[[target_column]])\n",
    "\n",
    "        # Reshape data for LSTM model\n",
    "        X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "        X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "        # Define and fit the LSTM model\n",
    "        lstm_model = create_lstm_model(X_train_scaled.shape[1:])\n",
    "        lstm_model.fit(X_train_scaled, y_train_scaled, batch_size=32, epochs=64)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred_scaled = lstm_model.predict(X_test_scaled)\n",
    "\n",
    "        # Inverse transform predictions and actual values to original scale\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()\n",
    "        y_test = scaler_y.inverse_transform(y_test_scaled).flatten()\n",
    "\n",
    "        ret.append(y_pred)\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Calculate Hit Rate\n",
    "        direction_pred = np.sign(np.diff(y_pred))\n",
    "        direction_true = np.sign(np.diff(y_test))\n",
    "        hit_rate = np.mean(direction_pred == direction_true)\n",
    "\n",
    "        # Store the best model and its performance metrics\n",
    "        stock_best_models.append({\n",
    "            'model': lstm_model,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'hit_rate': hit_rate\n",
    "        })\n",
    "\n",
    "        print(f\"Prediction for year {year} of {stock_name} is done.\")\n",
    "        print(f\"{year}: {stock_best_models[-1]}\")\n",
    "\n",
    "    # Add the best models and their performance to the dictionary\n",
    "    LSTM_performance[stock_name] = stock_best_models\n",
    "    LSTM_stock_return[stock_name] = ret\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sg5Z_aJnDTNV"
   },
   "source": [
    "<B>SVM</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hw0WRvXuDWeq",
    "outputId": "2d0ac282-2515-4308-c84e-510e1a646c8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for year 2017 of DPZ is done.\n",
      "2017: {'model': SVR(), 'mse': 0.0001096930312838774, 'rmse': 0.010473444098474838, 'mae': 0.003758988619366655, 'hit_rate': 0.9558232931726908}\n",
      "Prediction for year 2018 of DPZ is done.\n",
      "2018: {'model': SVR(), 'mse': 8.924297345871556e-05, 'rmse': 0.009446849922525263, 'mae': 0.003734323750727445, 'hit_rate': 0.9721115537848606}\n",
      "Prediction for year 2019 of DPZ is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0004860135961533107, 'rmse': 0.022045716049911162, 'mae': 0.006822349663366609, 'hit_rate': 0.9365079365079365}\n",
      "Prediction for year 2020 of DPZ is done.\n",
      "2020: {'model': SVR(), 'mse': 2.5208847661475262e-05, 'rmse': 0.0050208413300437274, 'mae': 0.0022146853720928185, 'hit_rate': 0.9800796812749004}\n",
      "Prediction for year 2021 of DPZ is done.\n",
      "2021: {'model': SVR(), 'mse': 9.92807510861887e-05, 'rmse': 0.009963972655833049, 'mae': 0.0028213809849720255, 'hit_rate': 0.9484126984126984}\n",
      "Prediction for year 2022 of DPZ is done.\n",
      "2022: {'model': SVR(), 'mse': 0.00010341349107715131, 'rmse': 0.010169242404287121, 'mae': 0.003404597415632808, 'hit_rate': 0.9718875502008032}\n",
      "Prediction for year 2017 of AVGO is done.\n",
      "2017: {'model': SVR(), 'mse': 1.616647250429461e-05, 'rmse': 0.004020755215664665, 'mae': 0.0019661594904462924, 'hit_rate': 0.9397590361445783}\n",
      "Prediction for year 2018 of AVGO is done.\n",
      "2018: {'model': SVR(), 'mse': 0.00013450550810704327, 'rmse': 0.011597650973668903, 'mae': 0.0035326105658392316, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2019 of AVGO is done.\n",
      "2019: {'model': SVR(), 'mse': 0.000692040541668678, 'rmse': 0.026306663446143793, 'mae': 0.008241265601540895, 'hit_rate': 0.9484126984126984}\n",
      "Prediction for year 2020 of AVGO is done.\n",
      "2020: {'model': SVR(), 'mse': 3.659455510192269e-05, 'rmse': 0.00604934336121886, 'mae': 0.0026451694519255115, 'hit_rate': 0.9641434262948207}\n",
      "Prediction for year 2021 of AVGO is done.\n",
      "2021: {'model': SVR(), 'mse': 1.353481306309463e-05, 'rmse': 0.003678969021763384, 'mae': 0.0017799508424192496, 'hit_rate': 0.9523809523809523}\n",
      "Prediction for year 2022 of AVGO is done.\n",
      "2022: {'model': SVR(), 'mse': 1.9995353498945652e-05, 'rmse': 0.004471616430212418, 'mae': 0.002374212250680948, 'hit_rate': 0.9558232931726908}\n",
      "Prediction for year 2017 of TSLA is done.\n",
      "2017: {'model': SVR(), 'mse': 5.2641552166433486e-05, 'rmse': 0.007255449825230238, 'mae': 0.0028412984952884534, 'hit_rate': 0.9598393574297188}\n",
      "Prediction for year 2018 of TSLA is done.\n",
      "2018: {'model': SVR(), 'mse': 0.0006238431388442663, 'rmse': 0.02497685206034312, 'mae': 0.010234067314283364, 'hit_rate': 0.9123505976095617}\n",
      "Prediction for year 2019 of TSLA is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0013882155792254646, 'rmse': 0.03725876513285786, 'mae': 0.013816438518766712, 'hit_rate': 0.9166666666666666}\n",
      "Prediction for year 2020 of TSLA is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0008068545517829099, 'rmse': 0.02840518529745775, 'mae': 0.013645096673121101, 'hit_rate': 0.9282868525896414}\n",
      "Prediction for year 2021 of TSLA is done.\n",
      "2021: {'model': SVR(), 'mse': 7.787384081033388e-05, 'rmse': 0.008824615618276747, 'mae': 0.0038581243745302745, 'hit_rate': 0.9761904761904762}\n",
      "Prediction for year 2022 of TSLA is done.\n",
      "2022: {'model': SVR(), 'mse': 7.438041814489035e-05, 'rmse': 0.008624408277956833, 'mae': 0.004947782565114318, 'hit_rate': 0.9718875502008032}\n",
      "Prediction for year 2017 of NOW is done.\n",
      "2017: {'model': SVR(), 'mse': 2.5011052525134898e-05, 'rmse': 0.005001105130382173, 'mae': 0.001975356908362522, 'hit_rate': 0.9437751004016064}\n",
      "Prediction for year 2018 of NOW is done.\n",
      "2018: {'model': SVR(), 'mse': 0.00017062161162358154, 'rmse': 0.013062220776865684, 'mae': 0.005728244658965146, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2019 of NOW is done.\n",
      "2019: {'model': SVR(), 'mse': 0.000378079752956757, 'rmse': 0.01944427301178311, 'mae': 0.007476155461852241, 'hit_rate': 0.9444444444444444}\n",
      "Prediction for year 2020 of NOW is done.\n",
      "2020: {'model': SVR(), 'mse': 8.330228213218899e-05, 'rmse': 0.009127008388962344, 'mae': 0.004221837343107423, 'hit_rate': 0.9402390438247012}\n",
      "Prediction for year 2021 of NOW is done.\n",
      "2021: {'model': SVR(), 'mse': 0.00012608443800834815, 'rmse': 0.011228732698232163, 'mae': 0.004354128073531289, 'hit_rate': 0.9603174603174603}\n",
      "Prediction for year 2022 of NOW is done.\n",
      "2022: {'model': SVR(), 'mse': 0.00017656947502516708, 'rmse': 0.013287944725395536, 'mae': 0.005417378837564852, 'hit_rate': 0.9678714859437751}\n",
      "Prediction for year 2017 of DTE is done.\n",
      "2017: {'model': SVR(), 'mse': 1.7638041478908653e-06, 'rmse': 0.0013280828844205717, 'mae': 0.000796155164837867, 'hit_rate': 0.9879518072289156}\n",
      "Prediction for year 2018 of DTE is done.\n",
      "2018: {'model': SVR(), 'mse': 2.3082711709453992e-05, 'rmse': 0.004804447076350617, 'mae': 0.001592519199337739, 'hit_rate': 0.9362549800796812}\n",
      "Prediction for year 2019 of DTE is done.\n",
      "2019: {'model': SVR(), 'mse': 0.000577252893893621, 'rmse': 0.024026087777530927, 'mae': 0.007058774533078209, 'hit_rate': 0.9325396825396826}\n",
      "Prediction for year 2020 of DTE is done.\n",
      "2020: {'model': SVR(), 'mse': 0.00018824302329832775, 'rmse': 0.01372016848651385, 'mae': 0.006049921088834772, 'hit_rate': 0.9243027888446215}\n",
      "Prediction for year 2021 of DTE is done.\n",
      "2021: {'model': SVR(), 'mse': 1.70875116234463e-06, 'rmse': 0.0013071920908361671, 'mae': 0.0009411625259738558, 'hit_rate': 0.9642857142857143}\n",
      "Prediction for year 2022 of DTE is done.\n",
      "2022: {'model': SVR(), 'mse': 6.751231037048245e-06, 'rmse': 0.0025983131137428846, 'mae': 0.0014639301344261358, 'hit_rate': 0.9518072289156626}\n",
      "Prediction for year 2017 of ADBE is done.\n",
      "2017: {'model': SVR(), 'mse': 0.00010498073016303378, 'rmse': 0.010246010451050388, 'mae': 0.002968283952438871, 'hit_rate': 0.9718875502008032}\n",
      "Prediction for year 2018 of ADBE is done.\n",
      "2018: {'model': SVR(), 'mse': 0.00021144672973626632, 'rmse': 0.01454120798751831, 'mae': 0.006177335243463456, 'hit_rate': 0.9362549800796812}\n",
      "Prediction for year 2019 of ADBE is done.\n",
      "2019: {'model': SVR(), 'mse': 0.000447482036345991, 'rmse': 0.02115377120860465, 'mae': 0.006797582524320673, 'hit_rate': 0.9563492063492064}\n",
      "Prediction for year 2020 of ADBE is done.\n",
      "2020: {'model': SVR(), 'mse': 7.718295187970519e-05, 'rmse': 0.008785382853336854, 'mae': 0.004053633055483032, 'hit_rate': 0.9681274900398407}\n",
      "Prediction for year 2021 of ADBE is done.\n",
      "2021: {'model': SVR(), 'mse': 0.00010904308878500224, 'rmse': 0.010442369883556233, 'mae': 0.0033821094745386583, 'hit_rate': 0.9761904761904762}\n",
      "Prediction for year 2022 of ADBE is done.\n",
      "2022: {'model': SVR(), 'mse': 0.0001943337502007712, 'rmse': 0.013940364062705508, 'mae': 0.004359939466311451, 'hit_rate': 0.9558232931726908}\n",
      "Prediction for year 2017 of COO is done.\n",
      "2017: {'model': SVR(), 'mse': 4.4717637816513776e-05, 'rmse': 0.0066871247794933345, 'mae': 0.0022408187581696467, 'hit_rate': 0.9598393574297188}\n",
      "Prediction for year 2018 of COO is done.\n",
      "2018: {'model': SVR(), 'mse': 0.0001027704672213324, 'rmse': 0.010137576989662393, 'mae': 0.0028424911577552576, 'hit_rate': 0.9601593625498008}\n",
      "Prediction for year 2019 of COO is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0003545729500619148, 'rmse': 0.018830107542494673, 'mae': 0.005877219527877996, 'hit_rate': 0.9603174603174603}\n",
      "Prediction for year 2020 of COO is done.\n",
      "2020: {'model': SVR(), 'mse': 7.914220269872991e-05, 'rmse': 0.008896190347487508, 'mae': 0.003840061764870963, 'hit_rate': 0.9442231075697212}\n",
      "Prediction for year 2021 of COO is done.\n",
      "2021: {'model': SVR(), 'mse': 1.8448680032590867e-05, 'rmse': 0.004295192665363321, 'mae': 0.0016761565634637885, 'hit_rate': 0.9801587301587301}\n",
      "Prediction for year 2022 of COO is done.\n",
      "2022: {'model': SVR(), 'mse': 9.337885650150263e-05, 'rmse': 0.009663273591361399, 'mae': 0.0035569608494587703, 'hit_rate': 0.9759036144578314}\n",
      "Prediction for year 2017 of DHI is done.\n",
      "2017: {'model': SVR(), 'mse': 4.720094522202651e-06, 'rmse': 0.002172577851816282, 'mae': 0.0012445188823982769, 'hit_rate': 0.9759036144578314}\n",
      "Prediction for year 2018 of DHI is done.\n",
      "2018: {'model': SVR(), 'mse': 0.0001450965299815618, 'rmse': 0.01204560210124682, 'mae': 0.004653614915546523, 'hit_rate': 0.9482071713147411}\n",
      "Prediction for year 2019 of DHI is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0006394459479643887, 'rmse': 0.025287268495517438, 'mae': 0.007415393493865753, 'hit_rate': 0.9365079365079365}\n",
      "Prediction for year 2020 of DHI is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0003673219188917651, 'rmse': 0.019165644233674093, 'mae': 0.008471896648657332, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2021 of DHI is done.\n",
      "2021: {'model': SVR(), 'mse': 1.7630415565531553e-05, 'rmse': 0.004198858840867546, 'mae': 0.0022287715406703857, 'hit_rate': 0.9722222222222222}\n",
      "Prediction for year 2022 of DHI is done.\n",
      "2022: {'model': SVR(), 'mse': 3.7200544185897716e-05, 'rmse': 0.006099224884024011, 'mae': 0.0028162990138660055, 'hit_rate': 0.9558232931726908}\n",
      "Prediction for year 2017 of ADSK is done.\n",
      "2017: {'model': SVR(), 'mse': 0.00028932700739505454, 'rmse': 0.017009615145412743, 'mae': 0.003765670946819875, 'hit_rate': 0.9558232931726908}\n",
      "Prediction for year 2018 of ADSK is done.\n",
      "2018: {'model': SVR(), 'mse': 0.00015947968778837575, 'rmse': 0.012628526746551861, 'mae': 0.004929916328782188, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2019 of ADSK is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0005080789266428787, 'rmse': 0.022540606172924426, 'mae': 0.007551501606722639, 'hit_rate': 0.9563492063492064}\n",
      "Prediction for year 2020 of ADSK is done.\n",
      "2020: {'model': SVR(), 'mse': 0.00010102691787271488, 'rmse': 0.010051214746124713, 'mae': 0.004820754370177833, 'hit_rate': 0.9721115537848606}\n",
      "Prediction for year 2021 of ADSK is done.\n",
      "2021: {'model': SVR(), 'mse': 0.000137400585947586, 'rmse': 0.011721799603626825, 'mae': 0.0027865326906528036, 'hit_rate': 0.9801587301587301}\n",
      "Prediction for year 2022 of ADSK is done.\n",
      "2022: {'model': SVR(), 'mse': 0.00019406320198164624, 'rmse': 0.013930656911346508, 'mae': 0.005521121532429349, 'hit_rate': 0.927710843373494}\n",
      "Prediction for year 2017 of TRV is done.\n",
      "2017: {'model': SVR(), 'mse': 4.3391685126448364e-05, 'rmse': 0.006587236531843104, 'mae': 0.0022196249400182814, 'hit_rate': 0.9317269076305221}\n",
      "Prediction for year 2018 of TRV is done.\n",
      "2018: {'model': SVR(), 'mse': 2.2331155368940963e-05, 'rmse': 0.0047255851879889925, 'mae': 0.002256697809038486, 'hit_rate': 0.9402390438247012}\n",
      "Prediction for year 2019 of TRV is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0006093595969096336, 'rmse': 0.024685210084373063, 'mae': 0.007037530382849108, 'hit_rate': 0.9126984126984127}\n",
      "Prediction for year 2020 of TRV is done.\n",
      "2020: {'model': SVR(), 'mse': 0.00015505543315578432, 'rmse': 0.012452125648088536, 'mae': 0.0062635668721985095, 'hit_rate': 0.9282868525896414}\n",
      "Prediction for year 2021 of TRV is done.\n",
      "2021: {'model': SVR(), 'mse': 2.6130505106586374e-06, 'rmse': 0.00161649327578516, 'mae': 0.0011768478719705298, 'hit_rate': 0.9722222222222222}\n",
      "Prediction for year 2022 of TRV is done.\n",
      "2022: {'model': SVR(), 'mse': 5.001927933578405e-06, 'rmse': 0.0022364990350050244, 'mae': 0.001370625216912436, 'hit_rate': 0.9678714859437751}\n",
      "Prediction for year 2017 of AES is done.\n",
      "2017: {'model': SVR(), 'mse': 5.120377695934798e-05, 'rmse': 0.007155681446190012, 'mae': 0.0019941263887255675, 'hit_rate': 0.9718875502008032}\n",
      "Prediction for year 2018 of AES is done.\n",
      "2018: {'model': SVR(), 'mse': 2.8482231840135888e-05, 'rmse': 0.005336874725917397, 'mae': 0.001663723714695006, 'hit_rate': 0.952191235059761}\n",
      "Prediction for year 2019 of AES is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0007103794409770554, 'rmse': 0.02665294432097616, 'mae': 0.007499255905752606, 'hit_rate': 0.9206349206349206}\n",
      "Prediction for year 2020 of AES is done.\n",
      "2020: {'model': SVR(), 'mse': 0.00040322958516938816, 'rmse': 0.020080577311655863, 'mae': 0.00982603149964922, 'hit_rate': 0.9322709163346613}\n",
      "Prediction for year 2021 of AES is done.\n",
      "2021: {'model': SVR(), 'mse': 3.0747663038255607e-06, 'rmse': 0.0017535011559236455, 'mae': 0.0013064792646442372, 'hit_rate': 0.9603174603174603}\n",
      "Prediction for year 2022 of AES is done.\n",
      "2022: {'model': SVR(), 'mse': 4.7418599728065073e-05, 'rmse': 0.0068861164474662406, 'mae': 0.0028107667339672903, 'hit_rate': 0.9678714859437751}\n",
      "Prediction for year 2017 of RF is done.\n",
      "2017: {'model': SVR(), 'mse': 1.0730552234148371e-05, 'rmse': 0.0032757521631143543, 'mae': 0.0015220602977061386, 'hit_rate': 0.9759036144578314}\n",
      "Prediction for year 2018 of RF is done.\n",
      "2018: {'model': SVR(), 'mse': 4.312429217873027e-05, 'rmse': 0.006566908875470275, 'mae': 0.002599493434607942, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2019 of RF is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0009136156884983718, 'rmse': 0.030226076300081884, 'mae': 0.009420569708092718, 'hit_rate': 0.9563492063492064}\n",
      "Prediction for year 2020 of RF is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0006497705494897697, 'rmse': 0.02549059727605004, 'mae': 0.013430472262092954, 'hit_rate': 0.9243027888446215}\n",
      "Prediction for year 2021 of RF is done.\n",
      "2021: {'model': SVR(), 'mse': 2.9322508914037334e-05, 'rmse': 0.005415026215452454, 'mae': 0.0023603895874184243, 'hit_rate': 0.9642857142857143}\n",
      "Prediction for year 2022 of RF is done.\n",
      "2022: {'model': SVR(), 'mse': 6.681575871675613e-05, 'rmse': 0.008174090696631407, 'mae': 0.0029136220303682494, 'hit_rate': 0.9799196787148594}\n",
      "Prediction for year 2017 of WMT is done.\n",
      "2017: {'model': SVR(), 'mse': 0.00011730898786738556, 'rmse': 0.010830927377994258, 'mae': 0.0027869864138024888, 'hit_rate': 0.963855421686747}\n",
      "Prediction for year 2018 of WMT is done.\n",
      "2018: {'model': SVR(), 'mse': 5.3918365758724226e-05, 'rmse': 0.007342912620937568, 'mae': 0.0021332500780093504, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2019 of WMT is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0002242069044348432, 'rmse': 0.014973540143694918, 'mae': 0.004309850935582282, 'hit_rate': 0.9603174603174603}\n",
      "Prediction for year 2020 of WMT is done.\n",
      "2020: {'model': SVR(), 'mse': 8.555377816912857e-05, 'rmse': 0.009249528537667667, 'mae': 0.0032254683017031356, 'hit_rate': 0.952191235059761}\n",
      "Prediction for year 2021 of WMT is done.\n",
      "2021: {'model': SVR(), 'mse': 2.358643344495235e-06, 'rmse': 0.0015357875323413833, 'mae': 0.0009841220302108948, 'hit_rate': 0.9682539682539683}\n",
      "Prediction for year 2022 of WMT is done.\n",
      "2022: {'model': SVR(), 'mse': 0.0001403379527615968, 'rmse': 0.011846432068838146, 'mae': 0.0034139321187521316, 'hit_rate': 0.9397590361445783}\n",
      "Prediction for year 2017 of LNT is done.\n",
      "2017: {'model': SVR(), 'mse': 4.187713497148871e-06, 'rmse': 0.0020463903579593192, 'mae': 0.0009098489835041507, 'hit_rate': 0.963855421686747}\n",
      "Prediction for year 2018 of LNT is done.\n",
      "2018: {'model': SVR(), 'mse': 1.4028204607133296e-05, 'rmse': 0.003745424489578357, 'mae': 0.0014488159486769321, 'hit_rate': 0.9800796812749004}\n",
      "Prediction for year 2019 of LNT is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0003384788881858997, 'rmse': 0.018397795742585567, 'mae': 0.005607469419101859, 'hit_rate': 0.9246031746031746}\n",
      "Prediction for year 2020 of LNT is done.\n",
      "2020: {'model': SVR(), 'mse': 0.00011982399653633209, 'rmse': 0.010946414780024193, 'mae': 0.005152521431794518, 'hit_rate': 0.9442231075697212}\n",
      "Prediction for year 2021 of LNT is done.\n",
      "2021: {'model': SVR(), 'mse': 1.748188017851978e-06, 'rmse': 0.001322190613282358, 'mae': 0.000962236999508918, 'hit_rate': 0.9642857142857143}\n",
      "Prediction for year 2022 of LNT is done.\n",
      "2022: {'model': SVR(), 'mse': 1.7692083342493344e-05, 'rmse': 0.004206195827882167, 'mae': 0.0022205539269900677, 'hit_rate': 0.9718875502008032}\n",
      "Prediction for year 2017 of COF is done.\n",
      "2017: {'model': SVR(), 'mse': 5.061527323842468e-05, 'rmse': 0.007114441175413898, 'mae': 0.0020171552584820644, 'hit_rate': 0.9477911646586346}\n",
      "Prediction for year 2018 of COF is done.\n",
      "2018: {'model': SVR(), 'mse': 3.05752887176804e-05, 'rmse': 0.005529492627509363, 'mae': 0.0023228458027325896, 'hit_rate': 0.9402390438247012}\n",
      "Prediction for year 2019 of COF is done.\n",
      "2019: {'model': SVR(), 'mse': 0.001012845145672074, 'rmse': 0.03182522813228641, 'mae': 0.009423968961159797, 'hit_rate': 0.9523809523809523}\n",
      "Prediction for year 2020 of COF is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0007867192667471812, 'rmse': 0.028048516302064556, 'mae': 0.014891057804303328, 'hit_rate': 0.9123505976095617}\n",
      "Prediction for year 2021 of COF is done.\n",
      "2021: {'model': SVR(), 'mse': 1.7497175563727773e-05, 'rmse': 0.0041829625343442626, 'mae': 0.002031995876366641, 'hit_rate': 0.9761904761904762}\n",
      "Prediction for year 2022 of COF is done.\n",
      "2022: {'model': SVR(), 'mse': 6.551374129552293e-05, 'rmse': 0.008094055923671576, 'mae': 0.003384791524364699, 'hit_rate': 0.9678714859437751}\n",
      "Prediction for year 2017 of EXR is done.\n",
      "2017: {'model': SVR(), 'mse': 1.920823686515282e-05, 'rmse': 0.004382720258601138, 'mae': 0.001878592768728278, 'hit_rate': 0.9477911646586346}\n",
      "Prediction for year 2018 of EXR is done.\n",
      "2018: {'model': SVR(), 'mse': 5.855818216085206e-06, 'rmse': 0.0024198797937263756, 'mae': 0.0011010696250132136, 'hit_rate': 0.9641434262948207}\n",
      "Prediction for year 2019 of EXR is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0003261803524702617, 'rmse': 0.018060463794439548, 'mae': 0.0051704831644082535, 'hit_rate': 0.9365079365079365}\n",
      "Prediction for year 2020 of EXR is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0001588556222387009, 'rmse': 0.01260379396208542, 'mae': 0.00558165750255233, 'hit_rate': 0.9322709163346613}\n",
      "Prediction for year 2021 of EXR is done.\n",
      "2021: {'model': SVR(), 'mse': 8.762261948020465e-06, 'rmse': 0.002960111813432132, 'mae': 0.00155448309598317, 'hit_rate': 0.9722222222222222}\n",
      "Prediction for year 2022 of EXR is done.\n",
      "2022: {'model': SVR(), 'mse': 0.00013995488226638535, 'rmse': 0.011830252840340538, 'mae': 0.00407244458629487, 'hit_rate': 0.9558232931726908}\n",
      "Prediction for year 2017 of PCAR is done.\n",
      "2017: {'model': SVR(), 'mse': 3.655523474867217e-05, 'rmse': 0.006046092519030136, 'mae': 0.002280459604542948, 'hit_rate': 0.9678714859437751}\n",
      "Prediction for year 2018 of PCAR is done.\n",
      "2018: {'model': SVR(), 'mse': 4.314626491004942e-05, 'rmse': 0.0065685816513193634, 'mae': 0.0025750395344427694, 'hit_rate': 0.9601593625498008}\n",
      "Prediction for year 2019 of PCAR is done.\n",
      "2019: {'model': SVR(), 'mse': 0.000265815675006416, 'rmse': 0.01630385460578007, 'mae': 0.0055430783223689925, 'hit_rate': 0.9206349206349206}\n",
      "Prediction for year 2020 of PCAR is done.\n",
      "2020: {'model': SVR(), 'mse': 7.080402324206511e-05, 'rmse': 0.008414512656242493, 'mae': 0.0030344040891100727, 'hit_rate': 0.9442231075697212}\n",
      "Prediction for year 2021 of PCAR is done.\n",
      "2021: {'model': SVR(), 'mse': 1.3769423904465715e-05, 'rmse': 0.003710717437971492, 'mae': 0.0015814474482468352, 'hit_rate': 0.9801587301587301}\n",
      "Prediction for year 2022 of PCAR is done.\n",
      "2022: {'model': SVR(), 'mse': 2.8413682893679332e-05, 'rmse': 0.005330448657822279, 'mae': 0.002214528531327751, 'hit_rate': 0.9759036144578314}\n",
      "Prediction for year 2017 of EIX is done.\n",
      "2017: {'model': SVR(), 'mse': 0.00014040615371914563, 'rmse': 0.011849310263434984, 'mae': 0.002826113580821655, 'hit_rate': 0.9437751004016064}\n",
      "Prediction for year 2018 of EIX is done.\n",
      "2018: {'model': SVR(), 'mse': 0.0003227189488891336, 'rmse': 0.017964380002915035, 'mae': 0.004868867947980773, 'hit_rate': 0.9322709163346613}\n",
      "Prediction for year 2019 of EIX is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0004884579440347465, 'rmse': 0.022101084680050127, 'mae': 0.008082604169229481, 'hit_rate': 0.9246031746031746}\n",
      "Prediction for year 2020 of EIX is done.\n",
      "2020: {'model': SVR(), 'mse': 9.4213797224339e-05, 'rmse': 0.009706379202583165, 'mae': 0.003931316514881844, 'hit_rate': 0.952191235059761}\n",
      "Prediction for year 2021 of EIX is done.\n",
      "2021: {'model': SVR(), 'mse': 1.4963918461288621e-06, 'rmse': 0.00122327096185958, 'mae': 0.000909076148954096, 'hit_rate': 0.9642857142857143}\n",
      "Prediction for year 2022 of EIX is done.\n",
      "2022: {'model': SVR(), 'mse': 1.71286923394213e-05, 'rmse': 0.004138682440031042, 'mae': 0.0017867315152893116, 'hit_rate': 0.963855421686747}\n",
      "Prediction for year 2017 of TMO is done.\n",
      "2017: {'model': SVR(), 'mse': 2.5641591318296222e-05, 'rmse': 0.005063752691265266, 'mae': 0.0017619652306069527, 'hit_rate': 0.9839357429718876}\n",
      "Prediction for year 2018 of TMO is done.\n",
      "2018: {'model': SVR(), 'mse': 3.644826960649515e-05, 'rmse': 0.006037240230974344, 'mae': 0.002756986949923379, 'hit_rate': 0.9800796812749004}\n",
      "Prediction for year 2019 of TMO is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0002713619085079538, 'rmse': 0.01647306615381465, 'mae': 0.006651000051448904, 'hit_rate': 0.9444444444444444}\n",
      "Prediction for year 2020 of TMO is done.\n",
      "2020: {'model': SVR(), 'mse': 9.713742705769548e-05, 'rmse': 0.00985583213420843, 'mae': 0.004308172198879428, 'hit_rate': 0.9641434262948207}\n",
      "Prediction for year 2021 of TMO is done.\n",
      "2021: {'model': SVR(), 'mse': 1.2620577710235074e-05, 'rmse': 0.0035525452439392063, 'mae': 0.0015558594920323347, 'hit_rate': 0.9603174603174603}\n",
      "Prediction for year 2022 of TMO is done.\n",
      "2022: {'model': SVR(), 'mse': 4.635695332090971e-05, 'rmse': 0.006808594078141956, 'mae': 0.002916284984956529, 'hit_rate': 0.9759036144578314}\n",
      "Prediction for year 2017 of FE is done.\n",
      "2017: {'model': SVR(), 'mse': 4.684783312120477e-05, 'rmse': 0.006844547692960052, 'mae': 0.0015556952534258946, 'hit_rate': 0.9799196787148594}\n",
      "Prediction for year 2018 of FE is done.\n",
      "2018: {'model': SVR(), 'mse': 4.159907203070458e-06, 'rmse': 0.0020395850565912807, 'mae': 0.0011454879746219803, 'hit_rate': 0.9681274900398407}\n",
      "Prediction for year 2019 of FE is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0004866594845203555, 'rmse': 0.02206036002698858, 'mae': 0.006264984374547302, 'hit_rate': 0.9563492063492064}\n",
      "Prediction for year 2020 of FE is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0005110139716155942, 'rmse': 0.02260561814274483, 'mae': 0.007344455433876726, 'hit_rate': 0.9482071713147411}\n",
      "Prediction for year 2021 of FE is done.\n",
      "2021: {'model': SVR(), 'mse': 2.8664902156176083e-06, 'rmse': 0.0016930712376086272, 'mae': 0.0009613143783917191, 'hit_rate': 0.9563492063492064}\n",
      "Prediction for year 2022 of FE is done.\n",
      "2022: {'model': SVR(), 'mse': 3.2017189109188334e-06, 'rmse': 0.001789334767705259, 'mae': 0.0011997759348796092, 'hit_rate': 0.9879518072289156}\n",
      "Prediction for year 2017 of RSG is done.\n",
      "2017: {'model': SVR(), 'mse': 2.5197104822660435e-05, 'rmse': 0.005019671784356069, 'mae': 0.0014310132371015143, 'hit_rate': 0.9558232931726908}\n",
      "Prediction for year 2018 of RSG is done.\n",
      "2018: {'model': SVR(), 'mse': 1.971929167372321e-05, 'rmse': 0.004440640907991009, 'mae': 0.0016078367070562283, 'hit_rate': 0.9721115537848606}\n",
      "Prediction for year 2019 of RSG is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0003209536265069818, 'rmse': 0.017915178662435433, 'mae': 0.005500425386416059, 'hit_rate': 0.9246031746031746}\n",
      "Prediction for year 2020 of RSG is done.\n",
      "2020: {'model': SVR(), 'mse': 7.743907540035333e-05, 'rmse': 0.008799947465772357, 'mae': 0.004293032100519217, 'hit_rate': 0.9123505976095617}\n",
      "Prediction for year 2021 of RSG is done.\n",
      "2021: {'model': SVR(), 'mse': 1.741434757827963e-05, 'rmse': 0.004173050152859372, 'mae': 0.0016982709513483926, 'hit_rate': 0.9682539682539683}\n",
      "Prediction for year 2022 of RSG is done.\n",
      "2022: {'model': SVR(), 'mse': 9.51563741183481e-06, 'rmse': 0.0030847426816243218, 'mae': 0.0015334907690249247, 'hit_rate': 0.9437751004016064}\n",
      "Prediction for year 2017 of DOV is done.\n",
      "2017: {'model': SVR(), 'mse': 2.2223731563014408e-05, 'rmse': 0.004714205294958463, 'mae': 0.0017122822224279598, 'hit_rate': 0.9678714859437751}\n",
      "Prediction for year 2018 of DOV is done.\n",
      "2018: {'model': SVR(), 'mse': 5.0876372693656575e-05, 'rmse': 0.007132767533970007, 'mae': 0.002405470260197939, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2019 of DOV is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0005375798197640154, 'rmse': 0.02318576761213688, 'mae': 0.007415286425317739, 'hit_rate': 0.9325396825396826}\n",
      "Prediction for year 2020 of DOV is done.\n",
      "2020: {'model': SVR(), 'mse': 7.940229728578258e-05, 'rmse': 0.008910796669534244, 'mae': 0.0037319749922957337, 'hit_rate': 0.952191235059761}\n",
      "Prediction for year 2021 of DOV is done.\n",
      "2021: {'model': SVR(), 'mse': 1.389666033582932e-05, 'rmse': 0.0037278224657069335, 'mae': 0.0015239140382880582, 'hit_rate': 0.9761904761904762}\n",
      "Prediction for year 2022 of DOV is done.\n",
      "2022: {'model': SVR(), 'mse': 3.199234803508935e-05, 'rmse': 0.005656177864520294, 'mae': 0.0023344885254757467, 'hit_rate': 0.9518072289156626}\n",
      "Prediction for year 2017 of AMT is done.\n",
      "2017: {'model': SVR(), 'mse': 2.3354201815165003e-05, 'rmse': 0.004832618525723399, 'mae': 0.0020997890479355634, 'hit_rate': 0.9558232931726908}\n",
      "Prediction for year 2018 of AMT is done.\n",
      "2018: {'model': SVR(), 'mse': 2.1707273420891414e-05, 'rmse': 0.0046591065045662365, 'mae': 0.0016560520760705883, 'hit_rate': 0.9681274900398407}\n",
      "Prediction for year 2019 of AMT is done.\n",
      "2019: {'model': SVR(), 'mse': 0.00045477791539444965, 'rmse': 0.021325522628870077, 'mae': 0.007173723760327263, 'hit_rate': 0.9246031746031746}\n",
      "Prediction for year 2020 of AMT is done.\n",
      "2020: {'model': SVR(), 'mse': 0.00010906480735092092, 'rmse': 0.010443409756919477, 'mae': 0.004181722356681199, 'hit_rate': 0.9482071713147411}\n",
      "Prediction for year 2021 of AMT is done.\n",
      "2021: {'model': SVR(), 'mse': 1.1076430557074311e-05, 'rmse': 0.0033281271846301655, 'mae': 0.0013798374607136249, 'hit_rate': 0.9761904761904762}\n",
      "Prediction for year 2022 of AMT is done.\n",
      "2022: {'model': SVR(), 'mse': 5.212144213717307e-05, 'rmse': 0.007219518137464098, 'mae': 0.003281626948317655, 'hit_rate': 0.9518072289156626}\n",
      "Prediction for year 2017 of VZ is done.\n",
      "2017: {'model': SVR(), 'mse': 4.497476293067714e-05, 'rmse': 0.006706322608604297, 'mae': 0.002105660203466409, 'hit_rate': 0.9437751004016064}\n",
      "Prediction for year 2018 of VZ is done.\n",
      "2018: {'model': SVR(), 'mse': 3.1404672810817774e-05, 'rmse': 0.005603987224362469, 'mae': 0.002578776085298339, 'hit_rate': 0.9362549800796812}\n",
      "Prediction for year 2019 of VZ is done.\n",
      "2019: {'model': SVR(), 'mse': 0.00013482660440241893, 'rmse': 0.01161148588262583, 'mae': 0.0037741163509942967, 'hit_rate': 0.9365079365079365}\n",
      "Prediction for year 2020 of VZ is done.\n",
      "2020: {'model': SVR(), 'mse': 1.0661756850832481e-05, 'rmse': 0.0032652345782244315, 'mae': 0.0012906396610324646, 'hit_rate': 0.9601593625498008}\n",
      "Prediction for year 2021 of VZ is done.\n",
      "2021: {'model': SVR(), 'mse': 4.144923934473604e-06, 'rmse': 0.0020359086262584586, 'mae': 0.0008761891611076766, 'hit_rate': 0.9523809523809523}\n",
      "Prediction for year 2022 of VZ is done.\n",
      "2022: {'model': SVR(), 'mse': 5.6590488166608176e-05, 'rmse': 0.007522664964399795, 'mae': 0.003025289451443757, 'hit_rate': 0.9558232931726908}\n",
      "Prediction for year 2017 of NUE is done.\n",
      "2017: {'model': SVR(), 'mse': 3.8390035566920655e-05, 'rmse': 0.006195969300030517, 'mae': 0.002351890728419936, 'hit_rate': 0.963855421686747}\n",
      "Prediction for year 2018 of NUE is done.\n",
      "2018: {'model': SVR(), 'mse': 8.892867149701858e-06, 'rmse': 0.002982091069987947, 'mae': 0.0016337333225367539, 'hit_rate': 0.9760956175298805}\n",
      "Prediction for year 2019 of NUE is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0004665957786898192, 'rmse': 0.021600828194535023, 'mae': 0.00691250997375108, 'hit_rate': 0.9682539682539683}\n",
      "Prediction for year 2020 of NUE is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0002077179572672628, 'rmse': 0.01441242371245249, 'mae': 0.006657752770577807, 'hit_rate': 0.9282868525896414}\n",
      "Prediction for year 2021 of NUE is done.\n",
      "2021: {'model': SVR(), 'mse': 0.00016829359817581847, 'rmse': 0.012972802248389453, 'mae': 0.006415095163937055, 'hit_rate': 0.9166666666666666}\n",
      "Prediction for year 2022 of NUE is done.\n",
      "2022: {'model': SVR(), 'mse': 0.0001367100253550203, 'rmse': 0.011692306246203968, 'mae': 0.00488535325382917, 'hit_rate': 0.9477911646586346}\n",
      "Prediction for year 2017 of OKE is done.\n",
      "2017: {'model': SVR(), 'mse': 2.0766311622917854e-06, 'rmse': 0.0014410521025597185, 'mae': 0.001113321399459466, 'hit_rate': 0.9598393574297188}\n",
      "Prediction for year 2018 of OKE is done.\n",
      "2018: {'model': SVR(), 'mse': 4.135788251429943e-06, 'rmse': 0.002033663750827541, 'mae': 0.0012215475432186488, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2019 of OKE is done.\n",
      "2019: {'model': SVR(), 'mse': 0.002550943814174683, 'rmse': 0.05050686898011678, 'mae': 0.011974345954174055, 'hit_rate': 0.9047619047619048}\n",
      "Prediction for year 2020 of OKE is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0010292509200506986, 'rmse': 0.03208194071515467, 'mae': 0.017173884107018155, 'hit_rate': 0.9243027888446215}\n",
      "Prediction for year 2021 of OKE is done.\n",
      "2021: {'model': SVR(), 'mse': 4.20853224537106e-06, 'rmse': 0.002051470751770802, 'mae': 0.0015751541236293377, 'hit_rate': 0.9761904761904762}\n",
      "Prediction for year 2022 of OKE is done.\n",
      "2022: {'model': SVR(), 'mse': 6.428374982078612e-06, 'rmse': 0.0025354240241187687, 'mae': 0.0016893745722763812, 'hit_rate': 0.9678714859437751}\n",
      "Prediction for year 2017 of WAB is done.\n",
      "2017: {'model': SVR(), 'mse': 0.00011935826583082177, 'rmse': 0.010925120861153974, 'mae': 0.0027736711180190578, 'hit_rate': 0.9678714859437751}\n",
      "Prediction for year 2018 of WAB is done.\n",
      "2018: {'model': SVR(), 'mse': 0.0001821053522216519, 'rmse': 0.013494641611456448, 'mae': 0.005626210439555502, 'hit_rate': 0.9482071713147411}\n",
      "Prediction for year 2019 of WAB is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0005456052241898954, 'rmse': 0.023358193941096887, 'mae': 0.008202424594489097, 'hit_rate': 0.9444444444444444}\n",
      "Prediction for year 2020 of WAB is done.\n",
      "2020: {'model': SVR(), 'mse': 0.00024683510420439326, 'rmse': 0.01571098673554253, 'mae': 0.006781245243560599, 'hit_rate': 0.9043824701195219}\n",
      "Prediction for year 2021 of WAB is done.\n",
      "2021: {'model': SVR(), 'mse': 3.019154833633757e-06, 'rmse': 0.0017375715333861098, 'mae': 0.0012357836893811553, 'hit_rate': 0.9642857142857143}\n",
      "Prediction for year 2022 of WAB is done.\n",
      "2022: {'model': SVR(), 'mse': 4.342945645369574e-06, 'rmse': 0.002083973523193031, 'mae': 0.0015050415409031757, 'hit_rate': 0.9678714859437751}\n",
      "Prediction for year 2017 of BIIB is done.\n",
      "2017: {'model': SVR(), 'mse': 1.4806105076275624e-05, 'rmse': 0.003847870200029573, 'mae': 0.0017247846599994922, 'hit_rate': 0.9477911646586346}\n",
      "Prediction for year 2018 of BIIB is done.\n",
      "2018: {'model': SVR(), 'mse': 0.0006733999083643022, 'rmse': 0.025949950064774734, 'mae': 0.004767217996379844, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2019 of BIIB is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0005736662142397116, 'rmse': 0.023951330114206842, 'mae': 0.007137451857974351, 'hit_rate': 0.9444444444444444}\n",
      "Prediction for year 2020 of BIIB is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0010806847555880795, 'rmse': 0.032873770023958, 'mae': 0.006865547481249397, 'hit_rate': 0.9442231075697212}\n",
      "Prediction for year 2021 of BIIB is done.\n",
      "2021: {'model': SVR(), 'mse': 0.00046658826856821783, 'rmse': 0.021600654355093455, 'mae': 0.004139328136306349, 'hit_rate': 0.9682539682539683}\n",
      "Prediction for year 2022 of BIIB is done.\n",
      "2022: {'model': SVR(), 'mse': 0.00044491691579606513, 'rmse': 0.021093053733304362, 'mae': 0.003431766686653293, 'hit_rate': 0.9598393574297188}\n",
      "Prediction for year 2017 of NTRS is done.\n",
      "2017: {'model': SVR(), 'mse': 4.96660417875077e-05, 'rmse': 0.007047413836827499, 'mae': 0.0021821478084986666, 'hit_rate': 0.9477911646586346}\n",
      "Prediction for year 2018 of NTRS is done.\n",
      "2018: {'model': SVR(), 'mse': 3.19828088920605e-05, 'rmse': 0.0056553345517361304, 'mae': 0.0023979896463457826, 'hit_rate': 0.9561752988047809}\n",
      "Prediction for year 2019 of NTRS is done.\n",
      "2019: {'model': SVR(), 'mse': 0.0005945125558162384, 'rmse': 0.02438262815646087, 'mae': 0.007985117049876247, 'hit_rate': 0.9285714285714286}\n",
      "Prediction for year 2020 of NTRS is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0001902400069079616, 'rmse': 0.013792751970073326, 'mae': 0.006841762943147714, 'hit_rate': 0.9163346613545816}\n",
      "Prediction for year 2021 of NTRS is done.\n",
      "2021: {'model': SVR(), 'mse': 3.132430253626492e-05, 'rmse': 0.0055968118189077005, 'mae': 0.002378137997491847, 'hit_rate': 0.9761904761904762}\n",
      "Prediction for year 2022 of NTRS is done.\n",
      "2022: {'model': SVR(), 'mse': 6.56450533054759e-05, 'rmse': 0.008102163495355787, 'mae': 0.003055482380441641, 'hit_rate': 0.9799196787148594}\n",
      "Prediction for year 2017 of MGM is done.\n",
      "2017: {'model': SVR(), 'mse': 3.893572183344739e-06, 'rmse': 0.001973213668953451, 'mae': 0.0013667925691869516, 'hit_rate': 0.9759036144578314}\n",
      "Prediction for year 2018 of MGM is done.\n",
      "2018: {'model': SVR(), 'mse': 9.346134012692981e-05, 'rmse': 0.009667540541778442, 'mae': 0.004028303725448234, 'hit_rate': 0.9641434262948207}\n",
      "Prediction for year 2019 of MGM is done.\n",
      "2019: {'model': SVR(), 'mse': 0.002040918885326312, 'rmse': 0.04517653024886165, 'mae': 0.012291086757957434, 'hit_rate': 0.9047619047619048}\n",
      "Prediction for year 2020 of MGM is done.\n",
      "2020: {'model': SVR(), 'mse': 0.0009925674074617128, 'rmse': 0.031505037810828175, 'mae': 0.015009465310698022, 'hit_rate': 0.9203187250996016}\n",
      "Prediction for year 2021 of MGM is done.\n",
      "2021: {'model': SVR(), 'mse': 1.3660792262167764e-05, 'rmse': 0.0036960509009167832, 'mae': 0.002283086522173731, 'hit_rate': 0.9761904761904762}\n",
      "Prediction for year 2022 of MGM is done.\n",
      "2022: {'model': SVR(), 'mse': 2.149239311580434e-05, 'rmse': 0.004635988903761995, 'mae': 0.0025504056037455084, 'hit_rate': 0.963855421686747}\n",
      "Execution time: 5.298928499221802 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "target_column = 'rt'\n",
    "\n",
    "# Initialize a dictionary to store the best models and their performance for each stock\n",
    "SVR_performance = {}\n",
    "SVR_stock_return={}\n",
    "# Loop over each stock\n",
    "for stock_name, windows in SP500_Train_Test_Dict.items():\n",
    "    stock_best_models = []\n",
    "    ret=[]\n",
    "    # Loop over each pair of training/testing set\n",
    "    years = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "    for year, (train_df, test_df) in zip(years, windows):\n",
    "        # Standardize the data\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        X_train_scaled = scaler_X.fit_transform(train_df.iloc[:, 7:].drop(columns=[target_column]))\n",
    "        y_train_scaled = scaler_y.fit_transform(train_df[[target_column]])\n",
    "        X_test_scaled = scaler_X.transform(test_df.iloc[:, 7:].drop(columns=[target_column]))\n",
    "        y_test_scaled = scaler_y.transform(test_df[[target_column]])\n",
    "\n",
    "        # Flatten y arrays\n",
    "        y_train_scaled = y_train_scaled.ravel()\n",
    "        y_test_scaled = y_test_scaled.ravel()\n",
    "\n",
    "        # Define and fit the SVR model\n",
    "        svr_model = SVR(C=1.0, epsilon=0.1)\n",
    "        svr_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred_scaled = svr_model.predict(X_test_scaled)\n",
    "\n",
    "        # Inverse tray_prensform predictions and actual values to original scale\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "        y_test = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "        ret.append(y_pred)\n",
    "\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Calculate Hit Rate\n",
    "        direction_pred = np.sign(np.diff(y_pred))\n",
    "        direction_true = np.sign(np.diff(y_test))\n",
    "        hit_rate = np.mean(direction_pred == direction_true)\n",
    "\n",
    "        # Store the best model and its performance metrics\n",
    "        stock_best_models.append({\n",
    "            'model': svr_model,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'hit_rate': hit_rate\n",
    "        })\n",
    "\n",
    "        print(f\"Prediction for year {year} of {stock_name} is done.\")\n",
    "        print(f\"{year}: {stock_best_models[-1]}\")\n",
    "\n",
    "    # Add the best models and their performance to the dictionary\n",
    "    SVR_performance[stock_name] = stock_best_models\n",
    "    SVR_stock_return[stock_name] = ret\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OX-JDpdHDlDG"
   },
   "source": [
    "<B>BPNN</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEhFU7CIDdyD",
    "outputId": "1983ab1c-8e4c-4617-b9f0-02a5f0df9f41",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of DPZ is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e408976f040>, 'mse': 4.4395554142293885e-06, 'rmse': 0.002107025252394804, 'mae': 0.0016082620500313068, 'hit_rate': 0.9437751004016064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of DPZ is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e4088930d00>, 'mse': 8.849936187826866e-06, 'rmse': 0.002974884230995698, 'mae': 0.002187514585218079, 'hit_rate': 0.9442231075697212}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of DPZ is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8cd4bf40>, 'mse': 2.3576343815534195e-05, 'rmse': 0.004855547735892851, 'mae': 0.002719349542973096, 'hit_rate': 0.9563492063492064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of DPZ is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8cec3dc0>, 'mse': 1.1470256101703526e-05, 'rmse': 0.0033867766536492374, 'mae': 0.00249495780102021, 'hit_rate': 0.9482071713147411}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of DPZ is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8cb073d0>, 'mse': 1.08266424405288e-05, 'rmse': 0.003290386366451332, 'mae': 0.00228055518939845, 'hit_rate': 0.9166666666666666}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of DPZ is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8ccacac0>, 'mse': 1.1467332121915079e-05, 'rmse': 0.0033863449502251064, 'mae': 0.002399932201367683, 'hit_rate': 0.9678714859437751}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of AVGO is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8ca26830>, 'mse': 1.0873937007104095e-05, 'rmse': 0.003297565315062629, 'mae': 0.0024537822711241867, 'hit_rate': 0.9357429718875502}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of AVGO is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8cad9e10>, 'mse': 1.6254863287416207e-05, 'rmse': 0.004031732045587381, 'mae': 0.002412857492200191, 'hit_rate': 0.9322709163346613}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of AVGO is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8c884df0>, 'mse': 3.314055424553425e-05, 'rmse': 0.005756783324525446, 'mae': 0.003522481601308129, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of AVGO is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8c956410>, 'mse': 2.000282645582365e-05, 'rmse': 0.004472451951203461, 'mae': 0.0033492558041861727, 'hit_rate': 0.9442231075697212}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of AVGO is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8c45b700>, 'mse': 1.595971225070782e-05, 'rmse': 0.003994960857218481, 'mae': 0.00283696171557162, 'hit_rate': 0.8968253968253969}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of AVGO is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8c495a20>, 'mse': 4.15819754201028e-05, 'rmse': 0.0064484087510100355, 'mae': 0.004691239823953065, 'hit_rate': 0.8955823293172691}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of TSLA is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8c2da950>, 'mse': 7.551094375900003e-06, 'rmse': 0.0027479254676755706, 'mae': 0.002102036700493752, 'hit_rate': 0.9518072289156626}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of TSLA is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8c14d2d0>, 'mse': 3.6017320332546476e-05, 'rmse': 0.006001443187479698, 'mae': 0.004195043932480423, 'hit_rate': 0.9442231075697212}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of TSLA is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c84760d60>, 'mse': 6.111148626021888e-05, 'rmse': 0.007817383594286445, 'mae': 0.005070781708859238, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of TSLA is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c846b3b20>, 'mse': 6.051200482933382e-05, 'rmse': 0.007778946254431497, 'mae': 0.005854386295561829, 'hit_rate': 0.9482071713147411}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of TSLA is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c84648ac0>, 'mse': 2.975800553961483e-05, 'rmse': 0.005455089874568047, 'mae': 0.004029457468511231, 'hit_rate': 0.9404761904761905}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of TSLA is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c84761000>, 'mse': 5.208063160208216e-05, 'rmse': 0.007216691181011015, 'mae': 0.0055150968924648856, 'hit_rate': 0.9317269076305221}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of NOW is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c84460c10>, 'mse': 6.752668540625127e-06, 'rmse': 0.0025985897214883934, 'mae': 0.0018825800855879252, 'hit_rate': 0.9357429718875502}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of NOW is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c843ab2b0>, 'mse': 1.42561300991228e-05, 'rmse': 0.003775729081796362, 'mae': 0.0026804604372745243, 'hit_rate': 0.9601593625498008}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of NOW is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c844cf7f0>, 'mse': 3.03478098187343e-05, 'rmse': 0.005508884625651031, 'mae': 0.003237980877954799, 'hit_rate': 0.9444444444444444}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of NOW is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c93ef5ba0>, 'mse': 2.1822617078693918e-05, 'rmse': 0.004671468407117179, 'mae': 0.0035179681395580698, 'hit_rate': 0.9482071713147411}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of NOW is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c93e0eb60>, 'mse': 2.006346660539457e-05, 'rmse': 0.004479226116796803, 'mae': 0.0031481097143971288, 'hit_rate': 0.9325396825396826}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of NOW is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c93c1b4c0>, 'mse': 2.8662172601181216e-05, 'rmse': 0.0053537064358424825, 'mae': 0.004179412498548217, 'hit_rate': 0.9477911646586346}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of DTE is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c93bca530>, 'mse': 1.6838932504496554e-06, 'rmse': 0.0012976491245516469, 'mae': 0.0010306898863048771, 'hit_rate': 0.9718875502008032}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of DTE is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c93aa3fd0>, 'mse': 3.543129562242617e-06, 'rmse': 0.001882320260275232, 'mae': 0.0012992503623135852, 'hit_rate': 0.9203187250996016}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of DTE is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c93be5ea0>, 'mse': 1.2923570527428982e-05, 'rmse': 0.003594936790463635, 'mae': 0.001682598904511269, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of DTE is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c939a11e0>, 'mse': 4.5311101267529674e-05, 'rmse': 0.006731352112876705, 'mae': 0.0045294051298554105, 'hit_rate': 0.9322709163346613}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of DTE is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c93988190>, 'mse': 4.599055477262188e-06, 'rmse': 0.0021445408546498217, 'mae': 0.0016496222703842232, 'hit_rate': 0.9285714285714286}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of DTE is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c84196bc0>, 'mse': 1.284730408757577e-05, 'rmse': 0.0035843136145677556, 'mae': 0.0028518063344354764, 'hit_rate': 0.9156626506024096}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of ADBE is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c84195e10>, 'mse': 4.1234276034401705e-06, 'rmse': 0.0020306224669889208, 'mae': 0.0014260707318779246, 'hit_rate': 0.963855421686747}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of ADBE is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e6640a0>, 'mse': 9.422412757967884e-06, 'rmse': 0.00306959488499181, 'mae': 0.002346810985897275, 'hit_rate': 0.9561752988047809}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of ADBE is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c842aee30>, 'mse': 1.6182336480666516e-05, 'rmse': 0.00402272749271766, 'mae': 0.0020456302747995396, 'hit_rate': 0.9761904761904762}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of ADBE is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e682a40>, 'mse': 2.2115761436315344e-05, 'rmse': 0.004702739779778947, 'mae': 0.0032898021385788594, 'hit_rate': 0.9681274900398407}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of ADBE is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e339f00>, 'mse': 5.409103905099982e-06, 'rmse': 0.0023257480313008936, 'mae': 0.0017348702337095542, 'hit_rate': 0.9761904761904762}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of ADBE is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e33a2c0>, 'mse': 1.2396018892788405e-05, 'rmse': 0.0035207980477142404, 'mae': 0.0025251708293560922, 'hit_rate': 0.9678714859437751}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of COO is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e3dad40>, 'mse': 4.820358350493499e-06, 'rmse': 0.002195531450581726, 'mae': 0.0016586775191736614, 'hit_rate': 0.9558232931726908}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of COO is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e01a0b0>, 'mse': 6.8700642168454095e-06, 'rmse': 0.0026210807345149463, 'mae': 0.0016726486757783316, 'hit_rate': 0.9442231075697212}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of COO is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e1e93c0>, 'mse': 1.4674018115628654e-05, 'rmse': 0.0038306681030374655, 'mae': 0.001811875784791565, 'hit_rate': 0.9365079365079365}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of COO is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e1214e0>, 'mse': 3.076415217722814e-05, 'rmse': 0.0055465441652643626, 'mae': 0.003989637114049129, 'hit_rate': 0.9362549800796812}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of COO is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91f01ff0>, 'mse': 1.064280485822518e-05, 'rmse': 0.003262331199958885, 'mae': 0.0023961529487108927, 'hit_rate': 0.9365079365079365}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of COO is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91ffbe20>, 'mse': 1.654021168100022e-05, 'rmse': 0.004066965906053334, 'mae': 0.002724486217441484, 'hit_rate': 0.963855421686747}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of DHI is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91ee1300>, 'mse': 6.82363644792112e-06, 'rmse': 0.0026122091125943803, 'mae': 0.001970326332080134, 'hit_rate': 0.9317269076305221}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of DHI is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91d024a0>, 'mse': 1.3532216219213236e-05, 'rmse': 0.0036786160739078542, 'mae': 0.0026280939930186055, 'hit_rate': 0.9442231075697212}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of DHI is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91cd2c80>, 'mse': 1.590100332262857e-05, 'rmse': 0.003987606214588969, 'mae': 0.0022173303133975557, 'hit_rate': 0.9404761904761905}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of DHI is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91bfb580>, 'mse': 3.8674437293381176e-05, 'rmse': 0.00621887749464332, 'mae': 0.00461697675536328, 'hit_rate': 0.9561752988047809}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of DHI is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91ad4370>, 'mse': 1.8621579966390376e-05, 'rmse': 0.004315272872761395, 'mae': 0.003235577318863026, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of DHI is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c9192d0c0>, 'mse': 2.1019365562221725e-05, 'rmse': 0.0045846881641199684, 'mae': 0.003605168197986881, 'hit_rate': 0.9477911646586346}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of ADSK is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91bdc670>, 'mse': 1.8236274923444202e-05, 'rmse': 0.004270395171813049, 'mae': 0.002776212483259108, 'hit_rate': 0.9116465863453815}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of ADSK is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7c626da0>, 'mse': 1.4525785224289975e-05, 'rmse': 0.0038112708148713304, 'mae': 0.0028503310529079035, 'hit_rate': 0.9760956175298805}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of ADSK is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7c570670>, 'mse': 2.6634495443053638e-05, 'rmse': 0.005160861889554267, 'mae': 0.003372152658732801, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of ADSK is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7c334b20>, 'mse': 3.481945925815103e-05, 'rmse': 0.005900801577595287, 'mae': 0.004311818384324011, 'hit_rate': 0.9402390438247012}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of ADSK is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7c463be0>, 'mse': 2.558821537839444e-05, 'rmse': 0.005058479552038779, 'mae': 0.0035277054352325773, 'hit_rate': 0.9603174603174603}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of ADSK is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7c676650>, 'mse': 1.7709323899427857e-05, 'rmse': 0.004208244752795143, 'mae': 0.0030315683350260443, 'hit_rate': 0.9759036144578314}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of TRV is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7c16d240>, 'mse': 2.7679688873935357e-06, 'rmse': 0.0016637213971676674, 'mae': 0.0011983982675951453, 'hit_rate': 0.9437751004016064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of TRV is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6c7eb550>, 'mse': 4.676380214507412e-06, 'rmse': 0.002162493980224549, 'mae': 0.0015746880945019552, 'hit_rate': 0.9243027888446215}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of TRV is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6c78fc10>, 'mse': 1.4851123267729078e-05, 'rmse': 0.003853715514633777, 'mae': 0.002051298783407908, 'hit_rate': 0.9404761904761905}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of TRV is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6c540ca0>, 'mse': 2.84240027346183e-05, 'rmse': 0.005331416578604442, 'mae': 0.0038627540433821155, 'hit_rate': 0.9362549800796812}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of TRV is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6c587ac0>, 'mse': 1.1085127706007664e-05, 'rmse': 0.003329433541311144, 'mae': 0.00244419527397516, 'hit_rate': 0.9246031746031746}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of TRV is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6c3d8d30>, 'mse': 9.951962478028609e-06, 'rmse': 0.0031546731174606044, 'mae': 0.0024054119072179354, 'hit_rate': 0.9156626506024096}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of AES is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6c3f1540>, 'mse': 1.112954843155583e-05, 'rmse': 0.0033360977850710296, 'mae': 0.0023610654009357966, 'hit_rate': 0.9236947791164659}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of AES is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c9054e620>, 'mse': 5.398219879089633e-06, 'rmse': 0.0023234069551177714, 'mae': 0.0017566142337929948, 'hit_rate': 0.9203187250996016}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of AES is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c906f08b0>, 'mse': 2.2271901771467202e-05, 'rmse': 0.0047193115781295055, 'mae': 0.0021168365302608365, 'hit_rate': 0.9444444444444444}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of AES is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c9046e020>, 'mse': 5.785856118601858e-05, 'rmse': 0.0076064815247273545, 'mae': 0.0054725563141410855, 'hit_rate': 0.9243027888446215}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of AES is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c905f0490>, 'mse': 1.1856000426783303e-05, 'rmse': 0.0034432543366390033, 'mae': 0.0026043949264833778, 'hit_rate': 0.9246031746031746}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of AES is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c905f0310>, 'mse': 1.92799200290155e-05, 'rmse': 0.004390890573564263, 'mae': 0.0032491816123857565, 'hit_rate': 0.9357429718875502}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of RF is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c9012b940>, 'mse': 4.411996774120079e-06, 'rmse': 0.0021004753686058968, 'mae': 0.001600139218478766, 'hit_rate': 0.9397590361445783}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of RF is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c90191e40>, 'mse': 6.910889966729608e-06, 'rmse': 0.0026288571598186176, 'mae': 0.001877697928271821, 'hit_rate': 0.9282868525896414}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of RF is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6c23a860>, 'mse': 1.727553969773678e-05, 'rmse': 0.004156385412559425, 'mae': 0.002398285465251613, 'hit_rate': 0.9642857142857143}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of RF is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c90192c50>, 'mse': 5.0389324230404896e-05, 'rmse': 0.00709854381055755, 'mae': 0.005161044383085865, 'hit_rate': 0.9482071713147411}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of RF is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c60743fa0>, 'mse': 2.0033092373663046e-05, 'rmse': 0.004475834265660766, 'mae': 0.003314296942820587, 'hit_rate': 0.9365079365079365}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of RF is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c606a06a0>, 'mse': 1.9009633692542142e-05, 'rmse': 0.004360003863821928, 'mae': 0.0029482967304620402, 'hit_rate': 0.9598393574297188}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of WMT is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c606d7dc0>, 'mse': 2.742835572374638e-06, 'rmse': 0.0016561508302007514, 'mae': 0.0011080547983813459, 'hit_rate': 0.9558232931726908}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of WMT is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c60461420>, 'mse': 5.44726568124267e-06, 'rmse': 0.0023339378057786095, 'mae': 0.0016691322307991743, 'hit_rate': 0.9203187250996016}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of WMT is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c60679f00>, 'mse': 8.747769689677156e-06, 'rmse': 0.0029576628762719315, 'mae': 0.001656669187057179, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of WMT is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c60443880>, 'mse': 1.3419449624184172e-05, 'rmse': 0.0036632566964634313, 'mae': 0.0027286207308463003, 'hit_rate': 0.9083665338645418}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of WMT is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6020d750>, 'mse': 3.7786300188249376e-06, 'rmse': 0.0019438698564525707, 'mae': 0.0014617451505591053, 'hit_rate': 0.9166666666666666}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of WMT is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c601375b0>, 'mse': 6.186135833180923e-06, 'rmse': 0.0024871943698032374, 'mae': 0.0017309876577165841, 'hit_rate': 0.963855421686747}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of LNT is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c60247bb0>, 'mse': 1.1787525817100138e-06, 'rmse': 0.0010857037264880387, 'mae': 0.0008130565750404983, 'hit_rate': 0.9558232931726908}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of LNT is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8ef20220>, 'mse': 3.959629811043546e-06, 'rmse': 0.0019898818585643587, 'mae': 0.0014900062353021442, 'hit_rate': 0.9322709163346613}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of LNT is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8ef6e6e0>, 'mse': 1.006765070908231e-05, 'rmse': 0.003172956146731674, 'mae': 0.0017378349925913758, 'hit_rate': 0.9404761904761905}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of LNT is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8efe50f0>, 'mse': 1.4487317317484741e-05, 'rmse': 0.0038062208708224935, 'mae': 0.002618677719655933, 'hit_rate': 0.9402390438247012}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of LNT is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8eed9b40>, 'mse': 3.7739163302116123e-06, 'rmse': 0.0019426570284565446, 'mae': 0.0015507920152876358, 'hit_rate': 0.9523809523809523}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of LNT is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8edc1780>, 'mse': 1.7390660466216875e-05, 'rmse': 0.004170211081733978, 'mae': 0.003108646870964602, 'hit_rate': 0.9036144578313253}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of COF is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8eed8190>, 'mse': 2.6185578106735427e-06, 'rmse': 0.0016181958505303191, 'mae': 0.001216081121890923, 'hit_rate': 0.9718875502008032}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of COF is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8ec8abc0>, 'mse': 1.2926403217476292e-05, 'rmse': 0.0035953307521668005, 'mae': 0.0026843435438007514, 'hit_rate': 0.9043824701195219}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of COF is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8eba9750>, 'mse': 8.130437664746453e-06, 'rmse': 0.0028513922327078143, 'mae': 0.001774564894374137, 'hit_rate': 0.9761904761904762}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of COF is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8e85ec50>, 'mse': 0.00019769692603708499, 'rmse': 0.014060473890914381, 'mae': 0.009312649494281752, 'hit_rate': 0.9243027888446215}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of COF is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c47d69b10>, 'mse': 1.344496203922086e-05, 'rmse': 0.003666737247093233, 'mae': 0.0027921684436658374, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of COF is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c47cbf520>, 'mse': 3.6179986949904513e-05, 'rmse': 0.006014980211929588, 'mae': 0.004544516685597596, 'hit_rate': 0.9236947791164659}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of EXR is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c47b41660>, 'mse': 3.9492126030117385e-06, 'rmse': 0.001987262590351798, 'mae': 0.0013792266292019662, 'hit_rate': 0.9317269076305221}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of EXR is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c47b737c0>, 'mse': 4.1014598389668735e-06, 'rmse': 0.0020252061225877415, 'mae': 0.0015908712168859545, 'hit_rate': 0.9402390438247012}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of EXR is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c47a70580>, 'mse': 9.205483064786232e-06, 'rmse': 0.0030340538994530456, 'mae': 0.0015791383978396784, 'hit_rate': 0.9603174603174603}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of EXR is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c4781a050>, 'mse': 2.4885834638844827e-05, 'rmse': 0.004988570400309574, 'mae': 0.003617503983410774, 'hit_rate': 0.9123505976095617}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of EXR is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c479234c0>, 'mse': 5.758354942139241e-06, 'rmse': 0.002399657255138584, 'mae': 0.0017265604201562178, 'hit_rate': 0.9563492063492064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of EXR is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c4471c490>, 'mse': 8.805286666031576e-06, 'rmse': 0.0029673703284274406, 'mae': 0.00219799761901681, 'hit_rate': 0.9437751004016064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of PCAR is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c44663820>, 'mse': 7.162453962564029e-06, 'rmse': 0.00267627613720334, 'mae': 0.00183415947112063, 'hit_rate': 0.9477911646586346}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of PCAR is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c44604940>, 'mse': 7.109264218758399e-06, 'rmse': 0.002666320351862919, 'mae': 0.0019385960981002182, 'hit_rate': 0.9561752988047809}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of PCAR is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c443de590>, 'mse': 8.291414053544944e-06, 'rmse': 0.002879481559854993, 'mae': 0.0019021342572489626, 'hit_rate': 0.9444444444444444}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of PCAR is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c44209420>, 'mse': 6.305907504844268e-06, 'rmse': 0.0025111566069929347, 'mae': 0.0018739870763710023, 'hit_rate': 0.9442231075697212}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of PCAR is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c442b3e80>, 'mse': 6.7487288006104276e-06, 'rmse': 0.0025978315573975206, 'mae': 0.001876966678454698, 'hit_rate': 0.9761904761904762}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of PCAR is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c441b5b40>, 'mse': 6.847056627107865e-06, 'rmse': 0.0026166881027565865, 'mae': 0.0020415551863033734, 'hit_rate': 0.9598393574297188}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of EIX is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c441b6890>, 'mse': 6.690279485774012e-06, 'rmse': 0.0025865574584327355, 'mae': 0.0013835814074712972, 'hit_rate': 0.9317269076305221}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of EIX is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c442fbd00>, 'mse': 2.1842602527991447e-05, 'rmse': 0.004673607014714806, 'mae': 0.0022338085135919145, 'hit_rate': 0.9083665338645418}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of EIX is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7ffc23e0>, 'mse': 3.4920269790079e-05, 'rmse': 0.005909337508560414, 'mae': 0.0032438567109332487, 'hit_rate': 0.8968253968253969}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of EIX is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c47a33e50>, 'mse': 1.6011277987863366e-05, 'rmse': 0.004001409500146588, 'mae': 0.0028194754286517947, 'hit_rate': 0.9322709163346613}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of EIX is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91987ca0>, 'mse': 3.4041408455059e-06, 'rmse': 0.0018450313941789447, 'mae': 0.0014247161079772913, 'hit_rate': 0.9285714285714286}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of EIX is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c938ae0e0>, 'mse': 7.371179483362928e-06, 'rmse': 0.0027149916175492933, 'mae': 0.0020108307385835007, 'hit_rate': 0.9437751004016064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of TMO is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca0b97be0>, 'mse': 2.0716782570134744e-06, 'rmse': 0.0014393325734566957, 'mae': 0.000967868131040376, 'hit_rate': 0.9558232931726908}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of TMO is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca09ec250>, 'mse': 4.498408050328358e-06, 'rmse': 0.0021209450842321113, 'mae': 0.0014687259446153345, 'hit_rate': 0.9601593625498008}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of TMO is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c9945e350>, 'mse': 1.3051170610909614e-05, 'rmse': 0.003612640393245585, 'mae': 0.002276429999174535, 'hit_rate': 0.9444444444444444}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of TMO is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca0ee8dc0>, 'mse': 1.5188339888984131e-05, 'rmse': 0.0038972220733471336, 'mae': 0.002948009617487667, 'hit_rate': 0.9163346613545816}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of TMO is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c99fbb130>, 'mse': 6.071319099962244e-06, 'rmse': 0.0024640046874878797, 'mae': 0.0018090136372346157, 'hit_rate': 0.9325396825396826}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of TMO is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca0222b90>, 'mse': 1.2205149956249916e-05, 'rmse': 0.0034935869756240385, 'mae': 0.002678647682177683, 'hit_rate': 0.9236947791164659}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of FE is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca6be2c80>, 'mse': 7.1911385779591625e-06, 'rmse': 0.00268162983611817, 'mae': 0.0017913275403063408, 'hit_rate': 0.9598393574297188}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of FE is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cac75ee60>, 'mse': 2.0494222005844695e-06, 'rmse': 0.0014315803157994558, 'mae': 0.0011254511218650775, 'hit_rate': 0.9442231075697212}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of FE is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca6c2c400>, 'mse': 9.317701051737262e-05, 'rmse': 0.009652823965937255, 'mae': 0.003538109710121883, 'hit_rate': 0.9404761904761905}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of FE is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca6e5c370>, 'mse': 1.3810680058564302e-05, 'rmse': 0.0037162723337457793, 'mae': 0.0022923614797483805, 'hit_rate': 0.9561752988047809}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of FE is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cb42e5c30>, 'mse': 1.8944939135592698e-05, 'rmse': 0.004352578446805146, 'mae': 0.0031847543055337816, 'hit_rate': 0.8690476190476191}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of FE is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cb6f650c0>, 'mse': 8.825397455686308e-06, 'rmse': 0.0029707570509360584, 'mae': 0.0022549183386270074, 'hit_rate': 0.9598393574297188}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of RSG is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cbcf15ab0>, 'mse': 3.1262385272955437e-06, 'rmse': 0.0017681172266836675, 'mae': 0.0012097760736147869, 'hit_rate': 0.9437751004016064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of RSG is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cbc687d60>, 'mse': 2.794870049936843e-06, 'rmse': 0.001671786484553827, 'mae': 0.001163314147969039, 'hit_rate': 0.9322709163346613}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of RSG is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cbc6b6470>, 'mse': 6.628936654276029e-06, 'rmse': 0.0025746721450072103, 'mae': 0.0013507002555994377, 'hit_rate': 0.9722222222222222}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of RSG is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cd00f5ff0>, 'mse': 9.919832215440223e-06, 'rmse': 0.0031495765136665952, 'mae': 0.002303418823037747, 'hit_rate': 0.9601593625498008}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of RSG is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cd37145e0>, 'mse': 5.416388226108376e-06, 'rmse': 0.0023273135212318035, 'mae': 0.0016793104452221836, 'hit_rate': 0.9404761904761905}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of RSG is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cd043eb90>, 'mse': 5.988265266386464e-06, 'rmse': 0.0024470932279720085, 'mae': 0.0018294437134289544, 'hit_rate': 0.9518072289156626}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of DOV is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3d08baf2b0>, 'mse': 3.0759182386941985e-06, 'rmse': 0.001753829592262087, 'mae': 0.001362267373962716, 'hit_rate': 0.9437751004016064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of DOV is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3d0a3878e0>, 'mse': 4.244948422773041e-06, 'rmse': 0.0020603272610857336, 'mae': 0.0013759111164156606, 'hit_rate': 0.9601593625498008}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of DOV is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ce380e9e0>, 'mse': 1.1262297319488858e-05, 'rmse': 0.0033559346417188847, 'mae': 0.0019356209784409028, 'hit_rate': 0.9563492063492064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of DOV is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cdc10e530>, 'mse': 3.169178434792363e-05, 'rmse': 0.005629545660879183, 'mae': 0.004194000893839671, 'hit_rate': 0.8924302788844621}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of DOV is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cdc10dbd0>, 'mse': 5.44277220038502e-06, 'rmse': 0.0023329749678007734, 'mae': 0.0017810825664734493, 'hit_rate': 0.9563492063492064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of DOV is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7ff000a0>, 'mse': 1.3351224891711571e-05, 'rmse': 0.0036539327979194652, 'mae': 0.0026562343805432783, 'hit_rate': 0.9156626506024096}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of AMT is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7ff00be0>, 'mse': 5.60310599803363e-06, 'rmse': 0.0023670880841307174, 'mae': 0.0016556886840432058, 'hit_rate': 0.9317269076305221}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of AMT is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c47b709d0>, 'mse': 2.5871163127299493e-06, 'rmse': 0.0016084515263849108, 'mae': 0.0011734998748941046, 'hit_rate': 0.9800796812749004}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of AMT is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c47b42380>, 'mse': 2.527555225136652e-05, 'rmse': 0.005027479711681243, 'mae': 0.002624932703970267, 'hit_rate': 0.9246031746031746}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of AMT is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6078a2f0>, 'mse': 1.6575499443587632e-05, 'rmse': 0.004071301934711749, 'mae': 0.003016074730289335, 'hit_rate': 0.9163346613545816}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of AMT is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c603383a0>, 'mse': 9.384237500886464e-06, 'rmse': 0.0030633702846516063, 'mae': 0.0023654277503790933, 'hit_rate': 0.9206349206349206}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of AMT is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c6c5260b0>, 'mse': 1.638575232504537e-05, 'rmse': 0.004047931857757165, 'mae': 0.0029592406214250105, 'hit_rate': 0.9236947791164659}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of VZ is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7c462260>, 'mse': 6.4182387155209665e-06, 'rmse': 0.0025334243062544747, 'mae': 0.0016726177302844576, 'hit_rate': 0.9317269076305221}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of VZ is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e111cf0>, 'mse': 3.3634000333777516e-06, 'rmse': 0.001833957478617689, 'mae': 0.0013297547864476447, 'hit_rate': 0.952191235059761}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of VZ is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7e6660e0>, 'mse': 8.220276238778194e-06, 'rmse': 0.0028671024116306335, 'mae': 0.0017701571836111916, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of VZ is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c91f012d0>, 'mse': 4.0163051738535585e-06, 'rmse': 0.0020040721478663285, 'mae': 0.0015533422857850472, 'hit_rate': 0.9362549800796812}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of VZ is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c93df8910>, 'mse': 2.5534231731943594e-06, 'rmse': 0.0015979434198977007, 'mae': 0.0012245479034058266, 'hit_rate': 0.9404761904761905}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of VZ is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c84539cc0>, 'mse': 6.237938102771788e-06, 'rmse': 0.0024975864555149612, 'mae': 0.0018035135583520994, 'hit_rate': 0.9236947791164659}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of NUE is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8cba1b70>, 'mse': 7.44169495586279e-06, 'rmse': 0.0027279470221877092, 'mae': 0.002153625262442038, 'hit_rate': 0.9558232931726908}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of NUE is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c8c47a560>, 'mse': 6.153493445791667e-06, 'rmse': 0.0024806236001843705, 'mae': 0.0019905015715175746, 'hit_rate': 0.9601593625498008}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of NUE is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c99766860>, 'mse': 1.6735187997349643e-05, 'rmse': 0.004090866411574649, 'mae': 0.0023932418237550056, 'hit_rate': 0.9642857142857143}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of NUE is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ca3f31a80>, 'mse': 2.3738877968818736e-05, 'rmse': 0.004872255942458148, 'mae': 0.0036638437869945155, 'hit_rate': 0.9322709163346613}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of NUE is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cb575d2a0>, 'mse': 2.939728384086371e-05, 'rmse': 0.005421926211307538, 'mae': 0.004278136773907578, 'hit_rate': 0.9563492063492064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of NUE is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cb68cd300>, 'mse': 3.560645006903445e-05, 'rmse': 0.00596711404860293, 'mae': 0.0046058760591837925, 'hit_rate': 0.9196787148594378}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of OKE is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cbe750190>, 'mse': 4.924124421222244e-06, 'rmse': 0.0022190368228630734, 'mae': 0.001743078757857841, 'hit_rate': 0.9397590361445783}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of OKE is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3d08c76800>, 'mse': 1.0012099231325873e-05, 'rmse': 0.0031641901383017224, 'mae': 0.0024267273953089493, 'hit_rate': 0.9083665338645418}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of OKE is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cbff0ab00>, 'mse': 6.365819952212168e-05, 'rmse': 0.00797860887135857, 'mae': 0.003358105558793511, 'hit_rate': 0.9404761904761905}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of OKE is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3cd303c190>, 'mse': 0.00031190078809365955, 'rmse': 0.017660713125286293, 'mae': 0.011764438295587522, 'hit_rate': 0.9123505976095617}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of OKE is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3ce988bb20>, 'mse': 3.369093134461773e-05, 'rmse': 0.005804388972546355, 'mae': 0.004501932810730081, 'hit_rate': 0.9126984126984127}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of OKE is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c38661210>, 'mse': 1.8384166490044033e-05, 'rmse': 0.00428767611767074, 'mae': 0.003227723129796978, 'hit_rate': 0.9236947791164659}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of WAB is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c3864fa00>, 'mse': 3.6052114941144903e-06, 'rmse': 0.001898739448717093, 'mae': 0.0013987799479133365, 'hit_rate': 0.963855421686747}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of WAB is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c3843ad40>, 'mse': 2.3724492517988895e-05, 'rmse': 0.004870779456923593, 'mae': 0.003297830400918479, 'hit_rate': 0.9601593625498008}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of WAB is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c38335270>, 'mse': 4.01132495064679e-05, 'rmse': 0.006333502151769422, 'mae': 0.0035606490557076164, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of WAB is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c38125210>, 'mse': 2.873621375978122e-05, 'rmse': 0.005360616919700681, 'mae': 0.003873513784939381, 'hit_rate': 0.9163346613545816}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of WAB is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c206fb850>, 'mse': 6.7461206386114665e-06, 'rmse': 0.002597329520606014, 'mae': 0.0020077620348251998, 'hit_rate': 0.9444444444444444}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of WAB is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c2071ae90>, 'mse': 1.2007691996868026e-05, 'rmse': 0.003465211681393797, 'mae': 0.002676495710637749, 'hit_rate': 0.9236947791164659}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of BIIB is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c206bc3a0>, 'mse': 4.21696641323713e-06, 'rmse': 0.0020535253622093715, 'mae': 0.0016353229481681345, 'hit_rate': 0.9678714859437751}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of BIIB is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c203f3070>, 'mse': 1.4123995705979243e-05, 'rmse': 0.0037581904829291505, 'mae': 0.002448721602311931, 'hit_rate': 0.9322709163346613}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of BIIB is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c205eeaa0>, 'mse': 5.224054479959618e-05, 'rmse': 0.007227762087921557, 'mae': 0.0043031254566362285, 'hit_rate': 0.9087301587301587}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of BIIB is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c202fc850>, 'mse': 2.41558759648057e-05, 'rmse': 0.004914862761543368, 'mae': 0.003052500305882393, 'hit_rate': 0.9402390438247012}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of BIIB is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c203a2ce0>, 'mse': 4.430141072830332e-05, 'rmse': 0.006655930493049286, 'mae': 0.0043581262478465084, 'hit_rate': 0.9285714285714286}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of BIIB is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c2058b010>, 'mse': 8.80857688585271e-05, 'rmse': 0.009385401901811509, 'mae': 0.0048168303446875175, 'hit_rate': 0.9076305220883534}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of NTRS is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7cef41f0>, 'mse': 4.438507004751349e-06, 'rmse': 0.0021067764486891695, 'mae': 0.0015455062653661677, 'hit_rate': 0.9518072289156626}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of NTRS is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7ced8e80>, 'mse': 7.375530777592986e-06, 'rmse': 0.002715792845117791, 'mae': 0.001795872255567575, 'hit_rate': 0.9482071713147411}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of NTRS is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7cdce1a0>, 'mse': 2.6852065844373126e-05, 'rmse': 0.005181897899840668, 'mae': 0.0028658774449399588, 'hit_rate': 0.9761904761904762}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of NTRS is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7ccbe350>, 'mse': 2.9604297919878664e-05, 'rmse': 0.005440983175849625, 'mae': 0.00397167929786226, 'hit_rate': 0.9322709163346613}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of NTRS is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7cae61a0>, 'mse': 1.1126087098790951e-05, 'rmse': 0.0033355789750493018, 'mae': 0.0025943577826860217, 'hit_rate': 0.9523809523809523}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of NTRS is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7c8bf2e0>, 'mse': 1.3534103239057078e-05, 'rmse': 0.003678872549988254, 'mae': 0.0028091957317056284, 'hit_rate': 0.9477911646586346}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2017 of MGM is done.\n",
      "2017: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c7cb77c10>, 'mse': 9.078571745252298e-06, 'rmse': 0.003013066833850902, 'mae': 0.0022204057265213352, 'hit_rate': 0.9156626506024096}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2018 of MGM is done.\n",
      "2018: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c200f5150>, 'mse': 1.6099219438246274e-05, 'rmse': 0.004012383261634695, 'mae': 0.003148159312986481, 'hit_rate': 0.9362549800796812}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2019 of MGM is done.\n",
      "2019: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c14784100>, 'mse': 6.356629018088108e-05, 'rmse': 0.007972847056157611, 'mae': 0.0033566999879766327, 'hit_rate': 0.9484126984126984}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2020 of MGM is done.\n",
      "2020: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c14533430>, 'mse': 0.00016805764343760302, 'rmse': 0.012963704849988024, 'mae': 0.009216121005946324, 'hit_rate': 0.900398406374502}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2021 of MGM is done.\n",
      "2021: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c1465c280>, 'mse': 1.7105244899950464e-05, 'rmse': 0.004135848752064135, 'mae': 0.003105842383761302, 'hit_rate': 0.9563492063492064}\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Prediction for year 2022 of MGM is done.\n",
      "2022: {'model': <keras.src.engine.sequential.Sequential object at 0x7e3c14670100>, 'mse': 3.086938115841142e-05, 'rmse': 0.005556022062448224, 'mae': 0.0041691511442089645, 'hit_rate': 0.9397590361445783}\n",
      "Execution time: 760.4297070503235 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "target_column = 'rt'\n",
    "\n",
    "# Initialize a dictionary to store the best models and their performance for each stock\n",
    "BPNN_performance = {}\n",
    "BPNN_stock_return = {}\n",
    "\n",
    "# Loop over each stock\n",
    "for stock_name, windows in SP500_Train_Test_Dict.items():\n",
    "    stock_best_models = []\n",
    "    ret = []\n",
    "\n",
    "    # Loop over each pair of training/testing set\n",
    "    years = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "    for year, (train_df, test_df) in zip(years, windows):\n",
    "        # Standardize the data\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        X_train_scaled = scaler_X.fit_transform(train_df.iloc[:, 7:].drop(columns=[target_column]))\n",
    "        y_train_scaled = scaler_y.fit_transform(train_df[[target_column]])\n",
    "        X_test_scaled = scaler_X.transform(test_df.iloc[:, 7:].drop(columns=[target_column]))\n",
    "        y_test_scaled = scaler_y.transform(test_df[[target_column]])\n",
    "\n",
    "        # Flatten y arrays\n",
    "        y_train_scaled = y_train_scaled.ravel()\n",
    "        y_test_scaled = y_test_scaled.ravel()\n",
    "\n",
    "        # Define and fit the BPNN model\n",
    "        bpnn_model = Sequential()\n",
    "        bpnn_model.add(Dense(10, input_dim=X_train_scaled.shape[1], activation='relu'))  # Adjust number of neurons\n",
    "        bpnn_model.add(Dense(1, activation='linear'))\n",
    "        bpnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        bpnn_model.fit(X_train_scaled, y_train_scaled, epochs=64, batch_size=32, verbose=0)  # Adjust epochs and batch_size\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred_scaled = bpnn_model.predict(X_test_scaled)\n",
    "\n",
    "        # Inverse transform predictions and actual values to original scale\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()\n",
    "        y_test = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "        ret.append(y_pred)\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Calculate Hit Rate\n",
    "        direction_pred = np.sign(np.diff(y_pred))\n",
    "        direction_true = np.sign(np.diff(y_test))\n",
    "        hit_rate = np.mean(direction_pred == direction_true)\n",
    "\n",
    "        # Store the best model and its performance metrics\n",
    "        stock_best_models.append({\n",
    "            'model': bpnn_model,\n",
    "            'mse': mse,\n",
    "\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'hit_rate': hit_rate\n",
    "        })\n",
    "\n",
    "        print(f\"Prediction for year {year} of {stock_name} is done.\")\n",
    "        print(f\"{year}: {stock_best_models[-1]}\")\n",
    "\n",
    "    # Add the best models and their performance to the dictionary\n",
    "    BPNN_performance[stock_name] = stock_best_models\n",
    "    BPNN_stock_return[stock_name] = ret\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMkD2zunDtLs"
   },
   "source": [
    "<B>ELM</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYxfQ5U0Dzs3",
    "outputId": "5ad5f564-118f-4a91-f6f1-f93895422faa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for year 2017 of DPZ is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c8c613190>, 'mse': 5.7437707462033474e-05, 'rmse': 0.007578766882681738, 'mae': 0.005060643339638788, 'hit_rate': 0.8955823293172691}\n",
      "Prediction for year 2018 of DPZ is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c143700a0>, 'mse': 6.057240383136127e-05, 'rmse': 0.007782827495927252, 'mae': 0.00566455529943028, 'hit_rate': 0.900398406374502}\n",
      "Prediction for year 2019 of DPZ is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c2058bee0>, 'mse': 0.0002917082799620373, 'rmse': 0.017079469545686638, 'mae': 0.007664486153867865, 'hit_rate': 0.9087301587301587}\n",
      "Prediction for year 2020 of DPZ is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14371180>, 'mse': 3.633888695466245e-05, 'rmse': 0.006028174429681216, 'mae': 0.004580464987555042, 'hit_rate': 0.8844621513944223}\n",
      "Prediction for year 2021 of DPZ is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c143380a0>, 'mse': 8.394740971980686e-05, 'rmse': 0.009162281905715783, 'mae': 0.005263002570968199, 'hit_rate': 0.8571428571428571}\n",
      "Prediction for year 2022 of DPZ is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c143386d0>, 'mse': 7.13424198785587e-05, 'rmse': 0.008446444215085938, 'mae': 0.006474198599861177, 'hit_rate': 0.9036144578313253}\n",
      "Prediction for year 2017 of AVGO is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c1424ad10>, 'mse': 4.703753752781145e-05, 'rmse': 0.006858391759575378, 'mae': 0.004952541677356317, 'hit_rate': 0.8714859437751004}\n",
      "Prediction for year 2018 of AVGO is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c1424b250>, 'mse': 9.045015412405219e-05, 'rmse': 0.009510528593303959, 'mae': 0.005317249004166503, 'hit_rate': 0.9203187250996016}\n",
      "Prediction for year 2019 of AVGO is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c1424b2e0>, 'mse': 0.00045912224750141575, 'rmse': 0.021427138108049235, 'mae': 0.008631113676337173, 'hit_rate': 0.9682539682539683}\n",
      "Prediction for year 2020 of AVGO is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c1424abc0>, 'mse': 0.00010442238090512658, 'rmse': 0.010218726970867094, 'mae': 0.007711906416244033, 'hit_rate': 0.8725099601593626}\n",
      "Prediction for year 2021 of AVGO is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c1424ae90>, 'mse': 6.518864670282391e-05, 'rmse': 0.008073948643806443, 'mae': 0.005914238054575488, 'hit_rate': 0.8888888888888888}\n",
      "Prediction for year 2022 of AVGO is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c1424af50>, 'mse': 0.00010310136999419885, 'rmse': 0.01015388447808024, 'mae': 0.007866042460734647, 'hit_rate': 0.8714859437751004}\n",
      "Prediction for year 2017 of TSLA is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c143cf340>, 'mse': 8.103120146481311e-05, 'rmse': 0.009001733247814728, 'mae': 0.006342826277798145, 'hit_rate': 0.9076305220883534}\n",
      "Prediction for year 2018 of TSLA is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c1424b100>, 'mse': 0.0003021723121184648, 'rmse': 0.017383104214105854, 'mae': 0.009971317061773148, 'hit_rate': 0.896414342629482}\n",
      "Prediction for year 2019 of TSLA is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c1424ab00>, 'mse': 0.0006601119826095262, 'rmse': 0.025692644523472592, 'mae': 0.01294703680559381, 'hit_rate': 0.9206349206349206}\n",
      "Prediction for year 2020 of TSLA is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c1424a9b0>, 'mse': 0.00045066192251305936, 'rmse': 0.0212287993657922, 'mae': 0.01494339419887781, 'hit_rate': 0.896414342629482}\n",
      "Prediction for year 2021 of TSLA is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c1424af20>, 'mse': 0.0001916521430114161, 'rmse': 0.013843848562138206, 'mae': 0.010344771171543256, 'hit_rate': 0.8888888888888888}\n",
      "Prediction for year 2022 of TSLA is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c143cfee0>, 'mse': 0.00023896891782864007, 'rmse': 0.015458619531790025, 'mae': 0.011976619594828689, 'hit_rate': 0.8875502008032129}\n",
      "Prediction for year 2017 of NOW is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c1424acb0>, 'mse': 4.417722075783789e-05, 'rmse': 0.006646594673803864, 'mae': 0.004900369411268602, 'hit_rate': 0.9076305220883534}\n",
      "Prediction for year 2018 of NOW is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c1424ace0>, 'mse': 0.00013221239333842548, 'rmse': 0.011498364811503655, 'mae': 0.008153459995458918, 'hit_rate': 0.896414342629482}\n",
      "Prediction for year 2019 of NOW is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c1424ada0>, 'mse': 0.0001581170923627237, 'rmse': 0.012574461911458624, 'mae': 0.007277033850842922, 'hit_rate': 0.9047619047619048}\n",
      "Prediction for year 2020 of NOW is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c1424a7d0>, 'mse': 0.00010246747070578188, 'rmse': 0.010122621730845318, 'mae': 0.007648046376305442, 'hit_rate': 0.8605577689243028}\n",
      "Prediction for year 2021 of NOW is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c1424b0d0>, 'mse': 0.00010797146996194652, 'rmse': 0.010390932102653088, 'mae': 0.006645317637155274, 'hit_rate': 0.9404761904761905}\n",
      "Prediction for year 2022 of NOW is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c1424aa10>, 'mse': 0.00013956901313367322, 'rmse': 0.011813933008683993, 'mae': 0.007953007491038057, 'hit_rate': 0.891566265060241}\n",
      "Prediction for year 2017 of DTE is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c1424ab30>, 'mse': 8.009086804172202e-06, 'rmse': 0.002830033004078257, 'mae': 0.002059081030666493, 'hit_rate': 0.9076305220883534}\n",
      "Prediction for year 2018 of DTE is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c1424a920>, 'mse': 1.4063933307220666e-05, 'rmse': 0.0037501911027600534, 'mae': 0.0024001842556285926, 'hit_rate': 0.900398406374502}\n",
      "Prediction for year 2019 of DTE is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c1424b130>, 'mse': 0.00043262096199058223, 'rmse': 0.020799542350508154, 'mae': 0.007267361514744802, 'hit_rate': 0.9365079365079365}\n",
      "Prediction for year 2020 of DTE is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c143cdcf0>, 'mse': 0.0001490392860170986, 'rmse': 0.012208164727636117, 'mae': 0.008971677034823782, 'hit_rate': 0.8605577689243028}\n",
      "Prediction for year 2021 of DTE is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c1424ac80>, 'mse': 3.960839906055162e-05, 'rmse': 0.006293520402807289, 'mae': 0.004861514707403963, 'hit_rate': 0.8412698412698413}\n",
      "Prediction for year 2022 of DTE is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c1424b0a0>, 'mse': 6.708606358989286e-05, 'rmse': 0.008190608255184278, 'mae': 0.006132483791626816, 'hit_rate': 0.891566265060241}\n",
      "Prediction for year 2017 of ADBE is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c1424a590>, 'mse': 6.177276558519095e-05, 'rmse': 0.007859565228763672, 'mae': 0.004328196952168629, 'hit_rate': 0.9357429718875502}\n",
      "Prediction for year 2018 of ADBE is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c1424aec0>, 'mse': 0.00010770676623924419, 'rmse': 0.01037818704009733, 'mae': 0.006489596132594839, 'hit_rate': 0.900398406374502}\n",
      "Prediction for year 2019 of ADBE is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c1424a740>, 'mse': 0.00021447769669260972, 'rmse': 0.014645057073723192, 'mae': 0.007113461935070054, 'hit_rate': 0.8968253968253969}\n",
      "Prediction for year 2020 of ADBE is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c1424abf0>, 'mse': 7.72421549280269e-05, 'rmse': 0.008788751613740537, 'mae': 0.006729633701091849, 'hit_rate': 0.9083665338645418}\n",
      "Prediction for year 2021 of ADBE is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c1424a410>, 'mse': 9.717341510593338e-05, 'rmse': 0.009857657688616165, 'mae': 0.006244631166120193, 'hit_rate': 0.9087301587301587}\n",
      "Prediction for year 2022 of ADBE is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c1424ae60>, 'mse': 0.00016940807352776972, 'rmse': 0.013015685672594039, 'mae': 0.008814307321975788, 'hit_rate': 0.9116465863453815}\n",
      "Prediction for year 2017 of COO is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c1424a890>, 'mse': 3.091409609054105e-05, 'rmse': 0.005560044612279748, 'mae': 0.003695492122789793, 'hit_rate': 0.891566265060241}\n",
      "Prediction for year 2018 of COO is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c1424a3e0>, 'mse': 6.984041995177521e-05, 'rmse': 0.008357058091922972, 'mae': 0.004215370673336438, 'hit_rate': 0.9362549800796812}\n",
      "Prediction for year 2019 of COO is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c1424b010>, 'mse': 0.0002050559451077085, 'rmse': 0.014319774617908919, 'mae': 0.006339928481392319, 'hit_rate': 0.9206349206349206}\n",
      "Prediction for year 2020 of COO is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c1424a4d0>, 'mse': 9.018454758734866e-05, 'rmse': 0.009496554511366145, 'mae': 0.006907856526099803, 'hit_rate': 0.8645418326693227}\n",
      "Prediction for year 2021 of COO is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c1424a5f0>, 'mse': 6.231413962311281e-05, 'rmse': 0.007893930556010283, 'mae': 0.005618491805886254, 'hit_rate': 0.8968253968253969}\n",
      "Prediction for year 2022 of COO is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c1424a470>, 'mse': 7.903318482756571e-05, 'rmse': 0.008890061013714456, 'mae': 0.006508758038860879, 'hit_rate': 0.8674698795180723}\n",
      "Prediction for year 2017 of DHI is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c1424b190>, 'mse': 1.8607372989839254e-05, 'rmse': 0.004313626431419306, 'mae': 0.003430319037154351, 'hit_rate': 0.9317269076305221}\n",
      "Prediction for year 2018 of DHI is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c1424a770>, 'mse': 8.256816130083278e-05, 'rmse': 0.00908670244372692, 'mae': 0.005326333948955092, 'hit_rate': 0.9163346613545816}\n",
      "Prediction for year 2019 of DHI is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14232890>, 'mse': 0.0004023207119980252, 'rmse': 0.02005793389155586, 'mae': 0.007272142769858363, 'hit_rate': 0.9126984126984127}\n",
      "Prediction for year 2020 of DHI is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14232980>, 'mse': 0.0002187333231095007, 'rmse': 0.014789635665204897, 'mae': 0.010202494967072104, 'hit_rate': 0.8565737051792829}\n",
      "Prediction for year 2021 of DHI is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14233df0>, 'mse': 8.954560700597921e-05, 'rmse': 0.009462854062384098, 'mae': 0.007226808870716526, 'hit_rate': 0.8690476190476191}\n",
      "Prediction for year 2022 of DHI is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14232950>, 'mse': 9.518800880843197e-05, 'rmse': 0.009756434226111093, 'mae': 0.007846593940386278, 'hit_rate': 0.9076305220883534}\n",
      "Prediction for year 2017 of ADSK is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c142335b0>, 'mse': 0.00014200839874599382, 'rmse': 0.01191672768615587, 'mae': 0.0055514022418682385, 'hit_rate': 0.9076305220883534}\n",
      "Prediction for year 2018 of ADSK is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c1424b070>, 'mse': 9.555841791970966e-05, 'rmse': 0.00977539860669168, 'mae': 0.0065516067472601355, 'hit_rate': 0.9163346613545816}\n",
      "Prediction for year 2019 of ADSK is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c1424a8c0>, 'mse': 0.00027699513669836155, 'rmse': 0.016643170872714177, 'mae': 0.009318152318313731, 'hit_rate': 0.9126984126984127}\n",
      "Prediction for year 2020 of ADSK is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c1424a710>, 'mse': 0.00010362176736315008, 'rmse': 0.010179477754931736, 'mae': 0.00787625163686023, 'hit_rate': 0.8884462151394422}\n",
      "Prediction for year 2021 of ADSK is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14232830>, 'mse': 9.232452460978956e-05, 'rmse': 0.009608565169149322, 'mae': 0.005740042057172194, 'hit_rate': 0.9484126984126984}\n",
      "Prediction for year 2022 of ADSK is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14233d30>, 'mse': 0.0001286345522486481, 'rmse': 0.01134171734124282, 'mae': 0.008378555100220071, 'hit_rate': 0.9116465863453815}\n",
      "Prediction for year 2017 of TRV is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14232800>, 'mse': 2.828519196360567e-05, 'rmse': 0.005318382457440013, 'mae': 0.003131571825394536, 'hit_rate': 0.8835341365461847}\n",
      "Prediction for year 2018 of TRV is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c142327d0>, 'mse': 2.21097584327247e-05, 'rmse': 0.004702101491112745, 'mae': 0.0034259539066985047, 'hit_rate': 0.8804780876494024}\n",
      "Prediction for year 2019 of TRV is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14232740>, 'mse': 0.00043792061808929704, 'rmse': 0.02092655294331336, 'mae': 0.007386241665403002, 'hit_rate': 0.9087301587301587}\n",
      "Prediction for year 2020 of TRV is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c142327a0>, 'mse': 0.00021146557493632466, 'rmse': 0.014541855966014951, 'mae': 0.011148810116498207, 'hit_rate': 0.8366533864541833}\n",
      "Prediction for year 2021 of TRV is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c1424aa70>, 'mse': 4.817282592475285e-05, 'rmse': 0.006940664660157041, 'mae': 0.005353029218170321, 'hit_rate': 0.8809523809523809}\n",
      "Prediction for year 2022 of TRV is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c142335e0>, 'mse': 7.507334180272546e-05, 'rmse': 0.008664487394111983, 'mae': 0.006871977271636906, 'hit_rate': 0.8795180722891566}\n",
      "Prediction for year 2017 of AES is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c142323e0>, 'mse': 4.044824177036794e-05, 'rmse': 0.006359893220044496, 'mae': 0.0038827448733593914, 'hit_rate': 0.9236947791164659}\n",
      "Prediction for year 2018 of AES is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14232680>, 'mse': 3.0111827560221726e-05, 'rmse': 0.00548742449243921, 'mae': 0.00390716133250017, 'hit_rate': 0.9163346613545816}\n",
      "Prediction for year 2019 of AES is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c142300a0>, 'mse': 0.0004971718085125265, 'rmse': 0.022297349809170742, 'mae': 0.00805733093459224, 'hit_rate': 0.9087301587301587}\n",
      "Prediction for year 2020 of AES is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c142329b0>, 'mse': 0.0003904843359395148, 'rmse': 0.019760676505107683, 'mae': 0.013733404563024115, 'hit_rate': 0.7689243027888446}\n",
      "Prediction for year 2021 of AES is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c142336d0>, 'mse': 9.924392183756438e-05, 'rmse': 0.009962124363686913, 'mae': 0.007218597014321711, 'hit_rate': 0.8333333333333334}\n",
      "Prediction for year 2022 of AES is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14232620>, 'mse': 0.00015597985890497472, 'rmse': 0.012489189681679702, 'mae': 0.008979955462864992, 'hit_rate': 0.8433734939759037}\n",
      "Prediction for year 2017 of RF is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c1424a7a0>, 'mse': 2.086173210844382e-05, 'rmse': 0.004567464516385849, 'mae': 0.0034496438558125615, 'hit_rate': 0.9196787148594378}\n",
      "Prediction for year 2018 of RF is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c142322f0>, 'mse': 4.272018043457685e-05, 'rmse': 0.0065360676583536715, 'mae': 0.004589311648429081, 'hit_rate': 0.9203187250996016}\n",
      "Prediction for year 2019 of RF is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c142320b0>, 'mse': 0.0005561896173629972, 'rmse': 0.023583672686055435, 'mae': 0.008803707470400027, 'hit_rate': 0.9325396825396826}\n",
      "Prediction for year 2020 of RF is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c142320e0>, 'mse': 0.0003351116882286343, 'rmse': 0.018306056053356612, 'mae': 0.012801191423018436, 'hit_rate': 0.852589641434263}\n",
      "Prediction for year 2021 of RF is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c142321a0>, 'mse': 0.00010472698575064927, 'rmse': 0.010233620363813057, 'mae': 0.007987285938914023, 'hit_rate': 0.8888888888888888}\n",
      "Prediction for year 2022 of RF is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14232260>, 'mse': 0.000167291594361421, 'rmse': 0.012934125187326007, 'mae': 0.00877546540029448, 'hit_rate': 0.8835341365461847}\n",
      "Prediction for year 2017 of WMT is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14231f30>, 'mse': 6.86913170159808e-05, 'rmse': 0.00828802250334667, 'mae': 0.003731869607759018, 'hit_rate': 0.9116465863453815}\n",
      "Prediction for year 2018 of WMT is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14233700>, 'mse': 3.490789228369773e-05, 'rmse': 0.005908290131983849, 'mae': 0.004123058526205127, 'hit_rate': 0.900398406374502}\n",
      "Prediction for year 2019 of WMT is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14233790>, 'mse': 0.00010929460408590197, 'rmse': 0.010454405965233126, 'mae': 0.0051554126205626384, 'hit_rate': 0.9206349206349206}\n",
      "Prediction for year 2020 of WMT is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14231ed0>, 'mse': 5.267807624997854e-05, 'rmse': 0.007257966399066514, 'mae': 0.005113802218391301, 'hit_rate': 0.8605577689243028}\n",
      "Prediction for year 2021 of WMT is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14231e70>, 'mse': 1.563883054991429e-05, 'rmse': 0.003954596129810766, 'mae': 0.003099725332902154, 'hit_rate': 0.8968253968253969}\n",
      "Prediction for year 2022 of WMT is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14231d80>, 'mse': 8.690102202733239e-05, 'rmse': 0.009322071766905273, 'mae': 0.0052285055809126015, 'hit_rate': 0.8875502008032129}\n",
      "Prediction for year 2017 of LNT is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14231db0>, 'mse': 1.0250882364793878e-05, 'rmse': 0.0032016999179801152, 'mae': 0.002445272305267033, 'hit_rate': 0.9156626506024096}\n",
      "Prediction for year 2018 of LNT is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14231e40>, 'mse': 1.2804245239428025e-05, 'rmse': 0.003578302005061622, 'mae': 0.0025993962923719386, 'hit_rate': 0.9362549800796812}\n",
      "Prediction for year 2019 of LNT is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c142326e0>, 'mse': 0.00024332172056739819, 'rmse': 0.015598773046858467, 'mae': 0.0060678210215337645, 'hit_rate': 0.9404761904761905}\n",
      "Prediction for year 2020 of LNT is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14232350>, 'mse': 0.00011325211143904304, 'rmse': 0.010641997530494125, 'mae': 0.007966847463926431, 'hit_rate': 0.852589641434263}\n",
      "Prediction for year 2021 of LNT is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14231c30>, 'mse': 2.6005366181146832e-05, 'rmse': 0.005099545683798394, 'mae': 0.0041229815019571256, 'hit_rate': 0.9087301587301587}\n",
      "Prediction for year 2022 of LNT is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14232aa0>, 'mse': 4.002878484832959e-05, 'rmse': 0.006326830553154524, 'mae': 0.004806451828575829, 'hit_rate': 0.891566265060241}\n",
      "Prediction for year 2017 of COF is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14231a20>, 'mse': 3.8906720038623394e-05, 'rmse': 0.006237525153345948, 'mae': 0.004236056981148687, 'hit_rate': 0.8795180722891566}\n",
      "Prediction for year 2018 of COF is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14232050>, 'mse': 3.880495093976094e-05, 'rmse': 0.006229362001020726, 'mae': 0.00450670736714613, 'hit_rate': 0.896414342629482}\n",
      "Prediction for year 2019 of COF is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14233640>, 'mse': 0.0007147372457439238, 'rmse': 0.02673457023675383, 'mae': 0.009336927945005659, 'hit_rate': 0.9285714285714286}\n",
      "Prediction for year 2020 of COF is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14231870>, 'mse': 0.00045515604526444976, 'rmse': 0.021334386451558662, 'mae': 0.015166376730917426, 'hit_rate': 0.8087649402390438}\n",
      "Prediction for year 2021 of COF is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14232590>, 'mse': 0.00011759724262587541, 'rmse': 0.01084422623453953, 'mae': 0.008220071015585176, 'hit_rate': 0.8888888888888888}\n",
      "Prediction for year 2022 of COF is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14231cf0>, 'mse': 0.0001591270079089068, 'rmse': 0.01261455539878068, 'mae': 0.00993800555177705, 'hit_rate': 0.8473895582329317}\n",
      "Prediction for year 2017 of EXR is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14231780>, 'mse': 1.6454054652666895e-05, 'rmse': 0.004056359778504231, 'mae': 0.0028395319646562084, 'hit_rate': 0.9036144578313253}\n",
      "Prediction for year 2018 of EXR is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14231c00>, 'mse': 1.1478086011689434e-05, 'rmse': 0.0033879324095515, 'mae': 0.0025110140748451594, 'hit_rate': 0.9442231075697212}\n",
      "Prediction for year 2019 of EXR is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14231b70>, 'mse': 0.00022418461840245364, 'rmse': 0.014972795944727679, 'mae': 0.0053927832618429795, 'hit_rate': 0.9365079365079365}\n",
      "Prediction for year 2020 of EXR is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c1424a860>, 'mse': 0.00010280937011587416, 'rmse': 0.010139495555296337, 'mae': 0.007008665632655599, 'hit_rate': 0.8725099601593626}\n",
      "Prediction for year 2021 of EXR is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14231f90>, 'mse': 3.835841303982498e-05, 'rmse': 0.006193416911513787, 'mae': 0.004743144168734199, 'hit_rate': 0.8928571428571429}\n",
      "Prediction for year 2022 of EXR is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14231690>, 'mse': 0.00010082421274827322, 'rmse': 0.010041126069733076, 'mae': 0.006441800468366711, 'hit_rate': 0.8995983935742972}\n",
      "Prediction for year 2017 of PCAR is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14231480>, 'mse': 3.210174333469738e-05, 'rmse': 0.005665840037867058, 'mae': 0.003907535266545924, 'hit_rate': 0.8955823293172691}\n",
      "Prediction for year 2018 of PCAR is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14232410>, 'mse': 3.267055565011735e-05, 'rmse': 0.00571581627155014, 'mae': 0.003941128853823134, 'hit_rate': 0.9043824701195219}\n",
      "Prediction for year 2019 of PCAR is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c142318a0>, 'mse': 0.0001718011077756984, 'rmse': 0.013107292160309024, 'mae': 0.006125940800671608, 'hit_rate': 0.9206349206349206}\n",
      "Prediction for year 2020 of PCAR is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c142316c0>, 'mse': 5.728502436233519e-05, 'rmse': 0.0075686870963420855, 'mae': 0.005642563158648424, 'hit_rate': 0.8565737051792829}\n",
      "Prediction for year 2021 of PCAR is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14230f10>, 'mse': 3.804817033017172e-05, 'rmse': 0.0061683198952528166, 'mae': 0.004298694445202087, 'hit_rate': 0.9325396825396826}\n",
      "Prediction for year 2022 of PCAR is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14231330>, 'mse': 4.036989834184245e-05, 'rmse': 0.006353731056776203, 'mae': 0.004623375420166117, 'hit_rate': 0.9317269076305221}\n",
      "Prediction for year 2017 of EIX is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c142313c0>, 'mse': 8.186481228843877e-05, 'rmse': 0.009047917566403817, 'mae': 0.0034187950829946646, 'hit_rate': 0.8875502008032129}\n",
      "Prediction for year 2018 of EIX is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14230f70>, 'mse': 0.0002465073539300431, 'rmse': 0.01570055266320403, 'mae': 0.006178403838958278, 'hit_rate': 0.8645418326693227}\n",
      "Prediction for year 2019 of EIX is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c142316f0>, 'mse': 0.0002512637360869493, 'rmse': 0.015851300769556716, 'mae': 0.008485119618697108, 'hit_rate': 0.8134920634920635}\n",
      "Prediction for year 2020 of EIX is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14231390>, 'mse': 0.0001376982500515441, 'rmse': 0.011734489765283537, 'mae': 0.00883325337556245, 'hit_rate': 0.8884462151394422}\n",
      "Prediction for year 2021 of EIX is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14230ee0>, 'mse': 5.550585661889485e-05, 'rmse': 0.007450225273029994, 'mae': 0.005928188124980788, 'hit_rate': 0.8373015873015873}\n",
      "Prediction for year 2022 of EIX is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c142310f0>, 'mse': 5.2277396316250055e-05, 'rmse': 0.007230310941878645, 'mae': 0.005884479622391766, 'hit_rate': 0.9116465863453815}\n",
      "Prediction for year 2017 of TMO is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c142315d0>, 'mse': 2.4143561112479257e-05, 'rmse': 0.004913609784311251, 'mae': 0.0031168778135214205, 'hit_rate': 0.9477911646586346}\n",
      "Prediction for year 2018 of TMO is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c142311b0>, 'mse': 2.976022672821883e-05, 'rmse': 0.005455293459404254, 'mae': 0.0038844011250687618, 'hit_rate': 0.9203187250996016}\n",
      "Prediction for year 2019 of TMO is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14230e20>, 'mse': 0.00015126087690671154, 'rmse': 0.012298816077440607, 'mae': 0.00626855161004068, 'hit_rate': 0.9087301587301587}\n",
      "Prediction for year 2020 of TMO is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14231660>, 'mse': 6.815919501474979e-05, 'rmse': 0.008255858223997659, 'mae': 0.0058417690778065, 'hit_rate': 0.8844621513944223}\n",
      "Prediction for year 2021 of TMO is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14230be0>, 'mse': 3.334396570519306e-05, 'rmse': 0.005774423408894871, 'mae': 0.0042882791122374345, 'hit_rate': 0.9166666666666666}\n",
      "Prediction for year 2022 of TMO is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c142314e0>, 'mse': 6.432340178728022e-05, 'rmse': 0.008020187141661984, 'mae': 0.005772539189327495, 'hit_rate': 0.9076305220883534}\n",
      "Prediction for year 2017 of FE is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14230b80>, 'mse': 3.498510580216366e-05, 'rmse': 0.0059148208596849034, 'mae': 0.0034333794678442636, 'hit_rate': 0.9236947791164659}\n",
      "Prediction for year 2018 of FE is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14230cd0>, 'mse': 1.1841257546770134e-05, 'rmse': 0.0034411128355184947, 'mae': 0.0027278367599301587, 'hit_rate': 0.9043824701195219}\n",
      "Prediction for year 2019 of FE is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14232320>, 'mse': 0.00037132284840232473, 'rmse': 0.019269739188746814, 'mae': 0.006813818959425617, 'hit_rate': 0.9007936507936508}\n",
      "Prediction for year 2020 of FE is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14230af0>, 'mse': 0.0004026349198167213, 'rmse': 0.020065764869964996, 'mae': 0.010547907639831933, 'hit_rate': 0.8725099601593626}\n",
      "Prediction for year 2021 of FE is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14230e50>, 'mse': 3.62601354169668e-05, 'rmse': 0.006021638931135509, 'mae': 0.004620489423439775, 'hit_rate': 0.8174603174603174}\n",
      "Prediction for year 2022 of FE is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14230700>, 'mse': 7.543429533125138e-05, 'rmse': 0.008685291896721225, 'mae': 0.0068512105976936315, 'hit_rate': 0.891566265060241}\n",
      "Prediction for year 2017 of RSG is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c142312d0>, 'mse': 1.490543298704731e-05, 'rmse': 0.00386075549433622, 'mae': 0.0021510116172932937, 'hit_rate': 0.9076305220883534}\n",
      "Prediction for year 2018 of RSG is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14230a30>, 'mse': 1.2455357529855499e-05, 'rmse': 0.003529214860256527, 'mae': 0.0023683919605934148, 'hit_rate': 0.9482071713147411}\n",
      "Prediction for year 2019 of RSG is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14231420>, 'mse': 0.00020901547446944207, 'rmse': 0.014457367480611471, 'mae': 0.005241056949252508, 'hit_rate': 0.9246031746031746}\n",
      "Prediction for year 2020 of RSG is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14231120>, 'mse': 7.095410906170136e-05, 'rmse': 0.008423426206817589, 'mae': 0.006444274861454213, 'hit_rate': 0.8685258964143426}\n",
      "Prediction for year 2021 of RSG is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14231270>, 'mse': 4.7353127643235735e-05, 'rmse': 0.006881360885990193, 'mae': 0.0050443923394245275, 'hit_rate': 0.8809523809523809}\n",
      "Prediction for year 2022 of RSG is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c142312a0>, 'mse': 3.0317982267298615e-05, 'rmse': 0.005506176737746312, 'mae': 0.004249855648445493, 'hit_rate': 0.9036144578313253}\n",
      "Prediction for year 2017 of DOV is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14230d60>, 'mse': 2.6818452390039e-05, 'rmse': 0.005178653530604167, 'mae': 0.0035850726069010757, 'hit_rate': 0.9116465863453815}\n",
      "Prediction for year 2018 of DOV is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c14230ac0>, 'mse': 3.762463587888337e-05, 'rmse': 0.006133892392183236, 'mae': 0.0037878349555429893, 'hit_rate': 0.8884462151394422}\n",
      "Prediction for year 2019 of DOV is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14230670>, 'mse': 0.00032831110697571525, 'rmse': 0.018119357245104342, 'mae': 0.007475618826530746, 'hit_rate': 0.9126984126984127}\n",
      "Prediction for year 2020 of DOV is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c142305b0>, 'mse': 8.983809622254456e-05, 'rmse': 0.009478296061135913, 'mae': 0.0069611906577878675, 'hit_rate': 0.852589641434263}\n",
      "Prediction for year 2021 of DOV is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14231360>, 'mse': 4.996857177875283e-05, 'rmse': 0.007068845151702846, 'mae': 0.00522963133252039, 'hit_rate': 0.9126984126984127}\n",
      "Prediction for year 2022 of DOV is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c144defe0>, 'mse': 5.819896279589505e-05, 'rmse': 0.007628824470119564, 'mae': 0.005966609492356188, 'hit_rate': 0.891566265060241}\n",
      "Prediction for year 2017 of AMT is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c142307c0>, 'mse': 2.2474077564389622e-05, 'rmse': 0.004740683238140851, 'mae': 0.0032795244135078233, 'hit_rate': 0.9036144578313253}\n",
      "Prediction for year 2018 of AMT is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c142307f0>, 'mse': 2.0592423514827238e-05, 'rmse': 0.004537887560840091, 'mae': 0.003037286796873189, 'hit_rate': 0.9123505976095617}\n",
      "Prediction for year 2019 of AMT is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c14230ca0>, 'mse': 0.00032707054640304287, 'rmse': 0.018085091827332336, 'mae': 0.007241784220793495, 'hit_rate': 0.8888888888888888}\n",
      "Prediction for year 2020 of AMT is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14231180>, 'mse': 0.00012236142421149994, 'rmse': 0.011061709823146689, 'mae': 0.008013247659307238, 'hit_rate': 0.8764940239043825}\n",
      "Prediction for year 2021 of AMT is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c14230c10>, 'mse': 4.3926404884086245e-05, 'rmse': 0.0066276998184955725, 'mae': 0.005240339121446248, 'hit_rate': 0.8531746031746031}\n",
      "Prediction for year 2022 of AMT is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14230580>, 'mse': 0.00010828840317213887, 'rmse': 0.010406171398364476, 'mae': 0.00804177807302813, 'hit_rate': 0.8674698795180723}\n",
      "Prediction for year 2017 of VZ is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e404c17f580>, 'mse': 2.6243559587592565e-05, 'rmse': 0.005122846824529557, 'mae': 0.0026130675654445633, 'hit_rate': 0.9116465863453815}\n",
      "Prediction for year 2018 of VZ is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e404c17f430>, 'mse': 2.516860449793682e-05, 'rmse': 0.0050168321177748035, 'mae': 0.003547114042924198, 'hit_rate': 0.9163346613545816}\n",
      "Prediction for year 2019 of VZ is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e404c17f850>, 'mse': 7.868093664900324e-05, 'rmse': 0.008870227542121073, 'mae': 0.004415583833631185, 'hit_rate': 0.9126984126984127}\n",
      "Prediction for year 2020 of VZ is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e404c17ff70>, 'mse': 1.948244717506925e-05, 'rmse': 0.004413892519655327, 'mae': 0.003383671465606501, 'hit_rate': 0.9282868525896414}\n",
      "Prediction for year 2021 of VZ is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e404c17f670>, 'mse': 1.2305894408712125e-05, 'rmse': 0.003507975827840341, 'mae': 0.002578265072438264, 'hit_rate': 0.8809523809523809}\n",
      "Prediction for year 2022 of VZ is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14233670>, 'mse': 4.2126715289631585e-05, 'rmse': 0.006490509632504337, 'mae': 0.004448017037076773, 'hit_rate': 0.9116465863453815}\n",
      "Prediction for year 2017 of NUE is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e404c17c070>, 'mse': 3.213701005622673e-05, 'rmse': 0.005668951407114611, 'mae': 0.003937220732926901, 'hit_rate': 0.9196787148594378}\n",
      "Prediction for year 2018 of NUE is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e404c17ffa0>, 'mse': 2.745608046453928e-05, 'rmse': 0.005239855004152241, 'mae': 0.0039599046610748695, 'hit_rate': 0.9043824701195219}\n",
      "Prediction for year 2019 of NUE is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e404c17f940>, 'mse': 0.0002885854556649842, 'rmse': 0.016987803144167413, 'mae': 0.007066156485306074, 'hit_rate': 0.9166666666666666}\n",
      "Prediction for year 2020 of NUE is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e40889560b0>, 'mse': 0.00013277770303839087, 'rmse': 0.011522920768554771, 'mae': 0.007841746581523168, 'hit_rate': 0.8764940239043825}\n",
      "Prediction for year 2021 of NUE is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e404c17f6a0>, 'mse': 0.0001200959074917634, 'rmse': 0.01095882783384078, 'mae': 0.008304788796327723, 'hit_rate': 0.876984126984127}\n",
      "Prediction for year 2022 of NUE is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c14230fa0>, 'mse': 0.0001419224614216433, 'rmse': 0.011913121397083273, 'mae': 0.008126252109207968, 'hit_rate': 0.8995983935742972}\n",
      "Prediction for year 2017 of OKE is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14231de0>, 'mse': 3.497479836460528e-05, 'rmse': 0.005913949472611791, 'mae': 0.004422755606117419, 'hit_rate': 0.9076305220883534}\n",
      "Prediction for year 2018 of OKE is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e4088956bc0>, 'mse': 4.1564975951936945e-05, 'rmse': 0.006447090502849867, 'mae': 0.0050057251605957935, 'hit_rate': 0.8685258964143426}\n",
      "Prediction for year 2019 of OKE is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e4088957130>, 'mse': 0.00208433572526244, 'rmse': 0.04565452579167196, 'mae': 0.012160538392363888, 'hit_rate': 0.9126984126984127}\n",
      "Prediction for year 2020 of OKE is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e4088956dd0>, 'mse': 0.0013414991805064454, 'rmse': 0.03662648195645393, 'mae': 0.02848861984517512, 'hit_rate': 0.7450199203187251}\n",
      "Prediction for year 2021 of OKE is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e4088957100>, 'mse': 0.0002114551189985677, 'rmse': 0.01454149644976636, 'mae': 0.010646198892300625, 'hit_rate': 0.8492063492063492}\n",
      "Prediction for year 2022 of OKE is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e40889564a0>, 'mse': 0.0002191966691194773, 'rmse': 0.01480529192955942, 'mae': 0.0110797814122072, 'hit_rate': 0.8313253012048193}\n",
      "Prediction for year 2017 of WAB is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c14231300>, 'mse': 7.490586023113496e-05, 'rmse': 0.008654817169133902, 'mae': 0.004372690366197201, 'hit_rate': 0.9236947791164659}\n",
      "Prediction for year 2018 of WAB is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e4088956f50>, 'mse': 0.00011306641793870932, 'rmse': 0.010633269390865131, 'mae': 0.006281192401221068, 'hit_rate': 0.900398406374502}\n",
      "Prediction for year 2019 of WAB is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e4088957940>, 'mse': 0.0003464059833520154, 'rmse': 0.0186119849385286, 'mae': 0.009139040535180746, 'hit_rate': 0.9166666666666666}\n",
      "Prediction for year 2020 of WAB is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e3c14230c40>, 'mse': 0.00015254035705771277, 'rmse': 0.012350722936642728, 'mae': 0.00863285575910896, 'hit_rate': 0.8804780876494024}\n",
      "Prediction for year 2021 of WAB is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e4088957fa0>, 'mse': 4.907635454182237e-05, 'rmse': 0.007005451772856792, 'mae': 0.005240963244983952, 'hit_rate': 0.9007936507936508}\n",
      "Prediction for year 2022 of WAB is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e4088956590>, 'mse': 5.550884050612679e-05, 'rmse': 0.0074504255251714845, 'mae': 0.005913103560070111, 'hit_rate': 0.8995983935742972}\n",
      "Prediction for year 2017 of BIIB is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e4088956ad0>, 'mse': 4.726137897847106e-05, 'rmse': 0.00687469119149879, 'mae': 0.005158376571041211, 'hit_rate': 0.8875502008032129}\n",
      "Prediction for year 2018 of BIIB is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e4088956530>, 'mse': 0.0003922971842975146, 'rmse': 0.019806493488184994, 'mae': 0.007356584711909658, 'hit_rate': 0.8844621513944223}\n",
      "Prediction for year 2019 of BIIB is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e404c17f820>, 'mse': 0.00032410698546920765, 'rmse': 0.018002971573304438, 'mae': 0.009426202913728721, 'hit_rate': 0.8571428571428571}\n",
      "Prediction for year 2020 of BIIB is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e4088956da0>, 'mse': 0.0008091613369980034, 'rmse': 0.02844576131865701, 'mae': 0.011062217329363752, 'hit_rate': 0.8685258964143426}\n",
      "Prediction for year 2021 of BIIB is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e4088956470>, 'mse': 0.0003783334708090091, 'rmse': 0.019450796148461614, 'mae': 0.01169127647837339, 'hit_rate': 0.8333333333333334}\n",
      "Prediction for year 2022 of BIIB is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e4088956e30>, 'mse': 0.00034502457186934776, 'rmse': 0.018574837061717333, 'mae': 0.011358474810271421, 'hit_rate': 0.8393574297188755}\n",
      "Prediction for year 2017 of NTRS is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c8cf4ab90>, 'mse': 3.2068267061114405e-05, 'rmse': 0.005662885047492524, 'mae': 0.0038439990443675754, 'hit_rate': 0.8955823293172691}\n",
      "Prediction for year 2018 of NTRS is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c8cf4afb0>, 'mse': 3.998940815978471e-05, 'rmse': 0.006323717906404801, 'mae': 0.004426046955873812, 'hit_rate': 0.9243027888446215}\n",
      "Prediction for year 2019 of NTRS is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e4088957040>, 'mse': 0.000409231400301451, 'rmse': 0.020229468611445308, 'mae': 0.007657847741665248, 'hit_rate': 0.9404761904761905}\n",
      "Prediction for year 2020 of NTRS is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e4088956fe0>, 'mse': 0.00011481964741820044, 'rmse': 0.010715393012773747, 'mae': 0.008001702879603102, 'hit_rate': 0.8884462151394422}\n",
      "Prediction for year 2021 of NTRS is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c8cf4bc10>, 'mse': 7.149905944348358e-05, 'rmse': 0.008455711646188248, 'mae': 0.006384613349894925, 'hit_rate': 0.9365079365079365}\n",
      "Prediction for year 2022 of NTRS is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c8cf4b7f0>, 'mse': 0.00010237506975285583, 'rmse': 0.010118056619373893, 'mae': 0.00757790726674805, 'hit_rate': 0.8714859437751004}\n",
      "Prediction for year 2017 of MGM is done.\n",
      "2017: {'model': <__main__.ELMRegressor object at 0x7e3c8cf4b2e0>, 'mse': 2.808085760634068e-05, 'rmse': 0.005299137439842515, 'mae': 0.004194073271499919, 'hit_rate': 0.9317269076305221}\n",
      "Prediction for year 2018 of MGM is done.\n",
      "2018: {'model': <__main__.ELMRegressor object at 0x7e3c8cf499c0>, 'mse': 7.203390816147802e-05, 'rmse': 0.008487279196625855, 'mae': 0.0054759246875916, 'hit_rate': 0.9322709163346613}\n",
      "Prediction for year 2019 of MGM is done.\n",
      "2019: {'model': <__main__.ELMRegressor object at 0x7e3c8cf4b820>, 'mse': 0.0015660365605096613, 'rmse': 0.03957317981297006, 'mae': 0.012363027687810339, 'hit_rate': 0.9166666666666666}\n",
      "Prediction for year 2020 of MGM is done.\n",
      "2020: {'model': <__main__.ELMRegressor object at 0x7e404c17f910>, 'mse': 0.0009709515160881536, 'rmse': 0.031160094930666588, 'mae': 0.021582114517127052, 'hit_rate': 0.7928286852589641}\n",
      "Prediction for year 2021 of MGM is done.\n",
      "2021: {'model': <__main__.ELMRegressor object at 0x7e3c8cf4b2b0>, 'mse': 0.00019258671487439114, 'rmse': 0.013877561560821525, 'mae': 0.010914424639327102, 'hit_rate': 0.9166666666666666}\n",
      "Prediction for year 2022 of MGM is done.\n",
      "2022: {'model': <__main__.ELMRegressor object at 0x7e3c8cf4b370>, 'mse': 0.00019071117534039196, 'rmse': 0.01380982169835628, 'mae': 0.010436501342022161, 'hit_rate': 0.8875502008032129}\n",
      "Execution time: 5.73444938659668 seconds\n"
     ]
    }
   ],
   "source": [
    "class ELMRegressor:\n",
    "    def __init__(self, n_hidden_units):\n",
    "        self.n_hidden_units = n_hidden_units\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.input_weights = np.random.normal(size=[X.shape[1], self.n_hidden_units])\n",
    "        self.biases = np.random.normal(size=[self.n_hidden_units])\n",
    "\n",
    "        # Calculate hidden layer output\n",
    "        H = np.tanh(np.dot(X, self.input_weights) + self.biases)\n",
    "\n",
    "        # Calculate output weights (beta)\n",
    "        self.beta = np.dot(np.linalg.pinv(H), y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        H = np.tanh(np.dot(X, self.input_weights) + self.biases)\n",
    "        return np.dot(H, self.beta)\n",
    "start_time = time.time()\n",
    "target_column = 'rt'\n",
    "\n",
    "# Initialize a dictionary to store the best models and their performance for each stock\n",
    "ELM_performance = {}\n",
    "ELM_stock_return={}\n",
    "# Loop over each stock\n",
    "for stock_name, windows in SP500_Train_Test_Dict.items():\n",
    "    stock_best_models = []\n",
    "    ret = []\n",
    "\n",
    "    # Loop over each pair of training/testing set\n",
    "    years = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "    for year, (train_df, test_df) in zip(years, windows):\n",
    "        # Standardize the data\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_y = StandardScaler()\n",
    "        X_train_scaled = scaler_X.fit_transform(train_df.iloc[:, 7:].drop(columns=[target_column]))\n",
    "        y_train_scaled = scaler_y.fit_transform(train_df[[target_column]])\n",
    "        X_test_scaled = scaler_X.transform(test_df.iloc[:, 7:].drop(columns=[target_column]))\n",
    "        y_test_scaled = scaler_y.transform(test_df[[target_column]])\n",
    "\n",
    "        # Flatten y arrays\n",
    "        y_train_scaled = y_train_scaled.ravel()\n",
    "        y_test_scaled = y_test_scaled.ravel()\n",
    "\n",
    "        # Define and fit the ELM model\n",
    "        elm_model = ELMRegressor(n_hidden_units=100)\n",
    "        elm_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred_scaled = elm_model.predict(X_test_scaled)\n",
    "\n",
    "        # Inverse transform predictions and actual values to original scale\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "        y_test = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "        ret.append(y_pred)\n",
    "        # Calculate performance metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Calculate Hit Rate\n",
    "        direction_pred = np.sign(np.diff(y_pred))\n",
    "        direction_true = np.sign(np.diff(y_test))\n",
    "        hit_rate = np.mean(direction_pred == direction_true)\n",
    "\n",
    "        # Store the best model and its performance metrics\n",
    "        stock_best_models.append({\n",
    "            'model': elm_model,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'hit_rate': hit_rate\n",
    "        })\n",
    "\n",
    "        print(f\"Prediction for year {year} of {stock_name} is done.\")\n",
    "        print(f\"{year}: {stock_best_models[-1]}\")\n",
    "\n",
    "    # Add the best models and their performance to the dictionary\n",
    "    ELM_performance[stock_name] = stock_best_models\n",
    "    ELM_stock_return[stock_name] = ret\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PolvCAe2D1hP"
   },
   "outputs": [],
   "source": [
    "def calculate_average_metrics(data):\n",
    "    averages = {}\n",
    "    for stock, records in data.items():\n",
    "        total_metrics = {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0}\n",
    "        for record in records:\n",
    "            total_metrics['mse'] += record['mse']\n",
    "            total_metrics['rmse'] += record['rmse']\n",
    "            total_metrics['mae'] += record['mae']\n",
    "            total_metrics['hit_rate'] += record['hit_rate']\n",
    "        averages[stock] = {metric: total / len(records) for metric, total in total_metrics.items()}\n",
    "\n",
    "    return averages\n",
    "\n",
    "def calculate_average_by_year(data):\n",
    "    year_metrics = {2017: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2018: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2019: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2020: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2021: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2022: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0}}\n",
    "    counts = {year: 0 for year in year_metrics}\n",
    "    for stock, records in data.items():\n",
    "        for index, record in enumerate(records):\n",
    "            year = 2017 + index\n",
    "            # 累加指标\n",
    "            year_metrics[year]['mse'] += record['mse']\n",
    "            year_metrics[year]['rmse'] += record['rmse']\n",
    "            year_metrics[year]['mae'] += record['mae']\n",
    "            year_metrics[year]['hit_rate'] += record['hit_rate']\n",
    "            counts[year] += 1\n",
    "    for year in year_metrics:\n",
    "        for metric in year_metrics[year]:\n",
    "            year_metrics[year][metric] /= counts[year]\n",
    "\n",
    "    return year_metrics\n",
    "# calculate mean\n",
    "RF_averages = calculate_averages(RF_performance)\n",
    "rf=pd.DataFrame(RF_averages)\n",
    "rf[\"model\"]=\"rf\"\n",
    "LSTM_averages = calculate_average_by_year(LSTM_performance)\n",
    "lstm=pd.DataFrame(LSTM_averages)\n",
    "lstm[\"model\"]=\"lstm\"\n",
    "SVR_averages = calculate_average_by_year(SVR_performance)\n",
    "svr=pd.DataFrame(SVR_averages)\n",
    "svr[\"model\"]=\"svr\"\n",
    "BPNN_averages = calculate_average_by_year(BPNN_performance)\n",
    "bpnn=pd.DataFrame(BPNN_averages)\n",
    "bpnn[\"model\"]=\"bpnn\"\n",
    "ELM_averages = calculate_average_by_year(ELM_performance)\n",
    "elm=pd.DataFrame(ELM_averages)\n",
    "elm[\"model\"]=\"elm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "agPayByKD4ME",
    "outputId": "1242c403-53d0-40aa-9044-150928c48b7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpnn\n",
      "mse         0.000006\n",
      "rmse        0.002281\n",
      "mae         0.001639\n",
      "hit_rate    0.945515\n",
      "Name: 2017, dtype: float64\n",
      "elm\n",
      "mse         0.000041\n",
      "rmse        0.006104\n",
      "mae         0.003849\n",
      "hit_rate    0.908300\n",
      "Name: 2017, dtype: float64\n",
      "lstm\n",
      "mse         0.000023\n",
      "rmse        0.004578\n",
      "mae         0.002788\n",
      "hit_rate    0.934404\n",
      "Name: 2017, dtype: float64\n",
      "rf\n",
      "mse         0.000131\n",
      "rmse        0.009220\n",
      "mae         0.003686\n",
      "hit_rate    0.950679\n",
      "Name: 2017, dtype: float64\n",
      "svr\n",
      "mse         0.000051\n",
      "rmse        0.006270\n",
      "mae         0.002072\n",
      "hit_rate    0.960509\n",
      "Name: 2017, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_models = pd.concat([rf, lstm, svr, bpnn, elm])\n",
    "for name, group in df_models.groupby(by=[\"model\"])[2017]:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "braFc5WQD6oq",
    "outputId": "97d16767-0cb1-47f4-9958-ba283e47898d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpnn\n",
      "mse         0.000010\n",
      "rmse        0.002932\n",
      "mae         0.002061\n",
      "hit_rate    0.941036\n",
      "Name: 2018, dtype: float64\n",
      "elm\n",
      "mse         0.000075\n",
      "rmse        0.007661\n",
      "mae         0.004724\n",
      "hit_rate    0.908367\n",
      "Name: 2018, dtype: float64\n",
      "lstm\n",
      "mse         0.000038\n",
      "rmse        0.005569\n",
      "mae         0.003415\n",
      "hit_rate    0.928552\n",
      "Name: 2018, dtype: float64\n",
      "rf\n",
      "mse         0.000131\n",
      "rmse        0.009220\n",
      "mae         0.003686\n",
      "hit_rate    0.950679\n",
      "Name: 2018, dtype: float64\n",
      "svr\n",
      "mse         0.000113\n",
      "rmse        0.008771\n",
      "mae         0.003207\n",
      "hit_rate    0.955113\n",
      "Name: 2018, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_models = pd.concat([rf, lstm, svr, bpnn, elm])\n",
    "for name, group in df_models.groupby(by=[\"model\"])[2018]:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqhWyYSzD69C",
    "outputId": "331f2e71-49ed-49b0-8e49-ff8700444057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpnn\n",
      "mse         0.000026\n",
      "rmse        0.004798\n",
      "mae         0.002582\n",
      "hit_rate    0.947884\n",
      "Name: 2019, dtype: float64\n",
      "elm\n",
      "mse         0.000426\n",
      "rmse        0.019231\n",
      "mae         0.007797\n",
      "hit_rate    0.913360\n",
      "Name: 2019, dtype: float64\n",
      "lstm\n",
      "mse         0.000254\n",
      "rmse        0.014480\n",
      "mae         0.005958\n",
      "hit_rate    0.931614\n",
      "Name: 2019, dtype: float64\n",
      "rf\n",
      "mse         0.000131\n",
      "rmse        0.009220\n",
      "mae         0.003686\n",
      "hit_rate    0.950679\n",
      "Name: 2019, dtype: float64\n",
      "svr\n",
      "mse         0.000645\n",
      "rmse        0.024056\n",
      "mae         0.007481\n",
      "hit_rate    0.937037\n",
      "Name: 2019, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_models = pd.concat([rf, lstm, svr, bpnn, elm])\n",
    "for name, group in df_models.groupby(by=[\"model\"])[2019]:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptkXDbB3D7KF",
    "outputId": "117a97a7-e1df-4395-cf36-42840ebf4994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpnn\n",
      "mse         0.000046\n",
      "rmse        0.005872\n",
      "mae         0.004176\n",
      "hit_rate    0.933466\n",
      "Name: 2020, dtype: float64\n",
      "elm\n",
      "mse         0.000249\n",
      "rmse        0.013896\n",
      "mae         0.009660\n",
      "hit_rate    0.860823\n",
      "Name: 2020, dtype: float64\n",
      "lstm\n",
      "mse         0.000073\n",
      "rmse        0.007648\n",
      "mae         0.005077\n",
      "hit_rate    0.938911\n",
      "Name: 2020, dtype: float64\n",
      "rf\n",
      "mse         0.000131\n",
      "rmse        0.009220\n",
      "mae         0.003686\n",
      "hit_rate    0.950679\n",
      "Name: 2020, dtype: float64\n",
      "svr\n",
      "mse         0.000297\n",
      "rmse        0.015016\n",
      "mae         0.006659\n",
      "hit_rate    0.940770\n",
      "Name: 2020, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_models = pd.concat([rf, lstm, svr, bpnn, elm])\n",
    "for name, group in df_models.groupby(by=[\"model\"])[2020]:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNj7_niLD7Vd",
    "outputId": "37eb233f-c4e1-40e0-97b7-3213d02370f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpnn\n",
      "mse         0.000014\n",
      "rmse        0.003469\n",
      "mae         0.002564\n",
      "hit_rate    0.937037\n",
      "Name: 2021, dtype: float64\n",
      "elm\n",
      "mse         0.000087\n",
      "rmse        0.008720\n",
      "mae         0.006300\n",
      "hit_rate    0.885847\n",
      "Name: 2021, dtype: float64\n",
      "lstm\n",
      "mse         0.000031\n",
      "rmse        0.005200\n",
      "mae         0.003634\n",
      "hit_rate    0.936905\n",
      "Name: 2021, dtype: float64\n",
      "rf\n",
      "mse         0.000131\n",
      "rmse        0.009220\n",
      "mae         0.003686\n",
      "hit_rate    0.950679\n",
      "Name: 2021, dtype: float64\n",
      "svr\n",
      "mse         0.000048\n",
      "rmse        0.005185\n",
      "mae         0.002091\n",
      "hit_rate    0.966667\n",
      "Name: 2021, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_models = pd.concat([rf, lstm, svr, bpnn, elm])\n",
    "for name, group in df_models.groupby(by=[\"model\"])[2021]:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpEAtdd1D7gw",
    "outputId": "a6849b8d-caf8-4bce-b157-bb22e60693ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpnn\n",
      "mse         0.000020\n",
      "rmse        0.004223\n",
      "mae         0.003075\n",
      "hit_rate    0.937483\n",
      "Name: 2022, dtype: float64\n",
      "elm\n",
      "mse         0.000113\n",
      "rmse        0.010215\n",
      "mae         0.007444\n",
      "hit_rate    0.887416\n",
      "Name: 2022, dtype: float64\n",
      "lstm\n",
      "mse         0.000044\n",
      "rmse        0.006397\n",
      "mae         0.004567\n",
      "hit_rate    0.935207\n",
      "Name: 2022, dtype: float64\n",
      "rf\n",
      "mse         0.000131\n",
      "rmse        0.009220\n",
      "mae         0.003686\n",
      "hit_rate    0.950679\n",
      "Name: 2022, dtype: float64\n",
      "svr\n",
      "mse         0.000077\n",
      "rmse        0.007592\n",
      "mae         0.002982\n",
      "hit_rate    0.962651\n",
      "Name: 2022, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_models = pd.concat([rf, lstm, svr, bpnn, elm])\n",
    "for name, group in df_models.groupby(by=[\"model\"])[2022]:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yj3pLp_D_q8",
    "outputId": "5895dfcf-7222-4fcc-dbe8-f02f43fe1692",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of simulations\n",
    "num_simulations = 100\n",
    "\n",
    "# Initialize a dictionary to store all predictions for each stock\n",
    "all_predictions = {stock_name: [] for stock_name in SP500_Train_Test_Dict.keys()}\n",
    "\n",
    "# Monte Carlo simulation: repeat the prediction process 5000 times\n",
    "for _ in range(num_simulations):\n",
    "    for stock_name, windows in SP500_Train_Test_Dict.items():\n",
    "        # Select the most recent testing set as the future data to predict\n",
    "        _, most_recent_test_df = windows[-1]  # Last pair in the list is the most recent\n",
    "\n",
    "        # Standardize the feature columns of the most recent data\n",
    "        X_future_scaled = scaler_X.transform(most_recent_test_df.iloc[:, 7:].drop(columns=[target_column]))\n",
    "\n",
    "        # Use the last trained BPNN model for this stock to make predictions on the future data\n",
    "        last_model = BPNN_performance[stock_name][-1]['model']  # Last model in the list for the stock\n",
    "        future_pred_scaled = last_model.predict(X_future_scaled)\n",
    "\n",
    "        # Inverse transform the predictions to the original scale\n",
    "        future_pred = scaler_y.inverse_transform(future_pred_scaled).flatten()\n",
    "\n",
    "        # Store the predictions\n",
    "        all_predictions[stock_name].append(future_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9ZBdaAK3e_xM"
   },
   "outputs": [],
   "source": [
    "def calculate_average_metrics(data):\n",
    "    averages = {}\n",
    "    for stock, records in data.items():\n",
    "        # 初始化累计指标\n",
    "        total_metrics = {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0}\n",
    "\n",
    "        # 累加每条记录的指标\n",
    "        for record in records:\n",
    "            total_metrics['mse'] += record['mse']\n",
    "            total_metrics['rmse'] += record['rmse']\n",
    "            total_metrics['mae'] += record['mae']\n",
    "            total_metrics['hit_rate'] += record['hit_rate']\n",
    "\n",
    "        # 计算平均值\n",
    "        averages[stock] = {metric: total / len(records) for metric, total in total_metrics.items()}\n",
    "\n",
    "    return averages\n",
    "\n",
    "def calculate_average_by_year(data):\n",
    "    year_metrics = {2017: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2018: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2019: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2020: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2021: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0},\n",
    "                    2022: {'mse': 0, 'rmse': 0, 'mae': 0, 'hit_rate': 0}}\n",
    "    counts = {year: 0 for year in year_metrics}\n",
    "    for stock, records in data.items():\n",
    "        for index, record in enumerate(records):\n",
    "            year = 2017 + index\n",
    "            # 累加指标\n",
    "            year_metrics[year]['mse'] += record['mse']\n",
    "            year_metrics[year]['rmse'] += record['rmse']\n",
    "            year_metrics[year]['mae'] += record['mae']\n",
    "            year_metrics[year]['hit_rate'] += record['hit_rate']\n",
    "            counts[year] += 1\n",
    "    for year in year_metrics:\n",
    "        for metric in year_metrics[year]:\n",
    "            year_metrics[year][metric] /= counts[year]\n",
    "\n",
    "    return year_metrics\n",
    "# calculate mean\n",
    "RF_averages = calculate_averages(RF_performance)\n",
    "rf=pd.DataFrame(RF_averages)\n",
    "rf[\"model\"]=\"rf\"\n",
    "LSTM_averages = calculate_average_by_year(LSTM_performance)\n",
    "lstm=pd.DataFrame(LSTM_averages)\n",
    "lstm[\"model\"]=\"lstm\"\n",
    "SVR_averages = calculate_average_by_year(SVR_performance)\n",
    "svr=pd.DataFrame(SVR_averages)\n",
    "svr[\"model\"]=\"svr\"\n",
    "BPNN_averages = calculate_average_by_year(BPNN_performance)\n",
    "bpnn=pd.DataFrame(BPNN_averages)\n",
    "bpnn[\"model\"]=\"bpnn\"\n",
    "ELM_averages = calculate_average_by_year(ELM_performance)\n",
    "elm=pd.DataFrame(ELM_averages)\n",
    "elm[\"model\"]=\"elm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVnpodcNfH49",
    "outputId": "503e96f4-e028-483d-c408-fcf02dbde39c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top eight stocks based on mean predicted future returns across 1000 simulations:\n",
      "WAB: 1.5209\n",
      "LNT: 1.2378\n",
      "VZ: 1.2293\n",
      "TRV: 1.2225\n",
      "EIX: 1.1416\n",
      "DHI: 1.1328\n",
      "WMT: 1.1326\n",
      "RSG: 1.0709\n"
     ]
    }
   ],
   "source": [
    "mean_future_returns = {}\n",
    "for stock_name, preds in all_predictions.items():\n",
    "  lst=[]\n",
    "  for pred in preds:\n",
    "    re=1\n",
    "    for i in pred:\n",
    "      re*=(1+i)\n",
    "    lst.append(re)\n",
    "  mean_future_returns[stock_name] = np.mean(lst)\n",
    "# Calculate the mean predicted return for each stock across all simulations\n",
    "\n",
    "\n",
    "# Sort the stocks by their mean predicted return in descending order\n",
    "sorted_stocks_by_return = sorted(mean_future_returns.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select the top eight stocks\n",
    "top_eight_stocks = sorted_stocks_by_return[:8]\n",
    "\n",
    "# Extract just the stock names if needed\n",
    "top_eight_stock_names = [stock[0] for stock in top_eight_stocks]\n",
    "\n",
    "print(\"Top eight stocks based on mean predicted future returns across 1000 simulations:\")\n",
    "for stock, mean_return in top_eight_stocks:\n",
    "    print(f\"{stock}: {mean_return:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vAdwJ28OfPrZ"
   },
   "outputs": [],
   "source": [
    "for stock_name, preds in all_predictions.items():\n",
    "  lst=[]\n",
    "  for pred in preds:\n",
    "    re=1\n",
    "    for i in pred:\n",
    "      re*=(1+i)\n",
    "    lst.append(re)\n",
    "  mean_future_returns[stock_name] = np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Mw_V3M_yfPtz"
   },
   "outputs": [],
   "source": [
    "mean_returns=[]\n",
    "stocks=[]\n",
    "for stock, ret in top_eight_stocks:\n",
    "  mean_returns.append(ret)\n",
    "  stocks.append(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "nYHvJZg7fPwd",
    "outputId": "9ae19082-5a42-471e-868c-9e6af42ede50"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"future_return\",\n  \"rows\": 250,\n  \"fields\": [\n    {\n      \"column\": \"WAB\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          0.0071631502360105515,\n          -0.002716928953304887,\n          0.0037308239843696356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LNT\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          -0.012402699328958988,\n          0.006934879347681999,\n          -0.0009639133349992335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VZ\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          0.0034876682329922915,\n          -0.003586438950151205,\n          -0.015050443820655346\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TRV\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          0.0014240131713449955,\n          -0.0036193719133734703,\n          -0.0010768775828182697\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EIX\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          0.0012649762211367488,\n          0.01494523137807846,\n          -0.01055894885212183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DHI\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          0.001425960217602551,\n          -0.00999003741890192,\n          -0.0004120631201658398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WMT\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          0.01095675304532051,\n          -0.009065748192369938,\n          -0.0026297597214579582\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RSG\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          -0.011543872766196728,\n          -0.012346017174422741,\n          -0.004869214724749327\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "future_return"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-01737cf6-c3a3-4c88-bab8-d89a8faffebc\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAB</th>\n",
       "      <th>LNT</th>\n",
       "      <th>VZ</th>\n",
       "      <th>TRV</th>\n",
       "      <th>EIX</th>\n",
       "      <th>DHI</th>\n",
       "      <th>WMT</th>\n",
       "      <th>RSG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.018220</td>\n",
       "      <td>-0.009445</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.012111</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>-0.000759</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>-0.009315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.038437</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.014686</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>-0.004216</td>\n",
       "      <td>-0.027202</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.011997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>-0.039964</td>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.001009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.007818</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.010678</td>\n",
       "      <td>-0.011430</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>0.015657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009145</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.022891</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.005056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.021856</td>\n",
       "      <td>-0.006781</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>-0.017769</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>-0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.016416</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.005269</td>\n",
       "      <td>0.006113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.021743</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>-0.003961</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.010725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.001317</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.005425</td>\n",
       "      <td>-0.004667</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>0.014974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.010369</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.025992</td>\n",
       "      <td>0.008650</td>\n",
       "      <td>0.003888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 8 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01737cf6-c3a3-4c88-bab8-d89a8faffebc')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-01737cf6-c3a3-4c88-bab8-d89a8faffebc button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-01737cf6-c3a3-4c88-bab8-d89a8faffebc');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-7a72722c-6f2c-4338-ad9c-55ea1d3a73c2\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a72722c-6f2c-4338-ad9c-55ea1d3a73c2')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-7a72722c-6f2c-4338-ad9c-55ea1d3a73c2 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_28ce72fd-72a8-4f9f-8e90-9208387ca6fd\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('future_return')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_28ce72fd-72a8-4f9f-8e90-9208387ca6fd button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('future_return');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          WAB       LNT        VZ       TRV       EIX       DHI       WMT  \\\n",
       "0   -0.018220 -0.009445  0.008773 -0.012111  0.001418 -0.000759 -0.000170   \n",
       "1   -0.038437  0.014720  0.014686 -0.000396 -0.004216 -0.027202  0.005824   \n",
       "2    0.011795  0.029273  0.012941  0.006537  0.012942 -0.039964  0.026164   \n",
       "3   -0.000069 -0.005438 -0.007818 -0.003822 -0.010678 -0.011430  0.015157   \n",
       "4   -0.009145  0.006454  0.022891  0.016665  0.014258  0.003473  0.009026   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "245  0.021856 -0.006781  0.015015  0.006210  0.005260 -0.017769  0.014796   \n",
       "246  0.009002  0.016416  0.000258  0.000352 -0.000917 -0.000074 -0.005269   \n",
       "247  0.010714  0.007359  0.014728  0.021743  0.016192 -0.003961  0.004756   \n",
       "248 -0.001317  0.007692  0.008500  0.002922  0.005425 -0.004667  0.007241   \n",
       "249  0.012892  0.007698  0.010369  0.001906  0.010243  0.025992  0.008650   \n",
       "\n",
       "          RSG  \n",
       "0   -0.009315  \n",
       "1    0.011997  \n",
       "2    0.001009  \n",
       "3    0.015657  \n",
       "4    0.005056  \n",
       "..        ...  \n",
       "245 -0.000213  \n",
       "246  0.006113  \n",
       "247  0.010725  \n",
       "248  0.014974  \n",
       "249  0.003888  \n",
       "\n",
       "[250 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_return=pd.DataFrame()\n",
    "for i in stocks:\n",
    "  future_return[i]=np.mean(all_predictions[i], axis=0)\n",
    "future_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HlXW52qdfPzU",
    "outputId": "1b6f744c-224b-4fb0-de58-1577de01c444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAB: 0.00000000000000000000%\n",
      "LNT: 8.06025792640135207989%\n",
      "VZ: 17.93148971318071716041%\n",
      "TRV: 27.58650410033712319091%\n",
      "EIX: 0.00000000000000145583%\n",
      "DHI: 2.82461196224525235010%\n",
      "WMT: 18.53654177775289824126%\n",
      "RSG: 25.06059452008266319467%\n",
      "The estimate return of the portfolio is: 1.16774690219049\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = future_return.cov()\n",
    "# Number of assets\n",
    "num_assets = len(mean_returns)\n",
    "\n",
    "# Objective function: Portfolio volatility\n",
    "def portfolio_volatility(weights, mean_returns, cov_matrix):\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "\n",
    "# Constraints: Weights sum to 1\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "\n",
    "# Bounds for weights\n",
    "bounds = tuple((0, 1) for asset in range(num_assets))\n",
    "\n",
    "# Initial guess for weights\n",
    "initial_guess = num_assets * [1. / num_assets,]\n",
    "\n",
    "# Optimization function\n",
    "def minimize_volatility(mean_returns, cov_matrix):\n",
    "    opt_result = minimize(fun=portfolio_volatility,\n",
    "                          x0=initial_guess,\n",
    "                          args=(mean_returns, cov_matrix),\n",
    "                          method='SLSQP',\n",
    "                          bounds=bounds,\n",
    "                          constraints=constraints)\n",
    "    return opt_result.x\n",
    "\n",
    "# Calculate optimal weights\n",
    "optimal_weights = minimize_volatility(mean_returns, cov_matrix)\n",
    "\n",
    "for stock, weight in zip(stocks, optimal_weights):\n",
    "    print(f\"{stock}: {weight:.20%}\")\n",
    "print(f\"The estimate return of the portfolio is: {sum(optimal_weights*mean_returns)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
